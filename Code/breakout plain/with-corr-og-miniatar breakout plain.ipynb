{"cells":[{"cell_type":"markdown","metadata":{"id":"nm2uk2yDFugI"},"source":["\\\n","# Reinforcement Learning (DQN) Tutorial\n","**Author**: [Adam Paszke](https://github.com/apaszke)\n","            [Mark Towers](https://github.com/pseudo-rnd-thoughts)\n","\n","\n","This tutorial shows how to use PyTorch to train a Deep Q Learning (DQN) agent\n","on the CartPole-v1 task from [Gymnasium](https://gymnasium.farama.org)_.\n","\n","**Task**\n","\n","The agent has to decide between two actions - moving the cart left or\n","right - so that the pole attached to it stays upright. You can find more\n","information about the environment and other more challenging environments at\n","[Gymnasium's website](https://gymnasium.farama.org/environments/classic_control/cart_pole/)_.\n","\n",".. figure:: /_static/img/cartpole.gif\n","   :alt: CartPole\n","\n","   CartPole\n","\n","As the agent observes the current state of the environment and chooses\n","an action, the environment *transitions* to a new state, and also\n","returns a reward that indicates the consequences of the action. In this\n","task, rewards are +1 for every incremental timestep and the environment\n","terminates if the pole falls over too far or the cart moves more than 2.4\n","units away from center. This means better performing scenarios will run\n","for longer duration, accumulating larger return.\n","\n","The CartPole task is designed so that the inputs to the agent are 4 real\n","values representing the environment state (position, velocity, etc.).\n","We take these 4 inputs without any scaling and pass them through a\n","small fully-connected network with 2 outputs, one for each action.\n","The network is trained to predict the expected value for each action,\n","given the input state. The action with the highest expected value is\n","then chosen.\n","\n","\n","**Packages**\n","\n","\n","First, let's import needed packages. Firstly, we need\n","[gymnasium](https://gymnasium.farama.org/)_ for the environment,\n","installed by using `pip`. This is a fork of the original OpenAI\n","Gym project and maintained by the same team since Gym v0.19.\n","If you are running this in Google Colab, run:\n"]},{"cell_type":"markdown","metadata":{"id":"hCNb6nixFugK"},"source":["We'll also use the following from PyTorch:\n","\n","-  neural networks (``torch.nn``)\n","-  optimization (``torch.optim``)\n","-  automatic differentiation (``torch.autograd``)\n"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T09:38:12.806805Z","iopub.status.busy":"2024-09-06T09:38:12.805761Z","iopub.status.idle":"2024-09-06T09:38:30.599226Z","shell.execute_reply":"2024-09-06T09:38:30.597072Z","shell.execute_reply.started":"2024-09-06T09:38:12.806752Z"},"trusted":true},"outputs":[],"source":["# %matplotlib inline\n","%matplotlib qt\n","# # !pip install swig\n","# !pip install minatar==1.0.13\n","# # !pip install gymnasium\n","# # !pip install \"gymnasium[all]\"\n","# # "]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T09:38:30.608228Z","iopub.status.busy":"2024-09-06T09:38:30.607570Z","iopub.status.idle":"2024-09-06T09:38:37.865809Z","shell.execute_reply":"2024-09-06T09:38:37.864425Z","shell.execute_reply.started":"2024-09-06T09:38:30.608180Z"},"id":"Vs-RXSibFugK","trusted":true},"outputs":[],"source":["from minatar import Environment\n","# import gymnasium as gym\n","import math\n","import random\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from collections import namedtuple, deque\n","from itertools import count\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as f\n","\n","# SEED = 42\n","\n","# # # Set random seed for NumPy\n","# np.random.seed(SEED)\n","\n","# # # Set random seed for Python's built-in random module\n","# random.seed(SEED)\n","\n","\n","# torch.manual_seed(SEED)\n","# if torch.cuda.is_available():\n","#     torch.cuda.manual_seed(SEED)\n","#     torch.cuda.manual_seed_all(SEED)\n","#     torch.backends.cudnn.deterministic = True\n","# #     # torch.backends.cudnn.benchmark = False\n","\n","\n","\n","# env = gym.make(\n","#     \"LunarLander-v2\",\n","#     continuous = False,\n","#     gravity = -10.0,\n","#     enable_wind = False,\n","#     wind_power = 15.0,\n","#     turbulence_power = 1.5,\n","# )\n","\n","# env.seed(SEED)\n","\n","# env = gym.make('LunarLander-v2')\n","env = Environment('breakout')\n","\n","# env = gym.make('CartPole-v1')\n","# env = gym.make('MountainCar-v0', max_episode_steps=1000)\n","# env = gym.make('MountainCar-v0', max_episode_steps=500)\n","# env = gym.make(\"Acrobot-v1\")\n","\n","# env = gym.make(\"BipedalWalker-v3\")\n","# env.action_space.seed(SEED)\n","# set up matplotlib\n","is_ipython = 'inline' in matplotlib.get_backend()\n","if is_ipython:\n","    from IPython import display\n","\n","plt.ion()\n","\n","# if GPU is to be used\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"WSzvivYYFugK"},"source":["## Replay Memory\n","\n","We'll be using experience replay memory for training our DQN. It stores\n","the transitions that the agent observes, allowing us to reuse this data\n","later. By sampling from it randomly, the transitions that build up a\n","batch are decorrelated. It has been shown that this greatly stabilizes\n","and improves the DQN training procedure.\n","\n","For this, we're going to need two classes:\n","\n","-  ``Transition`` - a named tuple representing a single transition in\n","   our environment. It essentially maps (state, action) pairs\n","   to their (next_state, reward) result, with the state being the\n","   screen difference image as described later on.\n","-  ``ReplayMemory`` - a cyclic buffer of bounded size that holds the\n","   transitions observed recently. It also implements a ``.sample()``\n","   method for selecting a random batch of transitions for training.\n","\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T09:38:37.868151Z","iopub.status.busy":"2024-09-06T09:38:37.867512Z","iopub.status.idle":"2024-09-06T09:38:37.878804Z","shell.execute_reply":"2024-09-06T09:38:37.877395Z","shell.execute_reply.started":"2024-09-06T09:38:37.868115Z"},"id":"WFlJl7ZAFugK","trusted":true},"outputs":[],"source":["Transition = namedtuple('Transition',\n","                        ('state', 'action', 'next_state', 'reward'))\n","\n","\n","class ReplayMemory(object):\n","\n","    def __init__(self, capacity):\n","        self.memory = deque([], maxlen=capacity)\n","\n","    def push(self, *args):\n","        \"\"\"Save a transition\"\"\"\n","        self.memory.append(Transition(*args))\n","\n","    def sample(self, batch_size):\n","        return random.sample(self.memory, batch_size)\n","\n","    def __len__(self):\n","        return len(self.memory)"]},{"cell_type":"markdown","metadata":{"id":"jHxgRpvRFugK"},"source":["Now, let's define our model. But first, let's quickly recap what a DQN is.\n","\n","## DQN algorithm\n","\n","Our environment is deterministic, so all equations presented here are\n","also formulated deterministically for the sake of simplicity. In the\n","reinforcement learning literature, they would also contain expectations\n","over stochastic transitions in the environment.\n","\n","Our aim will be to train a policy that tries to maximize the discounted,\n","cumulative reward\n","$R_{t_0} = \\sum_{t=t_0}^{\\infty} \\gamma^{t - t_0} r_t$, where\n","$R_{t_0}$ is also known as the *return*. The discount,\n","$\\gamma$, should be a constant between $0$ and $1$\n","that ensures the sum converges. A lower $\\gamma$ makes\n","rewards from the uncertain far future less important for our agent\n","than the ones in the near future that it can be fairly confident\n","about. It also encourages agents to collect reward closer in time\n","than equivalent rewards that are temporally far away in the future.\n","\n","The main idea behind Q-learning is that if we had a function\n","$Q^*: State \\times Action \\rightarrow \\mathbb{R}$, that could tell\n","us what our return would be, if we were to take an action in a given\n","state, then we could easily construct a policy that maximizes our\n","rewards:\n","\n","\\begin{align}\\pi^*(s) = \\arg\\!\\max_a \\ Q^*(s, a)\\end{align}\n","\n","However, we don't know everything about the world, so we don't have\n","access to $Q^*$. But, since neural networks are universal function\n","approximators, we can simply create one and train it to resemble\n","$Q^*$.\n","\n","For our training update rule, we'll use a fact that every $Q$\n","function for some policy obeys the Bellman equation:\n","\n","\\begin{align}Q^{\\pi}(s, a) = r + \\gamma Q^{\\pi}(s', \\pi(s'))\\end{align}\n","\n","The difference between the two sides of the equality is known as the\n","temporal difference error, $\\delta$:\n","\n","\\begin{align}\\delta = Q(s, a) - (r + \\gamma \\max_a' Q(s', a))\\end{align}\n","\n","To minimize this error, we will use the [Huber\n","loss](https://en.wikipedia.org/wiki/Huber_loss)_. The Huber loss acts\n","like the mean squared error when the error is small, but like the mean\n","absolute error when the error is large - this makes it more robust to\n","outliers when the estimates of $Q$ are very noisy. We calculate\n","this over a batch of transitions, $B$, sampled from the replay\n","memory:\n","\n","\\begin{align}\\mathcal{L} = \\frac{1}{|B|}\\sum_{(s, a, s', r) \\ \\in \\ B} \\mathcal{L}(\\delta)\\end{align}\n","\n","\\begin{align}\\text{where} \\quad \\mathcal{L}(\\delta) = \\begin{cases}\n","     \\frac{1}{2}{\\delta^2}  & \\text{for } |\\delta| \\le 1, \\\\\n","     |\\delta| - \\frac{1}{2} & \\text{otherwise.}\n","   \\end{cases}\\end{align}\n","\n","### Q-network\n","\n","Our model will be a feed forward  neural network that takes in the\n","difference between the current and previous screen patches. It has two\n","outputs, representing $Q(s, \\mathrm{left})$ and\n","$Q(s, \\mathrm{right})$ (where $s$ is the input to the\n","network). In effect, the network is trying to predict the *expected return* of\n","taking each action given the current input.\n","\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T09:38:37.883784Z","iopub.status.busy":"2024-09-06T09:38:37.882450Z","iopub.status.idle":"2024-09-06T09:38:37.901650Z","shell.execute_reply":"2024-09-06T09:38:37.900225Z","shell.execute_reply.started":"2024-09-06T09:38:37.883726Z"},"id":"umFHM0K0FugK","trusted":true},"outputs":[],"source":["class DQN(nn.Module):\n","\n","    def __init__(self, in_channels, n_actions):\n","        super(DQN, self).__init__()\n","        # One hidden 2D convolution layer:\n","        #   in_channels: variable\n","        #   out_channels: 16\n","        #   kernel_size: 3 of a 3x3 filter matrix\n","        #   stride: 1\n","        self.conv = nn.Conv2d(in_channels, 16, kernel_size=3, stride=1)\n","        # Final fully connected hidden layer:\n","        #   the number of linear unit depends on the output of the conv\n","        #   the output consist 128 rectified units\n","        def size_linear_unit(size, kernel_size=3, stride=1):\n","            return (size - (kernel_size - 1) - 1) // stride + 1\n","        num_linear_units = size_linear_unit(10) * size_linear_unit(10) * 16\n","        self.fc_hidden = nn.Linear(in_features=num_linear_units, out_features=128)\n","        \n","        self.output = nn.Linear(in_features=128, out_features=n_actions)\n","        \n","#         self.layer1 = nn.Linear(n_observations, 128)\n","#         self.layer2 = nn.Linear(128,128)\n","# #         self.layer3 = nn.Linear(128,128)\n","#         # self.layer4 = nn.Linear(128,128)\n","#         self.layer4 = nn.Linear(128, n_actions)\n","        \n","        \n","\n","    # As per implementation instructions according to pytorch, the forward function should be overwritten by all\n","    # subclasses\n","    def forward(self, x):\n","        # Rectified output from the first conv layer\n","        x = f.relu(self.conv(x))\n","\n","        # Rectified output from the final hidden layer\n","        x = f.relu(self.fc_hidden(x.view(x.size(0), -1)))\n","\n","        # Returns the output from the fully-connected linear layer\n","        return self.output(x)\n","\n","\n","    # Called with either one element to determine next action, or a batch\n","    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n","#     def forward(self, x):\n","#         x = F.relu(self.layer1(x))\n","#         x = F.relu(self.layer2(x))\n","# #         x = F.relu(self.layer3(x))\n","#         # x = F.relu(self.layer4(x))\n","#         return self.layer4(x)\n","\n","#     def forward_correlation(self, x):\n","#         x = F.relu(self.layer1(x))\n","# #         x = F.relu(self.layer2(x))\n","# #         x = F.relu(self.layer3(x))\n","#         # x = F.relu(self.layer4(x))\n","#         return F.relu(self.layer2(x))\n","\n","    def forward_correlation(self, x):\n","     # Rectified output from the first conv layer\n","        x = f.relu(self.conv(x))\n","\n","        # Rectified output from the final hidden layer\n","        return f.relu(self.fc_hidden(x.view(x.size(0), -1)))"]},{"cell_type":"markdown","metadata":{"id":"Geq4Fg3jFugK"},"source":["## Training\n","\n","### Hyperparameters and utilities\n","This cell instantiates our model and its optimizer, and defines some\n","utilities:\n","\n","-  ``select_action`` - will select an action accordingly to an epsilon\n","   greedy policy. Simply put, we'll sometimes use our model for choosing\n","   the action, and sometimes we'll just sample one uniformly. The\n","   probability of choosing a random action will start at ``EPS_START``\n","   and will decay exponentially towards ``EPS_END``. ``EPS_DECAY``\n","   controls the rate of the decay.\n","-  ``plot_durations`` - a helper for plotting the duration of episodes,\n","   along with an average over the last 100 episodes (the measure used in\n","   the official evaluations). The plot will be underneath the cell\n","   containing the main training loop, and will update after every\n","   episode.\n","\n","\n"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T15:46:14.556932Z","iopub.status.busy":"2024-09-06T15:46:14.556247Z","iopub.status.idle":"2024-09-06T15:46:14.910189Z","shell.execute_reply":"2024-09-06T15:46:14.908619Z","shell.execute_reply.started":"2024-09-06T15:46:14.556884Z"},"id":"TPPr8pR6FugL","trusted":true},"outputs":[],"source":["# BATCH_SIZE is the number of transitions sampled from the replay buffer\n","# GAMMA is the discount factor as mentioned in the previous section\n","# EPS_START is the starting value of epsilon\n","# EPS_END is the final value of epsilon\n","# EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n","# TAU is the update rate of the target network\n","# LR is the learning rate of the ``AdamW`` optimizer\n","BATCH_SIZE = 64\n","GAMMA = 0.99\n","EPS_START = 0.9\n","EPS_END = 0.05\n","EPS_DECAY = 1000\n","TAU = 0.005\n","LR = 1e-3\n","\n","# Get number of actions from gym action space\n","n_actions = env.num_actions()\n","in_channels = env.state_shape()[2]\n","\n","# Get the number of state observations\n","# state, info = env.reset()\n","\n","policy_net = DQN(in_channels, n_actions).to(device)\n","target_net = DQN(in_channels, n_actions).to(device)\n","target_net.load_state_dict(policy_net.state_dict())\n","\n","# optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n","optimizer = optim.Adam(policy_net.parameters(), lr = LR)\n","# faster_lr = 1e-3\n","# slower_lr = 1e-3\n","\n","###  CHANGE THISSSSSS\n","# slower_lr = 1e-3\n","\n","# # Create separate parameter groups for layers 1-3 and layer 4\n","# slower_params = list(map(id, policy_net.layer1.parameters() + policy_net.layer2.parameters() + policy_net.layer3.parameters()))\n","# faster_params = list(map(id, policy_net.layer4.parameters()))\n","\n","# # Create an optimizer with different learning rates for each parameter group\n","# optimizer = optim.AdamW(\n","#     [\n","#         {\"params\": [p for p in policy_net.parameters() if id(p) in faster_params], \"lr\": faster_lr},\n","#         {\"params\": [p for p in policy_net.parameters() if id(p) in slower_params], \"lr\": slower_lr},\n","#     ]\n","# )\n","\n","# params = [\n","#     {'params': policy_net.layer1.parameters(), 'lr':slower_lr },\n","#     {'params': policy_net.layer2.parameters(), 'lr': slower_lr},\n","# #     {'params': policy_net.layer3.parameters(), 'lr': slower_lr},  # Last two layers\n","#     {'params': policy_net.layer4.parameters(), 'lr': faster_lr},  # Last two layers\n","# ]\n","\n","# Define your optimizer with different learning rates for each parameter group\n","# optimizer = optim.Adam(params)\n","\n","\n","\n","memory = ReplayMemory(50000)\n","\n","\n","steps_done = 0\n","\n","\n","def select_action(state):\n","    global steps_done\n","    sample = random.random()\n","    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n","        math.exp(-1. * steps_done / EPS_DECAY)\n","    steps_done += 1\n","    if sample > eps_threshold:\n","        with torch.no_grad():\n","            # t.max(1) will return the largest column value of each row.\n","            # second column on max result is index of where max element was\n","            # found, so we pick action with the larger expected reward.\n","            return policy_net(state).max(1).indices.view(1, 1)\n","    else:\n","        return torch.tensor([[random.randrange(n_actions)]], device=device)\n","\n","\n","episode_durations = []\n","\n","\n","def plot_durations(show_result=False):\n","    plt.figure(1)\n","    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n","    if show_result:\n","        plt.title('Result')\n","    else:\n","        plt.clf()\n","        plt.title('Training...')\n","    plt.xlabel('Episode')\n","    plt.ylabel('Duration')\n","    plt.plot(durations_t.numpy())\n","    # Take 100 episode averages and plot them too\n","    if len(durations_t) >= 100:\n","        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n","        means = torch.cat((torch.zeros(99), means))\n","        plt.plot(means.numpy())\n","\n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","    if is_ipython:\n","        if not show_result:\n","            display.display(plt.gcf())\n","            display.clear_output(wait=True)\n","        else:\n","            display.display(plt.gcf())"]},{"cell_type":"markdown","metadata":{"id":"9A1xqvpZFugL"},"source":["### Training loop\n","\n","Finally, the code for training our model.\n","\n","Here, you can find an ``optimize_model`` function that performs a\n","single step of the optimization. It first samples a batch, concatenates\n","all the tensors into a single one, computes $Q(s_t, a_t)$ and\n","$V(s_{t+1}) = \\max_a Q(s_{t+1}, a)$, and combines them into our\n","loss. By definition we set $V(s) = 0$ if $s$ is a terminal\n","state. We also use a target network to compute $V(s_{t+1})$ for\n","added stability. The target network is updated at every step with a\n","[soft update](https://arxiv.org/pdf/1509.02971.pdf)_ controlled by\n","the hyperparameter ``TAU``, which was previously defined.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Y8VdiiKxigRg"},"source":["K means and then sampling from those clusters\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T09:38:39.679693Z","iopub.status.busy":"2024-09-06T09:38:39.679075Z","iopub.status.idle":"2024-09-06T09:38:39.686371Z","shell.execute_reply":"2024-09-06T09:38:39.684679Z","shell.execute_reply.started":"2024-09-06T09:38:39.679658Z"},"trusted":true},"outputs":[],"source":["def get_state(s):\n","    return (torch.tensor(s, device=device).permute(2, 0, 1)).unsqueeze(0).float()"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-09-06T15:46:19.306936Z","iopub.status.busy":"2024-09-06T15:46:19.306430Z","iopub.status.idle":"2024-09-06T15:46:21.034370Z","shell.execute_reply":"2024-09-06T15:46:21.032557Z","shell.execute_reply.started":"2024-09-06T15:46:19.306894Z"},"id":"6mu4iEHyife-","outputId":"5336272e-5ae5-44e5-9e78-dfadd329795f","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/scl/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n"]}],"source":["\n","from sklearn.cluster import KMeans\n","\n","# Create your Gym environment\n","# env = gym.make('YourEnvNameHere')\n","\n","# Define the number of clusters (bins)\n","k = 25\n","# k=10\n","# k=50\n","\n","# Initialize an empty list to store the clustered states\n","clustered_states = []\n","\n","# Reset the environment to get the initial state\n","state = env.reset()\n","\n","# Initialize an empty list to store all states\n","all_states = []\n","\n","# Collect a bunch of states from the environment\n","for _ in range(2000):  # You can adjust the number of samples as needed\n","    action = random.randrange(env.num_actions())\n","    # print(env.step(action))\n","    _, done = env.act(action)\n","    state = env.state().reshape(-1,)\n","    all_states.append(state)\n","    if done:\n","        state = env.reset()\n","\n","# Convert the list of states into a numpy array\n","all_states = np.array(all_states)\n","\n","# Perform K-means clustering\n","kmeans = KMeans(n_clusters=k, random_state=0).fit(all_states)\n","# Get the indices of states belonging to each cluster\n","cluster_indices = [np.where(kmeans.labels_ == i)[0] for i in range(k)]\n","\n","# Sample a random state from each cluster\n","# print(cluster_indices)\n","# Print the sampled states from each cluster\n","# for i, sampled_state in enumerate(clustered_states):\n","#     print(f\"Sampled state from cluster {i+1}: {sampled_state}\")\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T09:38:47.114543Z","iopub.status.busy":"2024-09-06T09:38:47.114018Z","iopub.status.idle":"2024-09-06T09:38:47.125520Z","shell.execute_reply":"2024-09-06T09:38:47.124225Z","shell.execute_reply.started":"2024-09-06T09:38:47.114507Z"},"id":"P02goxQG8Xew","trusted":true},"outputs":[],"source":["import math\n","def call_correlation_coeff_kmeans():\n","\n","    state_vector = []\n","    for indices in cluster_indices:\n","    # Randomly select an index from the cluster\n","      sampled_index = np.random.choice(indices)\n","      # Get the corresponding state\n","      sampled_state = get_state(all_states[sampled_index].reshape(env.state().shape))\n","      # Add the sampled state to the list\n","      state_vector.append(policy_net.forward_correlation(sampled_state))\n","      # state_vector.append(sampled_state)\n","\n","    stacked_tensor = torch.stack(state_vector)\n","    reshaped_tensor = stacked_tensor.reshape(len(state_vector), -1)\n","    correlation_matrix = torch.corrcoef(reshaped_tensor)\n","#     print(correlation_matrix)\n","    correlation_values = torch.masked_select(correlation_matrix, torch.triu(torch.ones_like(correlation_matrix), diagonal=1).bool())\n","    # print(state_vector)\n","    # Average correlation across all pairs of tensor vectors\n","    average_correlation = correlation_values.mean()\n","    if math.isnan(average_correlation): \n","#         print(\"nan-correlation\")\n","        return 0\n","    return average_correlation"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-09-06T15:46:23.682716Z","iopub.status.busy":"2024-09-06T15:46:23.682181Z","iopub.status.idle":"2024-09-06T15:46:23.708371Z","shell.execute_reply":"2024-09-06T15:46:23.706812Z","shell.execute_reply.started":"2024-09-06T15:46:23.682665Z"},"id":"AivVdWiHWMlT","outputId":"2e1b9978-e145-4463-e01d-c80a2282a32c","trusted":true},"outputs":[{"data":{"text/plain":["tensor(0.9301, device='cuda:0', grad_fn=<MeanBackward0>)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["call_correlation_coeff_kmeans()"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T14:19:05.001327Z","iopub.status.busy":"2024-09-06T14:19:05.000557Z","iopub.status.idle":"2024-09-06T14:19:05.021084Z","shell.execute_reply":"2024-09-06T14:19:05.018981Z","shell.execute_reply.started":"2024-09-06T14:19:05.001283Z"},"id":"OTqRsgdgFugL","trusted":true},"outputs":[],"source":["# import pickle\n","# from torch.autograd import Variable\n","# global corr_mult \n","# corr_mult =1\n","\n","# def optimize_model():\n","#     if not hasattr(optimize_model, \"count\"):\n","#         optimize_model.count = 0\n","\n","#     optimize_model.count += 1\n","\n","\n","\n","#     if len(memory) < BATCH_SIZE:\n","#         return\n","#     transitions = memory.sample(BATCH_SIZE)\n","#     # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n","#     # detailed explanation). This converts batch-array of Transitions\n","#     # to Transition of batch-arrays.\n","#     batch = Transition(*zip(*transitions))\n","\n","#     # Compute a mask of non-final states and concatenate the batch elements\n","#     # (a final state would've been the one after which simulation ended)\n","#     non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n","#                                           batch.next_state)), device=device, dtype=torch.bool)\n","#     non_final_next_states = torch.cat([s for s in batch.next_state\n","#                                                 if s is not None])\n","#     state_batch = torch.cat(batch.state)\n","#     action_batch = torch.cat(batch.action)\n","#     reward_batch = torch.cat(batch.reward)\n","\n","#     # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n","#     # columns of actions taken. These are the actions which would've been taken\n","#     # for each batch state according to policy_net\n","#     # print(\"works until here\")\n","#     state_action_values = policy_net(state_batch).gather(1, action_batch)\n","#     # print(state_batch[0])\n","#     # print(\"policy\"  + str(state_action_values[0]))\n","\n","\n","#     # Compute V(s_{t+1}) for all next states.\n","#     # Expected values of actions for non_final_next_states are computed based\n","#     # on the \"older\" target_net; selecting their best reward with max(1).values\n","#     # This is merged based on the mask, such that we'll have either the expected\n","#     # state value or 0 in case the state was final.\n","#     next_state_values = torch.zeros(BATCH_SIZE, device=device)\n","#     with torch.no_grad():\n","#         next_state_values[non_final_mask] = target_net(non_final_next_states).max(1).values\n","#     # Compute the expected Q values\n","#     expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n","#     # print(reward_batch)\n","#     # print(\"expected\" + str(expected_state_action_values[0]))\n","\n","#     # Compute Huber loss\n","#     criterion = nn.SmoothL1Loss()\n","#     loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n","#     # print(loss)\n","#     # if (optimize_model.count % 60 == 0): print(loss)\n","#     # print(loss)\n","\n","#     # loss = Variable(loss, requires_grad = True)\n","\n","#     # with torch.no_grad():\n","#     correlation_coeff = call_correlation_coeff_kmeans()\n","#     # print(correlation_coeff)\n","\n","#     # Define regularization strength\n","\n","#     # For LUNAAAA\n","#     lambda_corr = 0.1 # You can adjust this parameter as needed\n","\n","#     #for ACROOOO\n","#     lambda_corr = 0.1\n","# #     print(loss, correlation_coeff)\n","\n","#      #for Mountyainnnnn\n","    \n","# #     corr_mult = 1\n","#     lambda_corr = 1 - corr_mult\n","# #     lambda_corr = 0.1\n","# #     print(loss, correlation_coeff)\n","# #     print(lambda_corr)\n","#     # Add correlation coefficient regularization term to the loss\n","#     loss += (min(0.01,lambda_corr) * correlation_coeff) #(lambda_corr* correlation_coeff)\n","# #     print(loss)\n","#     # Optimize the model\n","#     optimizer.zero_grad()\n","#     loss.backward()\n","#     # In-place gradient clipping\n","# #     torch.nn.utils.clip_grad_value_(policy_net.parameters(), 1)\n","#     optimizer.step()\n","#     # return correlation_coeff"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T15:46:27.915795Z","iopub.status.busy":"2024-09-06T15:46:27.914569Z","iopub.status.idle":"2024-09-06T15:46:27.932289Z","shell.execute_reply":"2024-09-06T15:46:27.930884Z","shell.execute_reply.started":"2024-09-06T15:46:27.915747Z"},"trusted":true},"outputs":[],"source":["# For plain dqn\n","import pickle\n","from torch.autograd import Variable\n","global corr_mult \n","corr_mult =1\n","def optimize_model():\n","    if not hasattr(optimize_model, \"count\"):\n","        optimize_model.count = 0\n","\n","    optimize_model.count += 1\n","\n","\n","\n","    if len(memory) < BATCH_SIZE:\n","        return\n","    transitions = memory.sample(BATCH_SIZE)\n","    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n","    # detailed explanation). This converts batch-array of Transitions\n","    # to Transition of batch-arrays.\n","    batch = Transition(*zip(*transitions))\n","\n","    # Compute a mask of non-final states and concatenate the batch elements\n","    # (a final state would've been the one after which simulation ended)\n","    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n","                                          batch.next_state)), device=device, dtype=torch.bool)\n","    non_final_next_states = torch.cat([s for s in batch.next_state\n","                                                if s is not None])\n","    state_batch = torch.cat(batch.state)\n","    action_batch = torch.cat(batch.action)\n","    reward_batch = torch.cat(batch.reward)\n","\n","    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n","    # columns of actions taken. These are the actions which would've been taken\n","    # for each batch state according to policy_net\n","    # print(\"works until here\")\n","    state_action_values = policy_net(state_batch).gather(1, action_batch)\n","    # print(state_batch[0])\n","    # print(\"policy\"  + str(state_action_values[0]))\n","\n","\n","    # Compute V(s_{t+1}) for all next states.\n","    # Expected values of actions for non_final_next_states are computed based\n","    # on the \"older\" target_net; selecting their best reward with max(1).values\n","    # This is merged based on the mask, such that we'll have either the expected\n","    # state value or 0 in case the state was final.\n","    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n","    with torch.no_grad():\n","        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1).values\n","    # Compute the expected Q values\n","    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n","    # print(reward_batch)\n","    # print(\"expected\" + str(expected_state_action_values[0]))\n","\n","    # Compute Huber loss\n","    criterion = nn.SmoothL1Loss()\n","    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n","\n","    correlation_coeff = call_correlation_coeff_kmeans()\n","    # print(loss)\n","    # if (optimize_model.count % 60 == 0): print(loss)\n","    # print(loss)\n","\n","    # loss = Variable(loss, requires_grad = True)\n","\n","    \n","#     print(loss)\n","    # Optimize the model\n","    optimizer.zero_grad()\n","    loss.backward()\n","    # In-place gradient clipping\n","#     torch.nn.utils.clip_grad_value_(policy_net.parameters(), 1)\n","    optimizer.step()\n","    return correlation_coeff"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T15:46:30.982185Z","iopub.status.busy":"2024-09-06T15:46:30.981617Z","iopub.status.idle":"2024-09-06T15:48:57.705345Z","shell.execute_reply":"2024-09-06T15:48:57.703934Z","shell.execute_reply.started":"2024-09-06T15:46:30.982147Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1 tensor(0.9318, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.001998999999999973 0.5\n","2 tensor(0.9322, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.002997000999999999 0.3333333333333333\n","3 tensor(0.9331, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.003994003998999962 0.25\n","4 tensor(0.9317, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.004990009995000988 0.2\n","5 tensor(0.9308, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.0059850199850060015 0.16666666666666666\n","6 tensor(0.9251, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.006979034965020947 0.14285714285714285\n","7 tensor(0.9887, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.007972055930055899 0.25\n","8 tensor(0.9716, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.008964083874125839 0.2222222222222222\n","9 tensor(0.9688, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.009955119790251765 0.2\n","10 tensor(0.9596, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.010945164670461471 0.2\n","11 tensor(0.9265, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.011934219505790988 0.3\n","12 tensor(0.9280, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.012922285286285251 0.3\n","13 tensor(0.9128, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.013909363000998987 0.3\n","14 tensor(0.9357, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.014895453637997935 0.4\n","15 tensor(0.9293, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.01588055818435996 0.4\n","16 tensor(0.9250, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.016864677626175606 0.4\n","17 tensor(0.9502, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.017847812948549424 0.3\n","18 tensor(0.9004, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.018829965135600868 0.4\n","19 tensor(0.9112, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.01981113517046529 0.6\n","20 tensor(0.9061, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.020791324035294823 0.6\n","21 tensor(0.8978, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.021770532711259505 0.5\n","22 tensor(0.9279, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.022748762178548265 0.5\n","23 tensor(0.9239, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.023726013416369707 0.6\n","24 tensor(0.9042, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.024702287402953327 0.8\n","25 tensor(0.8618, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.025677585115550405 0.8\n","26 tensor(0.8638, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.026651907530434893 0.8\n","27 tensor(0.8671, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.02762525562290441 0.8\n","28 tensor(0.8669, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.028597630367281468 0.7\n","29 tensor(0.8845, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.029569032736914136 0.6\n","30 tensor(0.9079, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.03053946370417726 0.7\n","31 tensor(0.8450, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.031508924240473135 0.6\n","32 tensor(0.8725, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.032477415316232716 0.7\n","33 tensor(0.8615, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.033444937900916516 0.6\n","34 tensor(0.8746, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.0344114929630156 0.3\n","35 tensor(0.8772, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.035377081470052585 0.5\n","36 tensor(0.8340, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.03634170438858253 0.7\n","37 tensor(0.8948, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.03730536268419393 0.8\n","38 tensor(0.8673, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.03826805732150973 0.8\n","39 tensor(0.8822, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.039229789264188186 0.8\n","40 tensor(0.8718, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.040190559474924004 0.7\n","41 tensor(0.8693, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.0411503689154491 0.7\n","42 tensor(0.8316, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.0421092185465336 0.6\n","43 tensor(0.8381, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.043067109327987074 0.7\n","44 tensor(0.8442, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.044024042218659076 0.7\n","45 tensor(0.8850, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.04498001817644037 0.6\n","46 tensor(0.8419, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.04593503815826394 0.4\n","47 tensor(0.8570, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.046889103120105635 0.3\n","48 tensor(0.8469, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.04784221401698552 0.4\n","49 tensor(0.8660, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.04879437180296853 0.3\n","50 tensor(0.8518, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.04974557743116559 0.4\n","51 tensor(0.8464, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.050695831853734385 0.5\n","52 tensor(0.8313, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.0516451360218807 0.5\n","53 tensor(0.8101, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.05259349088585885 0.6\n","54 tensor(0.8462, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.05354089739497303 0.7\n","55 tensor(0.8185, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.05448735649757808 0.6\n","56 tensor(0.8347, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.055432869141080476 0.7\n","57 tensor(0.8302, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.05637743627193936 0.8\n","58 tensor(0.8503, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.057321058835667404 0.7\n","59 tensor(0.8493, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.05826373777683169 0.8\n","60 tensor(0.8447, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.05920547403905485 0.8\n","61 tensor(0.8200, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.060146268565015815 0.7\n","62 tensor(0.8207, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.06108612229645083 0.8\n","63 tensor(0.8067, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.062025036174154335 0.6\n","64 tensor(0.8092, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.0629630111379802 0.8\n","65 tensor(0.8115, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.06390004812684225 0.9\n","66 tensor(0.8208, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.0648361480787154 0.8\n","67 tensor(0.8175, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.06577131193063668 0.8\n","68 tensor(0.7927, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.06670554061870604 1.1\n","69 tensor(0.7843, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.06763883507808732 1.0\n","70 tensor(0.7745, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.06857119624300922 1.0\n","71 tensor(0.7793, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.06950262504676619 1.2\n","72 tensor(0.7727, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.0704331224217194 1.2\n","73 tensor(0.7695, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.07136268929929768 1.3\n","74 tensor(0.7414, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.07229132660999837 1.0\n","75 tensor(0.7785, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.07321903528338836 1.0\n","76 tensor(0.7269, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.07414581624810501 1.3\n","77 tensor(0.7024, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.07507167043185692 1.6\n","78 tensor(0.7215, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.07599659876142506 1.4\n","79 tensor(0.7431, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.07692060216266361 1.4\n","80 tensor(0.7341, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.07784368156050092 1.3\n","81 tensor(0.7197, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.07876583787894043 1.4\n","82 tensor(0.7466, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.07968707204106151 1.4\n","83 tensor(0.7262, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.08060738496902042 1.6\n","84 tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.08152677758405136 1.9\n","85 tensor(0.6779, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.08244525080646725 1.9\n","86 tensor(0.7295, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.08336280555566078 1.9\n","87 tensor(0.7024, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.08427944275010513 1.6\n","88 tensor(0.6847, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.08519516330735499 1.6\n","89 tensor(0.7087, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.08610996814404759 1.7\n","90 tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.08702385817590352 2.0\n","91 tensor(0.7041, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.08793683431772759 1.8\n","92 tensor(0.6964, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.08884889748340985 1.7\n","93 tensor(0.6536, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.08976004858592646 1.5\n","94 tensor(0.6719, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.0906702885373405 1.3\n","95 tensor(0.6552, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.09157961824880312 1.2\n","96 tensor(0.6769, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.09248803863055433 1.4\n","97 tensor(0.6481, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.09339555059192373 1.7\n","98 tensor(0.6849, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.09430215504133177 1.9\n","99 tensor(0.6407, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.09520785288629041 1.9\n","100 tensor(0.6796, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.09611264503340411 1.7\n","101 tensor(0.6330, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.09701653238837071 1.9\n","102 tensor(0.6828, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.09791951585598235 2.0\n","103 tensor(0.7198, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.09882159634012633 1.9\n","104 tensor(0.6541, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.09972277474378621 2.1\n","105 tensor(0.6783, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.10062305196904242 2.2\n","106 tensor(0.6756, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.10152242891707342 1.7\n","107 tensor(0.6897, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.10242090648815638 1.5\n","108 tensor(0.7014, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.10331848558166823 1.3\n","109 tensor(0.6443, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.10421516709608658 1.3\n","110 tensor(0.6567, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.10511095192899045 1.4\n","111 tensor(0.5969, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.10600584097706145 1.7\n","112 tensor(0.6941, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.10689983513608436 1.8\n","113 tensor(0.6628, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.10779293530094824 1.9\n","114 tensor(0.7205, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.1086851423656473 1.7\n","115 tensor(0.6323, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.10957645722328169 1.7\n","116 tensor(0.6730, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.11046688076605837 1.7\n","117 tensor(0.6223, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.11135641388529227 1.7\n","118 tensor(0.6824, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.112245057471407 2.1\n","119 tensor(0.6816, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.11313281241393558 2.2\n","120 tensor(0.6548, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.1140196796015216 2.3\n","121 tensor(0.6507, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.11490565992192003 1.8\n","122 tensor(0.6786, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.11579075426199814 1.6\n","123 tensor(0.7028, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.1166749635077361 1.5\n","124 tensor(0.7037, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.11755828854422834 1.6\n","125 tensor(0.6441, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.11844073025568413 1.7\n","126 tensor(0.6484, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.11932228952542845 1.9\n","127 tensor(0.6761, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.12020296723590307 1.7\n","128 tensor(0.6817, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.12108276426866715 1.3\n","129 tensor(0.6319, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.12196168150439846 1.3\n","130 tensor(0.6791, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.1228397198228941 1.1\n","131 tensor(0.6418, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.12371688010307125 1.1\n","132 tensor(0.6362, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.1245931632229682 1.3\n","133 tensor(0.6217, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.1254685700597452 1.4\n","134 tensor(0.6402, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.12634310148968542 1.4\n","135 tensor(0.5950, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.12721675838819568 1.5\n","136 tensor(0.6627, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.12808954162980746 1.5\n","137 tensor(0.6947, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.12896145208817766 1.5\n","138 tensor(0.6211, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.12983249063608948 1.5\n","139 tensor(0.6794, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.13070265814545334 1.4\n","140 tensor(0.5940, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.13157195548730793 1.6\n","141 tensor(0.6821, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.13244038353182064 1.7\n","142 tensor(0.6434, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.13330794314828887 1.8\n","143 tensor(0.6107, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.1341746352051406 1.9\n","144 tensor(0.6038, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.13504046056993546 1.9\n","145 tensor(0.5834, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.13590542010936557 1.7\n","146 tensor(0.5990, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.13676951468925624 1.6\n","147 tensor(0.5634, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.13763274517456703 1.9\n","148 tensor(0.5800, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.1384951124293925 1.9\n","149 tensor(0.5587, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.13935661731696314 2.1\n","150 tensor(0.5847, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.14021726069964613 1.9\n","151 tensor(0.6483, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.14107704343894645 1.7\n","152 tensor(0.5879, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.14193596639550754 1.7\n","153 tensor(0.6587, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.14279403042911198 1.6\n","154 tensor(0.6580, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.14365123639868282 1.8\n","155 tensor(0.6214, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.14450758516228412 2.1\n","156 tensor(0.6719, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.14536307757712186 2.1\n","157 tensor(0.6551, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.14621771449954468 2.1\n","158 tensor(0.6069, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.14707149678504516 2.4\n","159 tensor(0.6461, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.1479244252882601 2.5\n","160 tensor(0.6051, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.1487765008629719 2.5\n","161 tensor(0.6343, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.14962772436210892 2.7\n","162 tensor(0.6247, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.1504780966377468 2.6\n","163 tensor(0.5778, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.1513276185411091 3.0\n","164 tensor(0.5878, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.152176290922568 2.8\n","165 tensor(0.5963, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.15302411463164545 2.9\n","166 tensor(0.6092, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.15387109051701375 2.9\n","167 tensor(0.5382, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.15471721942649674 2.8\n","168 tensor(0.5740, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.15556250220707024 2.8\n","169 tensor(0.5936, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.1564069397048632 2.7\n","170 tensor(0.5578, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.15725053276515832 3.1\n","171 tensor(0.6100, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.15809328223239316 3.2\n","172 tensor(0.5969, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.1589351889501608 3.5\n","173 tensor(0.6475, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.15977625376121063 3.2\n","174 tensor(0.5599, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.16061647750744945 3.0\n","175 tensor(0.5699, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.16145586102994203 2.8\n","176 tensor(0.5906, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.16229440516891214 3.0\n","177 tensor(0.5723, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.16313211076374323 3.1\n","178 tensor(0.5547, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.16396897865297944 3.1\n","179 tensor(0.5687, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.16480500967432643 3.4\n","180 tensor(0.5391, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.16564020466465212 3.2\n","181 tensor(0.5887, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.16647456445998743 3.0\n","182 tensor(0.5871, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.16730808989552748 2.5\n","183 tensor(0.5686, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.16814078180563197 2.4\n","184 tensor(0.5694, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.16897264102382636 2.7\n","185 tensor(0.5707, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.1698036683828026 2.7\n","186 tensor(0.5904, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.17063386471441977 2.7\n","187 tensor(0.6106, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.17146323084970538 2.8\n","188 tensor(0.5849, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.17229176761885567 3.0\n","189 tensor(0.6293, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.17311947585123677 2.8\n","190 tensor(0.5718, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.17394635637538558 2.9\n","191 tensor(0.5861, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.17477241001901023 3.0\n","192 tensor(0.6495, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.17559763760899116 3.7\n","193 tensor(0.5712, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.17642203997138217 3.7\n","194 tensor(0.5662, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.1772456179314108 3.5\n","195 tensor(0.6000, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.17806837231347938 3.4\n","196 tensor(0.5773, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.1788903039411659 3.5\n","197 tensor(0.5959, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.17971141363722476 3.5\n","198 tensor(0.6386, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.1805317022235875 3.2\n","199 tensor(0.5722, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.18135117052136396 3.2\n","200 tensor(0.5896, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.18216981935084264 3.2\n","201 tensor(0.6109, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.18298764953149182 3.2\n","202 tensor(0.6082, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.18380466188196032 2.5\n","203 tensor(0.5917, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.18462085722007837 2.4\n","204 tensor(0.5836, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.18543623636285833 2.7\n","205 tensor(0.5967, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.18625080012649542 3.0\n","206 tensor(0.5923, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.18706454932636896 2.9\n","207 tensor(0.5689, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.18787748477704258 2.7\n","208 tensor(0.5626, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.18868960729226558 3.0\n","209 tensor(0.5455, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.18950091768497335 2.9\n","210 tensor(0.5945, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.19031141676728835 2.9\n","211 tensor(0.6384, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.19112110535052107 3.1\n","212 tensor(0.6110, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.1919299842451706 3.5\n","213 tensor(0.6458, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.19273805426092538 3.9\n","214 tensor(0.5815, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.19354531620666449 3.5\n","215 tensor(0.5436, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.19435177089045785 3.4\n","216 tensor(0.5585, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.1951574191195674 3.7\n","217 tensor(0.6193, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.19596226170044784 3.8\n","218 tensor(0.5860, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.19676629943874735 3.5\n","219 tensor(0.5700, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.19756953313930858 3.3\n","220 tensor(0.6894, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.19837196360616927 3.1\n","221 tensor(0.5532, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.1991735916425631 3.0\n","222 tensor(0.6092, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.19997441805092053 2.9\n","223 tensor(0.6394, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.20077444363286956 2.9\n","224 tensor(0.6797, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.2015736691892367 3.1\n","225 tensor(0.5852, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.20237209552004742 3.1\n","226 tensor(0.5269, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.20316972342452733 2.5\n","227 tensor(0.5467, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.20396655370110284 2.5\n","228 tensor(0.5508, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.2047625871474017 2.6\n","229 tensor(0.5288, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.2055578245602543 3.1\n","230 tensor(0.5682, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.20635226673569407 3.0\n","231 tensor(0.5722, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.20714591446895836 3.0\n","232 tensor(0.5557, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.20793876855448945 3.3\n","233 tensor(0.5920, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.20873082978593493 3.1\n","234 tensor(0.5817, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.20952209895614904 3.4\n","235 tensor(0.6297, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.21031257685719285 3.6\n","236 tensor(0.5588, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.21110226428033563 4.0\n","237 tensor(0.6107, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.2118911620160553 4.1\n","238 tensor(0.5922, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.21267927085403926 3.8\n","239 tensor(0.5613, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.21346659158318526 3.3\n","240 tensor(0.5801, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.2142531249916021 3.8\n","241 tensor(0.5754, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.21503887186661053 4.0\n","242 tensor(0.5415, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.21582383299474395 3.9\n","243 tensor(0.5792, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.21660800916174916 4.1\n","244 tensor(0.6093, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.21739140115258737 4.1\n","245 tensor(0.5758, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.21817400975143475 3.9\n","246 tensor(0.5255, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.2189558357416833 3.8\n","247 tensor(0.5482, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.2197368799059416 3.8\n","248 tensor(0.6434, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.22051714302603564 3.8\n","249 tensor(0.5246, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.22129662588300958 4.1\n","250 tensor(0.5117, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.22207532925712659 3.8\n","251 tensor(0.6423, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.22285325392786948 3.4\n","252 tensor(0.5830, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.22363040067394158 3.2\n","253 tensor(0.6187, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.2244067702732676 2.9\n","254 tensor(0.5824, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.22518236350299436 2.5\n","255 tensor(0.5754, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.22595718113949137 2.2\n","256 tensor(0.4928, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.22673122395835188 1.9\n","257 tensor(0.6250, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.22750449273439355 1.9\n","258 tensor(0.5766, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.2282769882416592 2.1\n","259 tensor(0.5909, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.22904871125341753 2.2\n","260 tensor(0.5618, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.22981966254216413 2.0\n","261 tensor(0.4983, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.23058984287962192 2.5\n","262 tensor(0.5838, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.23135925303674232 2.5\n","263 tensor(0.4942, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.23212789378370557 3.1\n","264 tensor(0.5501, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2328957658899219 3.0\n","265 tensor(0.4965, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.23366287012403197 3.5\n","266 tensor(0.5462, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.23442920725390792 3.8\n","267 tensor(0.5708, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.235194778046654 3.9\n","268 tensor(0.6189, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.23595958326860733 4.1\n","269 tensor(0.5725, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.23672362368533872 3.7\n","270 tensor(0.4922, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.2374869000616534 3.9\n","271 tensor(0.5452, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.23824941316159176 3.6\n","272 tensor(0.6591, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.23901116374843012 3.5\n","273 tensor(0.4694, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.23977215258468165 3.2\n","274 tensor(0.5844, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.24053238043209701 3.7\n","275 tensor(0.5997, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.24129184805166493 3.6\n","276 tensor(0.5409, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.24205055620361327 3.7\n","277 tensor(0.5921, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.24280850564740963 3.4\n","278 tensor(0.5025, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.24356569714176224 3.3\n","279 tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.24432213144462045 3.8\n","280 tensor(0.5290, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.2450778093131758 3.7\n","281 tensor(0.5606, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.24583273150386264 3.7\n","282 tensor(0.5622, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.24658689877235873 3.6\n","283 tensor(0.4735, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.2473403118735864 3.3\n","284 tensor(0.5782, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.24809297156171284 3.0\n","285 tensor(0.5620, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.24884487859015114 3.1\n","286 tensor(0.5283, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.24959603371156103 3.0\n","287 tensor(0.5225, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.2503464376778495 3.1\n","288 tensor(0.5862, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.2510960912401716 3.0\n","289 tensor(0.4586, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.25184499514893144 2.9\n","290 tensor(0.6371, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.2525931501537825 3.0\n","291 tensor(0.5335, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.2533405570036287 3.1\n","292 tensor(0.5560, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.254087216446625 3.1\n","293 tensor(0.5954, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.2548331292301784 3.4\n","294 tensor(0.6191, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.2555782961009483 3.4\n","295 tensor(0.5651, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.2563227178048474 3.5\n","296 tensor(0.5178, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.25706639508704254 3.5\n","297 tensor(0.5623, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.2578093286919555 3.5\n","298 tensor(0.5981, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.2585515193632636 3.3\n","299 tensor(0.5551, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.2592929678439003 3.3\n","300 tensor(0.5300, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.26003367487605644 3.3\n","301 tensor(0.5813, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.2607736412011804 3.2\n","302 tensor(0.5052, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.26151286755997927 3.7\n","303 tensor(0.5586, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.26225135469241934 3.6\n","304 tensor(0.5406, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.26298910333772696 3.7\n","305 tensor(0.5035, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.2637261142343892 3.3\n","306 tensor(0.5832, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.26446238812015477 3.4\n","307 tensor(0.5362, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.2651979257320346 3.4\n","308 tensor(0.5549, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.2659327278063026 3.6\n","309 tensor(0.6603, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.26666679507849633 3.7\n","310 tensor(0.5602, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.26740012828341786 3.6\n","311 tensor(0.5392, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.26813272815513445 3.6\n","312 tensor(0.6066, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.26886459542697927 3.5\n","313 tensor(0.5346, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.2695957308315523 3.5\n","314 tensor(0.5474, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.2703261351007208 3.8\n","315 tensor(0.5232, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2710558089656201 3.5\n","316 tensor(0.5700, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.2717847531566545 3.8\n","317 tensor(0.5948, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.2725129684034978 4.0\n","318 tensor(0.5192, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.27324045543509434 4.0\n","319 tensor(0.4976, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.27396721497965926 3.6\n","320 tensor(0.5058, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.2746932477646796 3.8\n","321 tensor(0.5037, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.275418554516915 4.1\n","322 tensor(0.5840, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.27614313596239803 4.3\n","323 tensor(0.5366, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.2768669928264357 4.4\n","324 tensor(0.5211, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.2775901258336092 4.4\n","325 tensor(0.5713, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.2783125357077756 4.5\n","326 tensor(0.4766, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.27903422317206783 4.1\n","327 tensor(0.5747, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.2797551889488957 4.2\n","328 tensor(0.5688, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.2804754337599469 4.3\n","329 tensor(0.4681, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.2811949583261869 4.7\n","330 tensor(0.5190, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.28191376336786067 4.3\n","331 tensor(0.5459, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.28263184960449284 4.2\n","332 tensor(0.5606, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.2833492177548883 4.2\n","333 tensor(0.5667, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.28406586853713345 3.8\n","334 tensor(0.5299, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.2847818026685963 3.6\n","335 tensor(0.5657, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.28549702086592776 4.1\n","336 tensor(0.5302, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2862115238450619 3.8\n","337 tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.28692531232121676 3.5\n","338 tensor(0.5585, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.28763838700889555 3.3\n","339 tensor(0.4653, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.2883507486218867 3.4\n","340 tensor(0.5449, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.2890623978732648 4.0\n","341 tensor(0.6011, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.2897733354753915 4.0\n","342 tensor(0.5866, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.2904835621399161 3.7\n","343 tensor(0.4878, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2911930785777762 3.7\n","344 tensor(0.5033, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.2919018854991985 3.7\n","345 tensor(0.4409, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.2926099836136993 3.5\n","346 tensor(0.5269, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.2933173736300856 4.0\n","347 tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.29402405625645556 4.2\n","348 tensor(0.5138, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.2947300322001991 4.4\n","349 tensor(0.5431, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.29543530216799896 4.3\n","350 tensor(0.4776, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.29613986686583094 4.3\n","351 tensor(0.5459, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.2968437269989651 4.4\n","352 tensor(0.5891, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.2975468832719661 4.4\n","353 tensor(0.5773, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.2982493363886941 5.0\n","354 tensor(0.5745, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.29895108705230544 5.4\n","355 tensor(0.5291, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.2996521359652531 5.6\n","356 tensor(0.5596, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.3003524838292878 5.4\n","357 tensor(0.5875, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.3010521313454585 5.2\n","358 tensor(0.5887, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.30175107921411304 5.0\n","359 tensor(0.4732, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.3024493281348989 5.1\n","360 tensor(0.5608, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.30314687880676394 5.1\n","361 tensor(0.5546, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.3038437319279572 5.1\n","362 tensor(0.5767, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.3045398881960293 4.8\n","363 tensor(0.6014, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.3052353483078333 4.8\n","364 tensor(0.4682, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.30593011295952544 4.8\n","365 tensor(0.5650, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.3066241828465659 4.7\n","366 tensor(0.5960, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.30731755866371935 4.8\n","367 tensor(0.5690, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.3080102411050556 5.1\n","368 tensor(0.6027, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.30870223086395054 5.5\n","369 tensor(0.5544, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.30939352863308656 5.4\n","370 tensor(0.5228, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.31008413510445343 5.1\n","371 tensor(0.5811, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.31077405096934896 5.2\n","372 tensor(0.5097, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.3114632769183796 5.7\n","373 tensor(0.5483, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.3121518136414613 5.4\n","374 tensor(0.5621, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.31283966182781986 5.2\n","375 tensor(0.5416, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.31352682216599204 5.3\n","376 tensor(0.4881, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.314213295343826 5.2\n","377 tensor(0.5607, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.31489908204848216 5.1\n","378 tensor(0.4623, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.31558418296643365 4.5\n","379 tensor(0.5529, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.31626859878346725 4.5\n","380 tensor(0.5305, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.31695233018468383 4.5\n","381 tensor(0.5451, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.31763537785449913 4.4\n","382 tensor(0.5423, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.3183177424766447 4.5\n","383 tensor(0.5910, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.3189994247341681 4.8\n","384 tensor(0.5626, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.31968042530943397 4.7\n","385 tensor(0.5356, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.3203607448841246 4.3\n","386 tensor(0.5278, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.3210403841392404 4.5\n","387 tensor(0.6108, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.32171934375510114 4.3\n","388 tensor(0.5610, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.322397624411346 4.8\n","389 tensor(0.5469, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.3230752267869347 4.9\n","390 tensor(0.5374, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.3237521515601477 5.3\n","391 tensor(0.5352, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.3244283994085876 5.0\n","392 tensor(0.5035, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.325103971009179 4.8\n","393 tensor(0.5041, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.32577886703816983 4.8\n","394 tensor(0.5023, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.3264530881711316 4.8\n","395 tensor(0.5090, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.32712663508296047 5.1\n","396 tensor(0.5586, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.32779950844787753 5.1\n","397 tensor(0.5889, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.3284717089394297 5.3\n","398 tensor(0.5366, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.3291432372304902 5.3\n","399 tensor(0.5757, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.32981409399325967 4.6\n","400 tensor(0.5309, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.33048427989926643 4.5\n","401 tensor(0.4495, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.3311537956193672 4.4\n","402 tensor(0.6281, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.3318226418237479 4.5\n","403 tensor(0.5639, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.33249081918192414 4.5\n","404 tensor(0.5586, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.3331583283627422 4.2\n","405 tensor(0.5471, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.3338251700343794 4.0\n","406 tensor(0.6105, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.33449134486434506 4.0\n","407 tensor(0.6349, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.33515685351948077 4.0\n","408 tensor(0.5352, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.3358216966659613 4.2\n","409 tensor(0.5096, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.3364858749692953 4.8\n","410 tensor(0.5270, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.337149389094326 4.8\n","411 tensor(0.5998, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.33781223970523166 5.1\n","412 tensor(0.6163, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.3384744274655265 4.7\n","413 tensor(0.5542, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.339135953038061 4.5\n","414 tensor(0.4933, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.33979681708502296 4.9\n","415 tensor(0.5819, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.3404570202679379 5.2\n","416 tensor(0.5766, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.3411165632476699 4.9\n","417 tensor(0.5309, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.3417754466844223 5.2\n","418 tensor(0.5351, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.3424336712377378 5.1\n","419 tensor(0.4647, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.34309123756650006 4.9\n","420 tensor(0.5728, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.3437481463289336 5.1\n","421 tensor(0.5639, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.3444043981826046 5.0\n","422 tensor(0.5679, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.345059993784422 5.5\n","423 tensor(0.4921, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.34571493379063756 5.2\n","424 tensor(0.5268, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.3463692188568469 5.3\n","425 tensor(0.4902, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.34702284963799 5.1\n","426 tensor(0.5404, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.34767582678835207 5.3\n","427 tensor(0.5999, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.34832815096156367 4.9\n","428 tensor(0.5766, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.34897982281060214 4.4\n","429 tensor(0.5344, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.34963084298779157 4.0\n","430 tensor(0.5250, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.3502812121448038 3.8\n","431 tensor(0.5463, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.35093093093265904 3.9\n","432 tensor(0.5592, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.3515800000017264 3.7\n","433 tensor(0.5425, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.3522284200017247 3.7\n","434 tensor(0.5573, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.352876191581723 3.6\n","435 tensor(0.5452, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.35352331539014126 3.8\n","436 tensor(0.5246, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.3541697920747511 3.7\n","437 tensor(0.5344, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.3548156222826764 3.7\n","438 tensor(0.5517, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.3554608066603937 4.1\n","439 tensor(0.5339, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3561053458537333 4.1\n","440 tensor(0.6070, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.3567492405078796 3.9\n","441 tensor(0.5855, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.3573924912673717 4.1\n","442 tensor(0.5313, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.3580350987761044 4.4\n","443 tensor(0.4726, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.3586770636773283 4.8\n","444 tensor(0.5917, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.359318386613651 4.6\n","445 tensor(0.5122, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.3599590682270374 4.7\n","446 tensor(0.5359, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.3605991091588103 5.1\n","447 tensor(0.5298, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.36123851004965146 4.9\n","448 tensor(0.4687, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.3618772715396018 4.5\n","449 tensor(0.5357, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.36251539426806223 4.6\n","450 tensor(0.4435, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.3631528788737942 4.9\n","451 tensor(0.5134, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.36378972599492043 4.8\n","452 tensor(0.5443, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.3644259362689255 4.4\n","453 tensor(0.5416, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.36506151033265655 4.6\n","454 tensor(0.5220, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.3656964488223239 4.8\n","455 tensor(0.6380, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.36633075237350154 4.5\n","456 tensor(0.5491, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.3669644216211281 4.1\n","457 tensor(0.4955, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.367597457199507 3.9\n","458 tensor(0.5618, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.3682298597423075 4.1\n","459 tensor(0.5795, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.3688616298825652 4.2\n","460 tensor(0.5052, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.3694927682526826 3.7\n","461 tensor(0.5676, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.3701232754844299 3.7\n","462 tensor(0.4718, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.37075315220894545 3.8\n","463 tensor(0.4633, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.37138239905673653 3.7\n","464 tensor(0.5412, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.37201101665767977 3.3\n","465 tensor(0.5865, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.37263900564102215 3.0\n","466 tensor(0.5087, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.37326636663538115 3.3\n","467 tensor(0.4752, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.3738931002687458 4.0\n","468 tensor(0.5716, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.3745192071684771 4.4\n","469 tensor(0.4768, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.3751446879613086 4.7\n","470 tensor(0.5984, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.37576954327334733 4.7\n","471 tensor(0.5626, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.376393773730074 4.8\n","472 tensor(0.5207, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.3770173799563439 4.6\n","473 tensor(0.5086, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.37764036257638756 4.5\n","474 tensor(0.5659, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.3782627222138112 4.7\n","475 tensor(0.5425, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.3788844594915973 4.7\n","476 tensor(0.5252, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.3795055750321057 4.5\n","477 tensor(0.4734, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.3801260694570736 4.2\n","478 tensor(0.5962, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.3807459433876166 4.1\n","479 tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.3813651974442289 3.9\n","480 tensor(0.5480, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.38198383224678467 4.0\n","481 tensor(0.4918, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3826018484145379 3.3\n","482 tensor(0.5332, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.3832192465661234 3.6\n","483 tensor(0.5150, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.38383602731955724 3.6\n","484 tensor(0.5131, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.38445219129223773 3.9\n","485 tensor(0.5705, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.3850677391009455 4.2\n","486 tensor(0.5432, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.38568267136184453 4.4\n","487 tensor(0.5552, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.3862969886904827 4.7\n","488 tensor(0.5926, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.38691069170179215 4.3\n","489 tensor(0.5926, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.38752378101009033 4.6\n","490 tensor(0.5609, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.3881362572290802 4.6\n","491 tensor(0.5210, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.3887481209718511 4.9\n","492 tensor(0.6077, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.3893593728508792 5.1\n","493 tensor(0.5669, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3899700134780283 4.6\n","494 tensor(0.5338, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.3905800434645502 4.2\n","495 tensor(0.5094, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.3911894634210856 4.5\n","496 tensor(0.4338, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.39179827395766453 3.9\n","497 tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.3924064756837069 4.0\n","498 tensor(0.4577, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.3930140692080232 4.1\n","499 tensor(0.5290, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.3936210551388152 3.9\n","500 tensor(0.5577, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.39422743408367633 4.3\n","501 tensor(0.5452, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.39483320664959265 4.6\n","502 tensor(0.4871, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.3954383734429431 3.9\n","503 tensor(0.5873, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.39604293506950017 4.2\n","504 tensor(0.5089, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.3966468921344307 4.2\n","505 tensor(0.4986, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.39725024524229624 3.8\n","506 tensor(0.4635, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.39785299499705395 4.0\n","507 tensor(0.5256, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.3984551420020569 3.9\n","508 tensor(0.5049, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.3990566868600548 3.8\n","509 tensor(0.5757, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.3996576301731948 3.7\n","510 tensor(0.4576, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.40025797254302153 3.3\n","511 tensor(0.4595, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.4008577145704785 2.9\n","512 tensor(0.5404, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.40145685685590804 3.0\n","513 tensor(0.5631, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.40205539999905215 3.0\n","514 tensor(0.5021, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.4026533445990531 3.3\n","515 tensor(0.5463, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.403250691254454 3.5\n","516 tensor(0.4938, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.40384744056319954 3.6\n","517 tensor(0.4593, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.40444359312263634 2.9\n","518 tensor(0.4783, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.4050391495295137 2.9\n","519 tensor(0.5062, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.4056341103799842 3.4\n","520 tensor(0.5543, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.40622847626960423 3.2\n","521 tensor(0.5427, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.40682224779333465 3.3\n","522 tensor(0.5674, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.40741542554554133 3.2\n","523 tensor(0.5566, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.40800801011999577 3.9\n","524 tensor(0.4636, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4086000021098758 3.3\n","525 tensor(0.5278, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.40919140210776594 3.3\n","526 tensor(0.5049, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.40978221070565823 3.7\n","527 tensor(0.5769, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.4103724284949526 4.1\n","528 tensor(0.5213, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.41096205606645764 4.6\n","529 tensor(0.5064, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.41155109401039114 4.5\n","530 tensor(0.5168, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.4121395429163808 4.6\n","531 tensor(0.5076, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.41272740337346436 4.8\n","532 tensor(0.4976, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.41331467597009086 5.5\n","533 tensor(0.5436, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.4139013612941208 5.1\n","534 tensor(0.5511, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.41448745993282665 5.8\n","535 tensor(0.5178, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.4150729724728939 5.7\n","536 tensor(0.5423, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.415657899500421 5.2\n","537 tensor(0.4824, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.4162422416009206 5.6\n","538 tensor(0.5718, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.41682599935931963 5.3\n","539 tensor(0.5235, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.4174091733599603 5.0\n","540 tensor(0.4831, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.41799176418660033 5.6\n","541 tensor(0.5493, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.4185737724224138 5.9\n","542 tensor(0.5040, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.4191551986499914 5.8\n","543 tensor(0.4700, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.4197360434513414 5.6\n","544 tensor(0.5287, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.42031630740789006 5.6\n","545 tensor(0.4934, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.42089599110048215 5.7\n","546 tensor(0.5226, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.42147509510938164 5.9\n","547 tensor(0.5259, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.42205362001427227 5.4\n","548 tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.42263156639425803 5.7\n","549 tensor(0.5673, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.4232089348278638 5.9\n","550 tensor(0.5542, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.423785725893036 5.6\n","551 tensor(0.5066, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.4243619401671429 4.9\n","552 tensor(0.5055, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.42493757822697575 4.7\n","553 tensor(0.4645, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.42551264064874883 4.8\n","554 tensor(0.5237, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.4260871280081001 4.8\n","555 tensor(0.4479, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.42666104088009205 4.9\n","556 tensor(0.5159, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.427234379839212 5.3\n","557 tensor(0.4768, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.4278071454593728 5.3\n","558 tensor(0.5124, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.4283793383139134 5.3\n","559 tensor(0.4435, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.42895095897559943 5.6\n","560 tensor(0.5366, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.4295220080166239 5.9\n","561 tensor(0.5941, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.4300924860086073 6.6\n","562 tensor(0.5626, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.4306623935225987 6.8\n","563 tensor(0.5194, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.4312317311290761 6.8\n","564 tensor(0.5170, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.43180049939794707 6.3\n","565 tensor(0.4471, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4323686988985491 5.7\n","566 tensor(0.5232, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.4329363301996506 5.6\n","567 tensor(0.4487, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.4335033938694509 6.1\n","568 tensor(0.4190, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.4340698904755814 6.1\n","569 tensor(0.5093, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.43463582058510586 5.8\n","570 tensor(0.5109, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.43520118476452074 5.6\n","571 tensor(0.4824, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.43576598357975627 5.5\n","572 tensor(0.5181, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.4363302175961765 5.5\n","573 tensor(0.4871, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.43689388737858037 5.7\n","574 tensor(0.4773, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.4374569934912018 5.9\n","575 tensor(0.5650, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.43801953649771064 6.9\n","576 tensor(0.4448, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.43858151696121295 6.9\n","577 tensor(0.4734, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.43914293544425176 6.4\n","578 tensor(0.4985, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.43970379250880753 6.4\n","579 tensor(0.5098, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.44026408871629874 6.4\n","580 tensor(0.5580, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.4408238246275824 6.5\n","581 tensor(0.4490, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.4413830008029548 6.1\n","582 tensor(0.4890, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.4419416178021518 6.1\n","583 tensor(0.4814, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.4424996761843496 6.1\n","584 tensor(0.5089, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.44305717650816523 6.4\n","585 tensor(0.5238, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.44361411933165706 5.5\n","586 tensor(0.4730, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.4441705052123254 5.6\n","587 tensor(0.4436, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.4447263347071131 6.0\n","588 tensor(0.4564, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.44528160837240593 6.0\n","589 tensor(0.4697, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.4458363267640335 5.7\n","590 tensor(0.5101, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.4463904904372695 5.7\n","591 tensor(0.4183, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.44694409994683226 5.7\n","592 tensor(0.4800, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.44749715584688543 5.7\n","593 tensor(0.5038, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.4480496586910385 5.7\n","594 tensor(0.4914, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.44860160903234747 5.8\n","595 tensor(0.5227, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.4491530074233151 6.1\n","596 tensor(0.4711, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.4497038544158918 6.0\n","597 tensor(0.4533, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.4502541505614759 5.8\n","598 tensor(0.4204, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.45080389641091445 5.6\n","599 tensor(0.4183, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.4513530925145035 6.3\n","600 tensor(0.4889, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.45190173942198897 6.3\n","601 tensor(0.4613, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.45244983768256697 6.5\n","602 tensor(0.4425, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.4529973878448844 6.3\n","603 tensor(0.4524, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.45354439045703954 6.3\n","604 tensor(0.3865, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.45409084606658245 6.2\n","605 tensor(0.4510, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.45463675522051583 6.5\n","606 tensor(0.5098, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.4551821184652953 6.2\n","607 tensor(0.4492, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.45572693634683004 6.3\n","608 tensor(0.5344, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.45627120941048316 6.6\n","609 tensor(0.5098, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.45681493820107266 6.2\n","610 tensor(0.5028, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4573581232628716 5.5\n","611 tensor(0.5634, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.45790076513960876 5.8\n","612 tensor(0.5081, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.45844286437446913 6.1\n","613 tensor(0.4719, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.45898442151009466 6.0\n","614 tensor(0.4854, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.4595254370885846 5.8\n","615 tensor(0.4704, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.460065911651496 5.2\n","616 tensor(0.4492, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.46060584573984453 5.2\n","617 tensor(0.4487, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.4611452398941047 5.3\n","618 tensor(0.4501, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.46168409465421056 4.8\n","619 tensor(0.5056, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.4622224105595564 4.9\n","620 tensor(0.4260, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.4627601881489968 5.6\n","621 tensor(0.4846, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.46329742796084783 5.6\n","622 tensor(0.4425, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.463834130532887 5.5\n","623 tensor(0.4172, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.46437029640235417 5.9\n","624 tensor(0.4642, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.46490592610595183 5.5\n","625 tensor(0.5202, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.4654410201798459 6.1\n","626 tensor(0.4956, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.46597557915966603 6.1\n","627 tensor(0.4447, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.4665096035805064 6.2\n","628 tensor(0.4146, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4670430939769259 5.9\n","629 tensor(0.4625, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.46757605088294896 5.5\n","630 tensor(0.5395, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.46810847483206597 5.4\n","631 tensor(0.4763, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.46864036635723394 4.8\n","632 tensor(0.4694, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.46917172599087675 4.9\n","633 tensor(0.4847, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.46970255426488583 4.2\n","634 tensor(0.4969, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.4702328517106209 4.3\n","635 tensor(0.4198, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.47076261885891024 4.2\n","636 tensor(0.5124, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.4712918562400513 4.0\n","637 tensor(0.4561, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.47182056438381126 3.9\n","638 tensor(0.4776, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.4723487438194275 5.1\n","639 tensor(0.4244, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.4728763950756081 5.7\n","640 tensor(0.4414, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.47340351868053243 5.5\n","641 tensor(0.5166, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.4739301151618519 6.1\n","642 tensor(0.4629, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.47445618504669007 6.0\n","643 tensor(0.4450, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.47498172886164336 6.3\n","644 tensor(0.4351, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.47550674713278174 6.7\n","645 tensor(0.4459, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4760312403856489 6.1\n","646 tensor(0.4767, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.4765552091452633 6.6\n","647 tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.47707865393611804 6.0\n","648 tensor(0.5070, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.47760157528218194 5.6\n","649 tensor(0.4500, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.47812397370689974 4.7\n","650 tensor(0.4510, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.4786458497331928 5.0\n","651 tensor(0.3718, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.47916720388345957 4.9\n","652 tensor(0.4682, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.47968803667957616 4.9\n","653 tensor(0.4415, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.48020834864289663 4.6\n","654 tensor(0.5027, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.4807281402942537 4.8\n","655 tensor(0.4510, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.4812474121539595 5.4\n","656 tensor(0.4855, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.48176616474180556 4.8\n","657 tensor(0.4274, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.48228439857706373 5.3\n","658 tensor(0.4892, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.4828021141784866 5.3\n","659 tensor(0.3979, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.4833193120643081 6.1\n","660 tensor(0.3976, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.48383599275224376 6.2\n","661 tensor(0.4257, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.4843521567594915 6.2\n","662 tensor(0.5096, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.48486780460273204 6.3\n","663 tensor(0.4092, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.48538293679812927 6.3\n","664 tensor(0.3946, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.48589755386133116 6.3\n","665 tensor(0.4780, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.48641165630746985 6.6\n","666 tensor(0.3974, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.4869252446511624 7.3\n","667 tensor(0.4646, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.48743831940651117 6.7\n","668 tensor(0.4241, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.4879508810871046 6.9\n","669 tensor(0.4144, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.4884629302060175 6.9\n","670 tensor(0.4453, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.4889744672758115 6.5\n","671 tensor(0.4306, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.4894854928085357 6.5\n","672 tensor(0.4361, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.4899960073157271 6.4\n","673 tensor(0.4551, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.4905060113084114 6.9\n","674 tensor(0.4531, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.491015505297103 6.9\n","675 tensor(0.4491, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.49152448979180596 6.1\n","676 tensor(0.4570, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.4920329653020141 6.2\n","677 tensor(0.4803, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.49254093233671215 6.6\n","678 tensor(0.3806, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.4930483914043754 6.5\n","679 tensor(0.4936, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.493555343012971 6.3\n","680 tensor(0.4707, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.494061787669958 6.1\n","681 tensor(0.5161, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.49456772588228803 5.7\n","682 tensor(0.4053, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.49507315815640573 5.8\n","683 tensor(0.4428, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.4955780849982493 5.2\n","684 tensor(0.4932, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.49608250691325106 5.1\n","685 tensor(0.4201, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4965864244063378 5.0\n","686 tensor(0.4667, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.4970898379819315 4.2\n","687 tensor(0.4609, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.4975927481439496 4.3\n","688 tensor(0.4977, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.4980951553958056 4.2\n","689 tensor(0.3940, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.49859706024040984 4.3\n","690 tensor(0.5143, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.4990984631801695 4.8\n","691 tensor(0.4535, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.4995993647169893 5.1\n","692 tensor(0.4680, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5000997653522723 4.5\n","693 tensor(0.4095, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.50059966558692 4.6\n","694 tensor(0.4769, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.5010990659213331 4.3\n","695 tensor(0.5249, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5015979668554118 5.1\n","696 tensor(0.4822, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5020963688885565 5.8\n","697 tensor(0.5165, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5025942725196679 6.1\n","698 tensor(0.4843, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5030916782471482 5.3\n","699 tensor(0.4974, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5035885865689012 4.7\n","700 tensor(0.5171, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5040849979823322 4.1\n","701 tensor(0.4702, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5045809129843499 4.2\n","702 tensor(0.4464, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.5050763320713656 5.1\n","703 tensor(0.4515, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5055712557392942 5.5\n","704 tensor(0.4131, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.5060656844835549 5.7\n","705 tensor(0.4698, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5065596187990713 4.9\n","706 tensor(0.4724, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5070530591802722 4.9\n","707 tensor(0.4332, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.5075460061210919 4.5\n","708 tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5080384601149709 4.6\n","709 tensor(0.4440, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5085304216548558 5.2\n","710 tensor(0.4240, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5090218912332011 5.9\n","711 tensor(0.4185, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5095128693419679 6.0\n","712 tensor(0.4546, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.5100033564726258 5.5\n","713 tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5104933531161533 5.5\n","714 tensor(0.4541, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5109828597630371 5.6\n","715 tensor(0.5034, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.5114718769032741 6.5\n","716 tensor(0.4022, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.5119604050263709 6.1\n","717 tensor(0.4743, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.5124484446213444 6.6\n","718 tensor(0.4550, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5129359961767231 7.2\n","719 tensor(0.4877, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.5134230601805464 6.8\n","720 tensor(0.4926, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.5139096371203659 6.4\n","721 tensor(0.4514, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5143957274832455 5.6\n","722 tensor(0.4614, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.5148813317557622 5.6\n","723 tensor(0.4486, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5153664504240065 5.1\n","724 tensor(0.4454, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5158510839735825 4.6\n","725 tensor(0.4906, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.5163352328896089 4.3\n","726 tensor(0.4461, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.5168188976567193 4.2\n","727 tensor(0.4801, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5173020787590625 3.3\n","728 tensor(0.4835, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5177847766803035 3.4\n","729 tensor(0.3888, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.5182669919036232 3.4\n","730 tensor(0.4464, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.5187487249117196 3.3\n","731 tensor(0.4731, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.519229976186808 4.1\n","732 tensor(0.4488, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5197107462106212 4.2\n","733 tensor(0.4828, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5201910354644106 4.8\n","734 tensor(0.4981, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.5206708444289461 5.0\n","735 tensor(0.4121, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5211501735845172 5.1\n","736 tensor(0.4626, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.5216290234109326 5.4\n","737 tensor(0.4243, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5221073943875217 6.2\n","738 tensor(0.4910, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5225852869931342 5.5\n","739 tensor(0.4948, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5230627017061411 6.0\n","740 tensor(0.5179, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5235396390044349 6.5\n","741 tensor(0.4422, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5240160993654306 5.9\n","742 tensor(0.5245, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.5244920832660651 5.6\n","743 tensor(0.4968, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.5249675911827991 5.3\n","744 tensor(0.4520, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5254426235916163 5.0\n","745 tensor(0.4390, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.5259171809680246 4.6\n","746 tensor(0.4870, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.5263912637870567 4.9\n","747 tensor(0.4092, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5268648725232696 4.3\n","748 tensor(0.4447, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5273380076507463 4.2\n","749 tensor(0.4216, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.5278106696430955 4.3\n","750 tensor(0.4981, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.5282828589734525 4.1\n","751 tensor(0.4773, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.528754576114479 4.1\n","752 tensor(0.4665, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.5292258215383645 4.3\n","753 tensor(0.5032, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5296965957168263 4.0\n","754 tensor(0.3978, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.5301668991211094 4.9\n","755 tensor(0.4872, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.5306367322219883 5.0\n","756 tensor(0.4522, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5311060954897663 4.8\n","757 tensor(0.4871, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5315749893942765 5.4\n","758 tensor(0.4221, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.5320434144048822 6.0\n","759 tensor(0.3840, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5325113709904774 5.8\n","760 tensor(0.4829, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5329788596194869 5.9\n","761 tensor(0.4836, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.5334458807598674 6.1\n","762 tensor(0.4180, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.5339124348791076 6.4\n","763 tensor(0.4658, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5343785224442283 6.9\n","764 tensor(0.3962, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5348441439217841 6.6\n","765 tensor(0.4679, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5353092997778623 7.0\n","766 tensor(0.4519, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5357739904780845 6.3\n","767 tensor(0.4212, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5362382164876064 6.3\n","768 tensor(0.4311, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.5367019782711188 6.2\n","769 tensor(0.3759, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.5371652762928476 6.0\n","770 tensor(0.4451, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.5376281110165548 5.9\n","771 tensor(0.4426, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5380904829055383 6.2\n","772 tensor(0.4515, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5385523924226328 5.3\n","773 tensor(0.4522, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.5390138400302101 4.9\n","774 tensor(0.4447, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.53947482619018 5.1\n","775 tensor(0.4286, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5399353513639897 4.4\n","776 tensor(0.3902, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5403954160126259 4.6\n","777 tensor(0.4638, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.5408550205966132 4.2\n","778 tensor(0.4873, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5413141655760165 4.4\n","779 tensor(0.3870, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5417728514104405 4.1\n","780 tensor(0.4408, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5422310785590301 3.5\n","781 tensor(0.4868, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5426888474804711 3.6\n","782 tensor(0.4652, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.5431461586329906 4.5\n","783 tensor(0.4921, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.5436030124743576 4.6\n","784 tensor(0.3984, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.5440594094618832 4.1\n","785 tensor(0.4606, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5445153500524214 4.0\n","786 tensor(0.4916, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.544970834702369 4.2\n","787 tensor(0.4809, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5454258638676666 4.0\n","788 tensor(0.4489, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5458804380037989 3.5\n","789 tensor(0.4434, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5463345575657951 3.3\n","790 tensor(0.4216, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.5467882230082293 3.8\n","791 tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.547241434785221 3.8\n","792 tensor(0.4354, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5476941933504358 3.7\n","793 tensor(0.4938, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5481464991570854 4.0\n","794 tensor(0.4704, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.5485983526579283 4.0\n","795 tensor(0.4195, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.5490497543052704 4.3\n","796 tensor(0.4429, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.5495007045509651 4.3\n","797 tensor(0.4249, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5499512038464142 4.8\n","798 tensor(0.4586, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.5504012526425677 5.1\n","799 tensor(0.4440, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.5508508513899252 5.6\n","800 tensor(0.4197, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5513000005385352 5.9\n","801 tensor(0.3991, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.5517487005379966 5.7\n","802 tensor(0.4461, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.5521969518374588 5.5\n","803 tensor(0.5252, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.5526447548856213 5.2\n","804 tensor(0.4514, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.5530921101307356 5.7\n","805 tensor(0.4762, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5535390180206049 5.6\n","806 tensor(0.3458, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.5539854790025842 6.2\n","807 tensor(0.4288, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5544314935235817 5.7\n","808 tensor(0.4339, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.554877062030058 5.9\n","809 tensor(0.4592, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.5553221849680281 5.7\n","810 tensor(0.4869, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5557668627830601 5.1\n","811 tensor(0.4083, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.556211095920277 5.1\n","812 tensor(0.4647, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5566548848243567 4.6\n","813 tensor(0.4488, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5570982299395323 4.9\n","814 tensor(0.4787, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.5575411317095927 4.6\n","815 tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5579835905778832 5.1\n","816 tensor(0.4445, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5584256069873053 4.3\n","817 tensor(0.4765, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5588671813803179 4.8\n","818 tensor(0.4709, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5593083141989377 4.8\n","819 tensor(0.3950, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.5597490058847387 4.8\n","820 tensor(0.4965, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.560189256878854 4.7\n","821 tensor(0.4961, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.5606290676219752 4.5\n","822 tensor(0.4886, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5610684385543532 4.4\n","823 tensor(0.4098, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.5615073701157988 4.0\n","824 tensor(0.3750, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.561945862745683 3.6\n","825 tensor(0.4930, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5623839168829373 3.7\n","826 tensor(0.4748, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.5628215329660544 3.9\n","827 tensor(0.4631, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5632587114330883 3.3\n","828 tensor(0.4170, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5636954527216552 3.3\n","829 tensor(0.3757, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.5641317572689335 3.6\n","830 tensor(0.4457, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.5645676255116646 4.1\n","831 tensor(0.4333, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5650030578861529 4.5\n","832 tensor(0.5081, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5654380548282668 5.3\n","833 tensor(0.4342, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.5658726167734385 5.3\n","834 tensor(0.4759, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5663067441566652 5.9\n","835 tensor(0.4769, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5667404374125085 5.9\n","836 tensor(0.5327, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.567173696975096 5.6\n","837 tensor(0.4237, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.5676065232781209 6.4\n","838 tensor(0.3980, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5680389167548427 6.4\n","839 tensor(0.4558, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.5684708778380878 6.2\n","840 tensor(0.4615, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5689024069602497 6.4\n","841 tensor(0.4457, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.5693335045532896 6.2\n","842 tensor(0.4427, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5697641710487362 6.1\n","843 tensor(0.4747, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5701944068776875 5.8\n","844 tensor(0.3869, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5706242124708099 5.2\n","845 tensor(0.4511, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5710535882583391 5.1\n","846 tensor(0.3980, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5714825346700807 5.8\n","847 tensor(0.4489, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5719110521354107 5.1\n","848 tensor(0.3765, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5723391410832752 5.2\n","849 tensor(0.3948, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.572766801942192 5.1\n","850 tensor(0.3943, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.5731940351402498 4.6\n","851 tensor(0.3837, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5736208411051096 4.7\n","852 tensor(0.4096, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5740472202640045 4.7\n","853 tensor(0.4194, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5744731730437405 5.5\n","854 tensor(0.4652, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5748986998706966 6.0\n","855 tensor(0.4914, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.5753238011708259 6.4\n","856 tensor(0.4291, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.5757484773696552 6.2\n","857 tensor(0.4281, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5761727288922855 6.0\n","858 tensor(0.4368, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5765965561633932 5.9\n","859 tensor(0.4228, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.5770199596072298 6.0\n","860 tensor(0.4205, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5774429396476226 6.4\n","861 tensor(0.4577, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.577865496707975 6.5\n","862 tensor(0.3786, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.578287631211267 6.1\n","863 tensor(0.4615, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5787093435800559 5.3\n","864 tensor(0.4089, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.5791306342364757 5.5\n","865 tensor(0.4296, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5795515036022393 5.2\n","866 tensor(0.4803, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5799719520986371 5.4\n","867 tensor(0.4093, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5803919801465385 5.5\n","868 tensor(0.4700, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5808115881663919 5.5\n","869 tensor(0.4109, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.5812307765782254 5.7\n","870 tensor(0.5139, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.5816495458016473 5.6\n","871 tensor(0.4614, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5820678962558457 5.5\n","872 tensor(0.4258, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.5824858283595897 5.5\n","873 tensor(0.3955, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.5829033425312302 6.5\n","874 tensor(0.3869, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5833204391886989 6.3\n","875 tensor(0.4023, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.5837371187495102 5.9\n","876 tensor(0.4810, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.5841533816307607 6.0\n","877 tensor(0.4712, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.5845692282491299 6.4\n","878 tensor(0.4637, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.5849846590208809 6.6\n","879 tensor(0.4548, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.5853996743618599 6.4\n","880 tensor(0.4505, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5858142746874981 6.5\n","881 tensor(0.4109, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5862284604128105 6.5\n","882 tensor(0.4324, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.5866422319523978 7.1\n","883 tensor(0.5113, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.5870555897204455 7.1\n","884 tensor(0.4659, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.587468534130725 6.4\n","885 tensor(0.4860, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.5878810655965943 6.6\n","886 tensor(0.4113, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5882931845309977 6.4\n","887 tensor(0.4537, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.5887048913464666 6.5\n","888 tensor(0.4361, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5891161864551202 5.7\n","889 tensor(0.3837, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.589527070268665 5.5\n","890 tensor(0.4858, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5899375431983964 4.8\n","891 tensor(0.3715, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.590347605655198 5.0\n","892 tensor(0.4716, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.5907572580495428 4.7\n","893 tensor(0.3995, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5911665007914932 3.7\n","894 tensor(0.3863, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.5915753342907017 4.6\n","895 tensor(0.3617, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.591983758956411 4.5\n","896 tensor(0.3911, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.5923917751974546 4.4\n","897 tensor(0.4637, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.5927993834222571 4.6\n","898 tensor(0.4127, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.593206584038835 5.4\n","899 tensor(0.4578, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.593613377454796 5.7\n","900 tensor(0.4567, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.5940197640773413 6.2\n","901 tensor(0.4546, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.5944257443132639 6.4\n","902 tensor(0.4326, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.5948313185689507 6.1\n","903 tensor(0.4790, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5952364872503817 6.2\n","904 tensor(0.4875, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.5956412507631312 5.7\n","905 tensor(0.4444, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.5960456095123682 5.7\n","906 tensor(0.4123, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.5964495639028558 5.4\n","907 tensor(0.3939, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5968531143389529 5.3\n","908 tensor(0.4477, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.597256261224614 5.0\n","909 tensor(0.3620, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.5976590049633894 4.8\n","910 tensor(0.4894, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.5980613459584261 4.8\n","911 tensor(0.5013, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.5984632846124676 4.3\n","912 tensor(0.4862, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.5988648213278551 4.4\n","913 tensor(0.4284, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.5992659565065273 5.0\n","914 tensor(0.4036, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5996666905500208 4.6\n","915 tensor(0.5159, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6000670238594707 4.2\n","916 tensor(0.4231, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6004669568356114 4.8\n","917 tensor(0.4489, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6008664898787757 4.2\n","918 tensor(0.4622, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6012656233888969 3.6\n","919 tensor(0.4012, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.601664357765508 3.3\n","920 tensor(0.4891, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6020626934077424 2.8\n","921 tensor(0.4140, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.6024606307143348 2.6\n","922 tensor(0.3776, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.6028581700836204 2.7\n","923 tensor(0.4521, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6032553119135369 2.9\n","924 tensor(0.4358, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6036520566016232 3.8\n","925 tensor(0.4074, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.6040484045450216 4.3\n","926 tensor(0.4438, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.6044443561404766 4.0\n","927 tensor(0.4573, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.6048399117843362 4.3\n","928 tensor(0.3662, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.6052350718725519 5.1\n","929 tensor(0.3831, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.6056298368006793 5.7\n","930 tensor(0.3892, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.6060242069638786 6.4\n","931 tensor(0.4255, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.6064181827569147 6.4\n","932 tensor(0.3994, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.6068117645741578 7.0\n","933 tensor(0.4685, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.6072049528095836 6.8\n","934 tensor(0.4273, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.607597747856774 6.6\n","935 tensor(0.4531, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6079901501089173 6.0\n","936 tensor(0.3912, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.6083821599588084 5.7\n","937 tensor(0.4317, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6087737777988496 6.2\n","938 tensor(0.4713, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.6091650040210508 6.2\n","939 tensor(0.4527, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.6095558390170297 6.2\n","940 tensor(0.4273, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.6099462831780127 6.5\n","941 tensor(0.4592, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.6103363368948347 6.4\n","942 tensor(0.4525, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.6107260005579398 5.9\n","943 tensor(0.4215, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6111152745573819 5.2\n","944 tensor(0.3982, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.6115041592828245 5.2\n","945 tensor(0.4219, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.6118926551235417 5.5\n","946 tensor(0.4287, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6122807624684181 5.3\n","947 tensor(0.4592, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6126684817059497 4.5\n","948 tensor(0.4300, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6130558132242437 3.7\n","949 tensor(0.4052, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.6134427574110195 3.7\n","950 tensor(0.4029, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.6138293146536085 3.2\n","951 tensor(0.4978, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.6142154853389549 3.3\n","952 tensor(0.4321, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6146012698536159 2.7\n","953 tensor(0.3743, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.6149866685837623 3.5\n","954 tensor(0.4434, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6153716819151784 3.7\n","955 tensor(0.4333, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6157563102332633 3.5\n","956 tensor(0.3957, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.61614055392303 4.3\n","957 tensor(0.4301, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.616524413369107 5.1\n","958 tensor(0.4561, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.616907888955738 5.8\n","959 tensor(0.4760, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6172909810667822 6.1\n","960 tensor(0.4387, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.6176736900857154 5.9\n","961 tensor(0.4032, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6180560163956297 6.4\n","962 tensor(0.5046, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.618437960379234 7.0\n","963 tensor(0.4082, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6188195224188549 7.1\n","964 tensor(0.4763, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.6192007028964359 7.4\n","965 tensor(0.4058, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.6195815021935396 7.6\n","966 tensor(0.4747, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.619961920691346 6.9\n","967 tensor(0.4624, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.6203419587706547 7.1\n","968 tensor(0.4523, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.620721616811884 6.5\n","969 tensor(0.4511, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6211008951950721 6.5\n","970 tensor(0.4652, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.6214797942998771 6.9\n","971 tensor(0.4162, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.6218583145055772 6.6\n","972 tensor(0.4554, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6222364561910716 6.0\n","973 tensor(0.4721, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.6226142197348805 5.5\n","974 tensor(0.4253, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.6229916055151457 5.1\n","975 tensor(0.4212, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.6233686139096305 5.2\n","976 tensor(0.4076, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.6237452452957208 5.4\n","977 tensor(0.4052, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.6241215000504251 5.4\n","978 tensor(0.4634, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6244973785503747 6.2\n","979 tensor(0.3700, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6248728811718243 6.2\n","980 tensor(0.4144, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.6252480082906525 6.1\n","981 tensor(0.4357, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.6256227602823619 5.9\n","982 tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6259971375220794 6.8\n","983 tensor(0.5054, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6263711403845573 7.3\n","984 tensor(0.4290, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.6267447692441728 7.6\n","985 tensor(0.4190, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6271180244749286 7.3\n","986 tensor(0.4542, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6274909064504537 6.9\n","987 tensor(0.4317, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6278634155440033 6.7\n","988 tensor(0.4551, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.6282355521284593 6.2\n","989 tensor(0.4929, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.6286073165763308 6.5\n","990 tensor(0.4203, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.6289787092597545 6.3\n","991 tensor(0.4762, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.6293497305504947 6.2\n","992 tensor(0.4176, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.6297203808199442 6.1\n","993 tensor(0.4968, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.6300906604391243 6.2\n","994 tensor(0.4416, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.6304605697786851 6.2\n","995 tensor(0.3772, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6308301092089065 7.0\n","996 tensor(0.4311, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6311992790996976 7.0\n","997 tensor(0.4103, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.6315680798205978 6.5\n","998 tensor(0.4057, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6319365117407773 7.0\n","999 tensor(0.4356, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.6323045752290365 6.8\n","1000 tensor(0.3759, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.6326722706538075 7.5\n","1001 tensor(0.4556, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6330395983831536 7.3\n","1002 tensor(0.4244, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6334065587847704 6.7\n","1003 tensor(0.4020, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.6337731522259857 6.3\n","1004 tensor(0.4662, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.6341393790737597 5.8\n","1005 tensor(0.4128, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.634505239694686 5.7\n","1006 tensor(0.4215, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.6348707344549913 6.0\n","1007 tensor(0.4643, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.6352358637205362 6.7\n","1008 tensor(0.4550, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.6356006278568157 6.1\n","1009 tensor(0.4027, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.6359650272289589 5.4\n","1010 tensor(0.4335, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.6363290622017299 5.0\n","1011 tensor(0.4408, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.6366927331395282 5.3\n","1012 tensor(0.4332, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6370560404063886 6.0\n","1013 tensor(0.4166, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.6374189843659823 6.4\n","1014 tensor(0.4159, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6377815653816163 6.0\n","1015 tensor(0.4284, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6381437838162347 6.1\n","1016 tensor(0.4240, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.6385056400324185 6.4\n","1017 tensor(0.4397, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.638867134392386 6.0\n","1018 tensor(0.4262, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.6392282672579936 6.4\n","1019 tensor(0.4433, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.6395890389907357 6.9\n","1020 tensor(0.3848, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.6399494499517449 6.5\n","1021 tensor(0.4569, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.6403095005017931 7.1\n","1022 tensor(0.4184, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6406691910012914 6.4\n","1023 tensor(0.4089, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.64102852181029 5.6\n","1024 tensor(0.3935, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.6413874932884798 6.4\n","1025 tensor(0.4667, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6417461057951912 6.4\n","1026 tensor(0.4144, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.642104359689396 6.1\n","1027 tensor(0.4398, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.6424622553297066 6.2\n","1028 tensor(0.4136, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.6428197930743769 6.1\n","1029 tensor(0.4371, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6431769732813025 5.3\n","1030 tensor(0.4078, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.6435337963080212 5.6\n","1031 tensor(0.4928, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.6438902625117131 5.7\n","1032 tensor(0.4880, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.6442463722492014 6.3\n","1033 tensor(0.4068, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.6446021258769523 7.1\n","1034 tensor(0.4599, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6449575237510753 7.0\n","1035 tensor(0.4267, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.6453125662273242 7.2\n","1036 tensor(0.4367, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.6456672536610968 7.9\n","1037 tensor(0.4251, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.6460215864074357 8.1\n","1038 tensor(0.4148, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.6463755648210283 7.8\n","1039 tensor(0.3596, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.6467291892562073 8.5\n","1040 tensor(0.3457, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.647082460066951 8.5\n","1041 tensor(0.4552, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6474353776068841 7.5\n","1042 tensor(0.4060, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.6477879422292772 7.7\n","1043 tensor(0.4243, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.648140154287048 7.9\n","1044 tensor(0.3719, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.6484920141327608 8.0\n","1045 tensor(0.4229, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.6488435221186282 7.9\n","1046 tensor(0.4097, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6491946785965095 7.0\n","1047 tensor(0.4456, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.6495454839179129 7.0\n","1048 tensor(0.4104, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.6498959384339951 7.3\n","1049 tensor(0.3918, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.650246042495561 7.0\n","1050 tensor(0.4298, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.6505957964530654 7.4\n","1051 tensor(0.5060, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.6509452006566123 8.1\n","1052 tensor(0.4460, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.6512942554559558 7.8\n","1053 tensor(0.4536, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6516429612004998 6.6\n","1054 tensor(0.3624, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.6519913182392993 5.9\n","1055 tensor(0.4750, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.65233932692106 6.1\n","1056 tensor(0.4150, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.652686987594139 6.2\n","1057 tensor(0.4392, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.6530343006065449 6.3\n","1058 tensor(0.4030, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.6533812663059383 6.3\n","1059 tensor(0.4448, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6537278850396324 6.8\n","1060 tensor(0.4431, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.6540741571545927 6.8\n","1061 tensor(0.4875, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.6544200829974381 7.0\n","1062 tensor(0.4809, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.6547656629144407 7.3\n","1063 tensor(0.4792, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.6551108972515263 8.3\n","1064 tensor(0.4539, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.6554557863542747 8.7\n","1065 tensor(0.4100, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.6558003305679205 8.7\n","1066 tensor(0.5073, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.6561445302373525 9.6\n","1067 tensor(0.4658, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.6564883857071151 9.1\n","1068 tensor(0.3870, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.656831897321408 8.8\n","1069 tensor(0.3905, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.6571750654240867 8.7\n","1070 tensor(0.4807, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.6575178903586626 8.5\n","1071 tensor(0.4748, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.6578603724683039 7.8\n","1072 tensor(0.4265, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6582025120958357 6.8\n","1073 tensor(0.4379, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.6585443095837398 6.3\n","1074 tensor(0.4304, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.658885765274156 6.7\n","1075 tensor(0.3873, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.6592268795088818 6.6\n","1076 tensor(0.4613, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.659567652629373 6.4\n","1077 tensor(0.4513, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6599080849767436 6.0\n","1078 tensor(0.4581, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.660248176891767 6.3\n","1079 tensor(0.4391, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.6605879287148751 6.7\n","1080 tensor(0.4446, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.6609273407861602 7.0\n","1081 tensor(0.4337, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6612664134453741 6.9\n","1082 tensor(0.4263, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6616051470319287 7.1\n","1083 tensor(0.4380, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.6619435418848968 7.7\n","1084 tensor(0.4113, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.6622815983430119 7.4\n","1085 tensor(0.4274, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.6626193167446688 6.7\n","1086 tensor(0.4428, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6629566974279242 5.8\n","1087 tensor(0.4630, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.6632937407304962 6.3\n","1088 tensor(0.4555, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.6636304469897658 6.7\n","1089 tensor(0.3688, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.663966816542776 6.1\n","1090 tensor(0.4179, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.6643028497262332 5.6\n","1091 tensor(0.4850, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.664638546876507 6.1\n","1092 tensor(0.3604, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6649739083296304 6.1\n","1093 tensor(0.4485, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6653089344213008 5.1\n","1094 tensor(0.4329, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.6656436254868796 5.1\n","1095 tensor(0.4770, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.6659779818613927 5.4\n","1096 tensor(0.4686, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6663120038795313 5.6\n","1097 tensor(0.4351, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.6666456918756518 5.3\n","1098 tensor(0.4861, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6669790461837761 5.2\n","1099 tensor(0.4579, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.6673120671375923 5.3\n","1100 tensor(0.4668, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6676447550704547 4.9\n","1101 tensor(0.4277, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.6679771103153842 5.0\n","1102 tensor(0.4517, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6683091332050688 4.8\n","1103 tensor(0.3757, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.6686408240718638 5.4\n","1104 tensor(0.4017, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.668972183247792 4.8\n","1105 tensor(0.5063, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.669303211064544 5.2\n","1106 tensor(0.4668, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6696339078534795 5.0\n","1107 tensor(0.3300, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6699642739456261 5.5\n","1108 tensor(0.4078, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.6702943096716805 5.3\n","1109 tensor(0.5208, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.6706240153620088 5.0\n","1110 tensor(0.3920, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6709533913466468 5.7\n","1111 tensor(0.4165, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6712824379553002 4.9\n","1112 tensor(0.4392, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.6716111555173448 6.0\n","1113 tensor(0.4654, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.6719395443618275 6.0\n","1114 tensor(0.4565, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.6722676048174656 6.9\n","1115 tensor(0.4314, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.6725953372126482 6.8\n","1116 tensor(0.3974, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.6729227418754355 7.9\n","1117 tensor(0.3957, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.6732498191335601 8.2\n","1118 tensor(0.4735, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.6735765693144266 8.1\n","1119 tensor(0.4646, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6739029927451121 7.9\n","1120 tensor(0.3944, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6742290897523671 7.9\n","1121 tensor(0.3985, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.6745548606626146 9.0\n","1122 tensor(0.4088, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.6748803058019521 8.2\n","1123 tensor(0.4185, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.6752054254961501 8.5\n","1124 tensor(0.4137, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.675530220070654 8.5\n","1125 tensor(0.4166, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6758546898505833 8.4\n","1126 tensor(0.3704, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.6761788351607327 8.0\n","1127 tensor(0.3960, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.676502656325572 6.9\n","1128 tensor(0.4387, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.6768261536692464 7.4\n","1129 tensor(0.4194, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6771493275155771 8.1\n","1130 tensor(0.4225, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.6774721781880616 7.8\n","1131 tensor(0.4384, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.6777947060098735 7.4\n","1132 tensor(0.4622, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.6781169113038636 7.7\n","1133 tensor(0.3671, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.6784387943925598 7.9\n","1134 tensor(0.4068, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6787603555981672 6.9\n","1135 tensor(0.3898, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.6790815952425691 6.7\n","1136 tensor(0.4764, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.6794025136473265 7.0\n","1137 tensor(0.3686, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.6797231111336792 8.0\n","1138 tensor(0.3732, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.6800433880225455 7.6\n","1139 tensor(0.4539, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.680363344634523 7.4\n","1140 tensor(0.4487, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.6806829812898885 7.3\n","1141 tensor(0.4965, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.6810022983085986 7.8\n","1142 tensor(0.4646, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.68132129601029 7.2\n","1143 tensor(0.4592, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.6816399747142797 6.8\n","1144 tensor(0.4819, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.6819583347395655 7.7\n","1145 tensor(0.4433, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6822763764048259 7.2\n","1146 tensor(0.3843, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.682594100028421 6.9\n","1147 tensor(0.3989, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.6829115059283927 6.4\n","1148 tensor(0.4121, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.6832285944224643 6.8\n","1149 tensor(0.4742, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.6835453658280417 6.9\n","1150 tensor(0.4766, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6838618204622138 6.5\n","1151 tensor(0.4970, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.6841779586417516 6.3\n","1152 tensor(0.4476, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.6844937806831097 6.7\n","1153 tensor(0.3568, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.6848092869024267 6.4\n","1154 tensor(0.4718, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.6851244776155242 6.1\n","1155 tensor(0.4169, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.6854393531379086 6.7\n","1156 tensor(0.4576, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6857539137847708 6.1\n","1157 tensor(0.4309, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.6860681598709859 6.6\n","1158 tensor(0.4952, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.686382091711115 5.7\n","1159 tensor(0.4903, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.6866957096194038 5.6\n","1160 tensor(0.4120, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6870090139097844 6.4\n","1161 tensor(0.4873, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.6873220048958747 6.6\n","1162 tensor(0.5036, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.6876346828909788 6.8\n","1163 tensor(0.4533, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.6879470482080878 7.4\n","1164 tensor(0.4628, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.6882591011598798 7.7\n","1165 tensor(0.4766, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.68857084205872 7.9\n","1166 tensor(0.3767, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.6888822712166612 8.6\n","1167 tensor(0.4289, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.6891933889454446 8.5\n","1168 tensor(0.5539, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.6895041955564991 9.4\n","1169 tensor(0.4113, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6898146913609426 8.9\n","1170 tensor(0.4220, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.6901248766695817 9.1\n","1171 tensor(0.3792, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.6904347517929121 8.5\n","1172 tensor(0.4556, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6907443170411192 8.8\n","1173 tensor(0.4122, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.6910535727240781 8.9\n","1174 tensor(0.4002, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6913625191513539 8.8\n","1175 tensor(0.4196, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.6916711566322026 8.4\n","1176 tensor(0.4310, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.6919794854755703 8.8\n","1177 tensor(0.4429, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.6922875059900948 8.6\n","1178 tensor(0.4204, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6925952184841047 8.4\n","1179 tensor(0.4558, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.6929026232656206 9.0\n","1180 tensor(0.4194, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6932097206423551 7.9\n","1181 tensor(0.4547, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.6935165109217127 7.7\n","1182 tensor(0.3993, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.693822994410791 7.5\n","1183 tensor(0.4327, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.6941291714163802 7.0\n","1184 tensor(0.4046, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.6944350422449639 7.3\n","1185 tensor(0.4737, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6947406072027189 7.6\n","1186 tensor(0.4627, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.6950458665955161 6.7\n","1187 tensor(0.4484, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6953508207289206 6.1\n","1188 tensor(0.4545, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.6956554699081917 5.8\n","1189 tensor(0.4617, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.6959598144382835 5.4\n","1190 tensor(0.4261, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.6962638546238453 6.2\n","1191 tensor(0.3827, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6965675907692215 6.0\n","1192 tensor(0.4112, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.6968710231784522 5.6\n","1193 tensor(0.3898, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.6971741521552737 6.0\n","1194 tensor(0.4796, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.6974769780031185 5.7\n","1195 tensor(0.3814, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6977795010251153 5.0\n","1196 tensor(0.3921, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6980817215240902 4.9\n","1197 tensor(0.4484, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6983836398025662 4.8\n","1198 tensor(0.4668, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6986852561627637 4.4\n","1199 tensor(0.4452, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.6989865709066008 5.1\n","1200 tensor(0.4162, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.6992875843356943 5.6\n","1201 tensor(0.4561, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.6995882967513585 5.9\n","1202 tensor(0.3970, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.6998887084546072 6.8\n","1203 tensor(0.4328, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.7001888197461525 6.6\n","1204 tensor(0.4269, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7004886309264065 5.8\n","1205 tensor(0.4493, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.70078814229548 6.7\n","1206 tensor(0.4368, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7010873541531846 6.5\n","1207 tensor(0.4418, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7013862667990314 6.5\n","1208 tensor(0.4758, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.7016848805322322 7.1\n","1209 tensor(0.5222, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.7019831956517 6.9\n","1210 tensor(0.3947, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7022812124560484 5.8\n","1211 tensor(0.5414, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7025789312435924 5.5\n","1212 tensor(0.3748, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7028763523123487 4.5\n","1213 tensor(0.4163, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.7031734759600363 4.8\n","1214 tensor(0.4169, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.7034703024840763 5.2\n","1215 tensor(0.4500, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7037668321815922 4.1\n","1216 tensor(0.4032, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.7040630653494107 5.4\n","1217 tensor(0.4201, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.7043590022840612 5.8\n","1218 tensor(0.4192, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7046546432817772 5.2\n","1219 tensor(0.3999, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7049499886384953 4.7\n","1220 tensor(0.4215, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.7052450386498569 5.3\n","1221 tensor(0.3796, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.705539793611207 5.9\n","1222 tensor(0.4568, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.7058342538175958 6.6\n","1223 tensor(0.4508, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.7061284195637783 6.1\n","1224 tensor(0.4324, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7064222911442144 5.7\n","1225 tensor(0.4367, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.7067158688530701 6.9\n","1226 tensor(0.4287, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7070091529842171 5.6\n","1227 tensor(0.3680, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7073021438312329 5.2\n","1228 tensor(0.4384, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.7075948416874016 5.7\n","1229 tensor(0.3703, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.7078872468457142 6.1\n","1230 tensor(0.4300, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.7081793595988686 6.2\n","1231 tensor(0.4190, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7084711802392696 5.8\n","1232 tensor(0.4221, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.7087627090590304 5.4\n","1233 tensor(0.4203, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.7090539463499714 5.5\n","1234 tensor(0.4227, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.7093448924036214 5.9\n","1235 tensor(0.4296, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7096355475112178 5.8\n","1236 tensor(0.4529, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7099259119637066 6.1\n","1237 tensor(0.4558, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.7102159860517429 7.2\n","1238 tensor(0.4095, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7105057700656912 7.6\n","1239 tensor(0.3757, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7107952642956255 7.2\n","1240 tensor(0.4240, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.7110844690313298 7.3\n","1241 tensor(0.4733, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7113733845622985 8.0\n","1242 tensor(0.3739, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.7116620111777361 8.2\n","1243 tensor(0.4769, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7119503491665584 8.5\n","1244 tensor(0.4475, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.7122383988173919 9.2\n","1245 tensor(0.4861, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.7125261604185744 8.9\n","1246 tensor(0.4420, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.7128136342581559 9.6\n","1247 tensor(0.3764, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.7131008206238978 9.0\n","1248 tensor(0.4392, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7133877198032739 8.3\n","1249 tensor(0.4257, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7136743320834705 8.3\n","1250 tensor(0.4016, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.7139606577513871 8.1\n","1251 tensor(0.4038, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.7142466970936356 8.3\n","1252 tensor(0.4705, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.714532450396542 8.5\n","1253 tensor(0.4396, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7148179179461456 8.5\n","1254 tensor(0.4361, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7151031000281993 7.6\n","1255 tensor(0.4424, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.7153879969281711 7.7\n","1256 tensor(0.4240, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.7156726089312431 7.9\n","1257 tensor(0.4888, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7159569363223117 7.3\n","1258 tensor(0.4221, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7162409793859894 7.0\n","1259 tensor(0.4617, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.7165247384066035 7.5\n","1260 tensor(0.4246, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7168082136681968 7.0\n","1261 tensor(0.4073, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7170914054545287 6.8\n","1262 tensor(0.4213, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.7173743140490741 7.2\n","1263 tensor(0.4613, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.7176569397350251 7.3\n","1264 tensor(0.4411, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.7179392827952901 7.8\n","1265 tensor(0.4652, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.7182213435124948 7.7\n","1266 tensor(0.4729, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7185031221689823 6.5\n","1267 tensor(0.3721, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7187846190468132 6.5\n","1268 tensor(0.5308, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.7190658344277665 7.1\n","1269 tensor(0.4098, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7193467685933387 6.4\n","1270 tensor(0.4049, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7196274218247454 6.3\n","1271 tensor(0.4207, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.7199077944029206 5.8\n","1272 tensor(0.3987, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7201878866085176 5.6\n","1273 tensor(0.5176, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.7204676987219092 5.6\n","1274 tensor(0.4984, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.7207472310231873 5.7\n","1275 tensor(0.3848, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.721026483792164 6.2\n","1276 tensor(0.3924, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7213054573083719 6.4\n","1277 tensor(0.3805, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7215841518510635 6.4\n","1278 tensor(0.4400, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.7218625676992125 6.2\n","1279 tensor(0.4468, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7221407051315132 6.3\n","1280 tensor(0.4563, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.7224185644263817 6.8\n","1281 tensor(0.4823, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.7226961458619554 6.7\n","1282 tensor(0.4869, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7229734497160933 5.6\n","1283 tensor(0.4366, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7232504762663773 4.6\n","1284 tensor(0.4441, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7235272257901109 3.8\n","1285 tensor(0.4478, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.7238036985643208 3.3\n","1286 tensor(0.3971, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.7240798948657565 4.3\n","1287 tensor(0.3962, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.7243558149708906 4.8\n","1288 tensor(0.4733, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.7246314591559198 5.1\n","1289 tensor(0.4333, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.7249068276967638 6.0\n","1290 tensor(0.3963, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.7251819208690671 6.5\n","1291 tensor(0.4203, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.7254567389481981 6.8\n","1292 tensor(0.4625, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7257312822092499 7.2\n","1293 tensor(0.4516, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.7260055509270407 7.9\n","1294 tensor(0.4072, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.7262795453761135 8.4\n","1295 tensor(0.4324, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.7265532658307374 8.3\n","1296 tensor(0.3946, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7268267125649066 8.2\n","1297 tensor(0.4415, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.7270998858523418 8.2\n","1298 tensor(0.4141, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7273727859664894 8.5\n","1299 tensor(0.4364, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.727645413180523 7.4\n","1300 tensor(0.4679, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.7279177677673424 6.9\n","1301 tensor(0.3652, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.7281898499995751 6.8\n","1302 tensor(0.4181, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7284616601495755 6.7\n","1303 tensor(0.3855, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.728733198489426 6.5\n","1304 tensor(0.5028, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.7290044652909365 7.2\n","1305 tensor(0.3783, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.7292754608256455 7.7\n","1306 tensor(0.4290, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.72954618536482 6.7\n","1307 tensor(0.4336, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7298166391794552 6.4\n","1308 tensor(0.3993, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7300868225402757 6.4\n","1309 tensor(0.4457, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7303567357177354 7.4\n","1310 tensor(0.4888, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.7306263789820177 7.6\n","1311 tensor(0.4682, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.7308957526030356 7.5\n","1312 tensor(0.4165, device='cuda:0', grad_fn=<MeanBackward0>) 15 0.7311648568504325 8.7\n","1313 tensor(0.4904, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7314336919935822 8.0\n","1314 tensor(0.4460, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7317022583015886 6.8\n","1315 tensor(0.4608, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.731970556043287 6.8\n","1316 tensor(0.4421, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.7322385854872437 7.7\n","1317 tensor(0.4055, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7325063469017564 7.7\n","1318 tensor(0.4093, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.7327738405548547 7.3\n","1319 tensor(0.4391, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7330410667142998 6.2\n","1320 tensor(0.3726, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7333080256475855 5.7\n","1321 tensor(0.4238, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.7335747176219379 6.4\n","1322 tensor(0.4391, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.733841142904316 5.8\n","1323 tensor(0.4426, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7341073017614117 5.9\n","1324 tensor(0.4153, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.7343731944596503 6.7\n","1325 tensor(0.4522, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7346388212651906 5.9\n","1326 tensor(0.4707, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7349041824439255 4.9\n","1327 tensor(0.4410, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7351692782614816 4.7\n","1328 tensor(0.4361, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.73543410898322 4.4\n","1329 tensor(0.3836, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7356986748742368 5.5\n","1330 tensor(0.4179, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.7359629761993626 6.3\n","1331 tensor(0.3580, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.7362270132231632 5.7\n","1332 tensor(0.4703, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.73649078620994 5.0\n","1333 tensor(0.4554, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.73675429542373 5.9\n","1334 tensor(0.4605, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.7370175411283063 5.7\n","1335 tensor(0.3886, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.737280523587178 6.4\n","1336 tensor(0.4054, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.7375432430635909 7.1\n","1337 tensor(0.3571, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7378056998205272 7.3\n","1338 tensor(0.4624, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.7380678941207067 7.8\n","1339 tensor(0.4183, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.738329826226586 7.9\n","1340 tensor(0.4017, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.7385914964003595 7.4\n","1341 tensor(0.4604, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.738852904903959 7.6\n","1342 tensor(0.4023, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7391140519990551 7.4\n","1343 tensor(0.4660, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.739374937947056 7.4\n","1344 tensor(0.4740, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.7396355630091089 7.6\n","1345 tensor(0.4066, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7398959274460999 7.6\n","1346 tensor(0.3809, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7401560315186537 6.9\n","1347 tensor(0.4741, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.7404158754871351 7.4\n","1348 tensor(0.4294, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.740675459611648 7.0\n","1349 tensor(0.4705, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.7409347841520364 6.3\n","1350 tensor(0.4396, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.7411938493678842 6.2\n","1351 tensor(0.4110, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.7414526555185164 6.2\n","1352 tensor(0.3917, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.741711202862998 6.4\n","1353 tensor(0.4061, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.7419694916601349 6.6\n","1354 tensor(0.4335, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7422275221684749 6.8\n","1355 tensor(0.4427, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7424852946463063 6.0\n","1356 tensor(0.4367, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.74274280935166 6.3\n","1357 tensor(0.4673, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.7430000665423084 6.6\n","1358 tensor(0.3899, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7432570664757661 7.2\n","1359 tensor(0.4426, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.7435138094092903 7.6\n","1360 tensor(0.4100, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7437702955998811 7.1\n","1361 tensor(0.3977, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7440265253042811 6.4\n","1362 tensor(0.4234, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.7442824987789769 7.4\n","1363 tensor(0.4622, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.7445382162801979 6.7\n","1364 tensor(0.4243, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7447936780639177 5.9\n","1365 tensor(0.3967, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.7450488843858538 6.6\n","1366 tensor(0.4473, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.7453038355014678 7.5\n","1367 tensor(0.4402, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.7455585316659664 7.4\n","1368 tensor(0.4592, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.7458129731343004 6.9\n","1369 tensor(0.4440, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7460671601611661 6.0\n","1370 tensor(0.4038, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.7463210930010049 6.9\n","1371 tensor(0.4605, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.746574771908004 7.5\n","1372 tensor(0.4478, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7468281971360959 6.3\n","1373 tensor(0.4904, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.7470813689389599 6.7\n","1374 tensor(0.4559, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.7473342875700208 7.2\n","1375 tensor(0.4332, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.7475869532824508 7.1\n","1376 tensor(0.4343, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.7478393663291685 7.2\n","1377 tensor(0.4934, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7480915269628392 6.5\n","1378 tensor(0.4300, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7483434354358764 7.0\n","1379 tensor(0.4155, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.7485950920004405 8.0\n","1380 tensor(0.4290, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.7488464969084401 7.6\n","1381 tensor(0.4574, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7490976504115316 7.2\n","1382 tensor(0.4626, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.7493485527611201 8.5\n","1383 tensor(0.5090, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.749599204208359 8.7\n","1384 tensor(0.4808, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.7498496050041508 8.6\n","1385 tensor(0.3955, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7500997553991465 7.7\n","1386 tensor(0.4477, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7503496556437474 7.5\n","1387 tensor(0.4148, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.7505993059881036 8.3\n","1388 tensor(0.4764, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.7508487066821156 8.2\n","1389 tensor(0.4220, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.7510978579754335 8.0\n","1390 tensor(0.4700, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.7513467601174579 8.4\n","1391 tensor(0.4272, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7515954133573406 8.4\n","1392 tensor(0.4155, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.7518438179439833 8.0\n","1393 tensor(0.4404, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.7520919741260392 7.8\n","1394 tensor(0.4219, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.7523398821519132 7.8\n","1395 tensor(0.4434, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7525875422697612 8.2\n","1396 tensor(0.4542, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7528349547274915 8.2\n","1397 tensor(0.4047, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.753082119772764 7.4\n","1398 tensor(0.4680, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.7533290376529912 6.9\n","1399 tensor(0.4281, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.7535757086153383 6.7\n","1400 tensor(0.3700, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.753822132906723 5.8\n","1401 tensor(0.4266, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.7540683107738162 5.9\n","1402 tensor(0.3765, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.7543142424630424 6.0\n","1403 tensor(0.4608, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7545599282205793 5.3\n","1404 tensor(0.3782, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7548053682923588 4.9\n","1405 tensor(0.4760, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.7550505629240664 5.0\n","1406 tensor(0.5069, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.7552955123611422 4.5\n","1407 tensor(0.4669, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7555402168487811 4.4\n","1408 tensor(0.5020, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7557846766319324 3.9\n","1409 tensor(0.4325, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7560288919553004 3.5\n","1410 tensor(0.4498, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.7562728630633451 4.3\n","1411 tensor(0.4329, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7565165902002817 3.9\n","1412 tensor(0.4407, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.7567600736100815 3.7\n","1413 tensor(0.4305, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7570033135364714 3.7\n","1414 tensor(0.4488, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.757246310222935 3.6\n","1415 tensor(0.3657, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.757489063912712 3.6\n","1416 tensor(0.4527, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.7577315748487993 4.3\n","1417 tensor(0.4393, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7579738432739505 4.6\n","1418 tensor(0.4850, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.7582158694306765 5.9\n","1419 tensor(0.4240, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.7584576535612458 6.2\n","1420 tensor(0.4103, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7586991959076846 6.4\n","1421 tensor(0.4499, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.758940496711777 7.6\n","1422 tensor(0.4354, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.7591815562150652 7.6\n","1423 tensor(0.4453, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7594223746588501 7.8\n","1424 tensor(0.4455, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.7596629522841912 8.4\n","1425 tensor(0.3870, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.7599032893319071 8.7\n","1426 tensor(0.3867, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.7601433860425751 8.6\n","1427 tensor(0.4225, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.7603832426565326 9.5\n","1428 tensor(0.4548, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.7606228594138761 9.5\n","1429 tensor(0.4943, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7608622365544622 10.1\n","1430 tensor(0.4097, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7611013743179077 10.1\n","1431 tensor(0.4438, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7613402729435899 9.9\n","1432 tensor(0.4144, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.7615789326706462 10.0\n","1433 tensor(0.4480, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.7618173537379755 10.8\n","1434 tensor(0.4422, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.7620555363842376 10.7\n","1435 tensor(0.3833, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.7622934808478534 10.9\n","1436 tensor(0.4127, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.7625311873670055 10.7\n","1437 tensor(0.4309, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7627686561796385 10.5\n","1438 tensor(0.4817, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7630058875234589 9.2\n","1439 tensor(0.4502, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7632428816359355 9.2\n","1440 tensor(0.4367, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7634796387542995 8.1\n","1441 tensor(0.4421, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7637161591155452 7.0\n","1442 tensor(0.3986, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.7639524429564296 6.9\n","1443 tensor(0.4319, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7641884905134733 5.9\n","1444 tensor(0.3577, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7644243020229597 5.2\n","1445 tensor(0.4763, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.7646598777209368 4.9\n","1446 tensor(0.4639, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.7648952178432159 5.1\n","1447 tensor(0.4415, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7651303226253727 5.1\n","1448 tensor(0.4118, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.7653651923027474 5.8\n","1449 tensor(0.4159, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7655998271104445 5.0\n","1450 tensor(0.4100, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.7658342272833341 6.0\n","1451 tensor(0.4706, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.7660683930560508 7.3\n","1452 tensor(0.4793, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.7663023246629947 7.1\n","1453 tensor(0.4423, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7665360223383317 7.2\n","1454 tensor(0.4309, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.7667694863159934 8.4\n","1455 tensor(0.4075, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.7670027168296775 8.7\n","1456 tensor(0.4027, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.7672357141128477 8.8\n","1457 tensor(0.3562, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7674684783987349 8.0\n","1458 tensor(0.3873, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.7677010099203362 8.2\n","1459 tensor(0.3947, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.7679333089104159 8.5\n","1460 tensor(0.3937, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.7681653756015054 8.1\n","1461 tensor(0.4574, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.7683972102259039 7.4\n","1462 tensor(0.4619, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.768628813015678 7.4\n","1463 tensor(0.4632, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.7688601842026623 8.4\n","1464 tensor(0.4351, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.7690913240184597 8.5\n","1465 tensor(0.5026, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.7693222326944412 8.0\n","1466 tensor(0.3745, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.7695529104617468 7.6\n","1467 tensor(0.3899, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7697833575512851 7.6\n","1468 tensor(0.4446, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.7700135741937337 8.0\n","1469 tensor(0.4112, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.77024356061954 7.6\n","1470 tensor(0.4713, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7704733170589205 7.4\n","1471 tensor(0.4317, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7707028437418616 7.9\n","1472 tensor(0.4805, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.7709321408981197 8.6\n","1473 tensor(0.4918, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.7711612087572216 8.1\n","1474 tensor(0.3898, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7713900475484643 6.9\n","1475 tensor(0.4311, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.7716186575009158 7.4\n","1476 tensor(0.4069, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.771847038843415 7.3\n","1477 tensor(0.3984, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7720751918045715 7.2\n","1478 tensor(0.4057, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.772303116612767 6.5\n","1479 tensor(0.4092, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7725308134961542 6.7\n","1480 tensor(0.4421, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.772758282682658 6.9\n","1481 tensor(0.4442, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7729855243999754 6.1\n","1482 tensor(0.4662, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7732125388755754 5.1\n","1483 tensor(0.4644, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.7734393263366999 5.5\n","1484 tensor(0.4656, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7736658870103631 6.5\n","1485 tensor(0.4729, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7738922211233528 6.6\n","1486 tensor(0.4337, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.7741183289022294 6.8\n","1487 tensor(0.4196, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.7743442105733271 7.4\n","1488 tensor(0.3168, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.7745698663627538 7.7\n","1489 tensor(0.4135, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.7747952964963911 8.0\n","1490 tensor(0.4433, device='cuda:0', grad_fn=<MeanBackward0>) 15 0.7750205011998947 8.9\n","1491 tensor(0.3879, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7752454806986948 9.0\n","1492 tensor(0.5054, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.7754702352179961 9.6\n","1493 tensor(0.4028, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7756947649827781 9.5\n","1494 tensor(0.4837, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7759190702177954 8.6\n","1495 tensor(0.3826, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.7761431511475776 8.5\n","1496 tensor(0.4791, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.77636700799643 8.3\n","1497 tensor(0.3969, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7765906409884336 7.9\n","1498 tensor(0.4398, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.7768140503474452 7.5\n","1499 tensor(0.4165, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.7770372362970978 8.1\n","1500 tensor(0.4328, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.7772601990608006 7.1\n","1501 tensor(0.4260, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.7774829388617398 7.4\n","1502 tensor(0.4148, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.7777054559228781 7.3\n","1503 tensor(0.4199, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7779277504669553 6.4\n","1504 tensor(0.3740, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.7781498227164882 7.5\n","1505 tensor(0.4561, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7783716728937717 6.7\n","1506 tensor(0.4005, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.778593301220878 6.6\n","1507 tensor(0.4558, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.7788147079196571 7.4\n","1508 tensor(0.4355, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7790358932117375 7.1\n","1509 tensor(0.3943, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7792568573185258 5.8\n","1510 tensor(0.3886, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.7794776004612072 6.3\n","1511 tensor(0.4591, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.779698122860746 6.3\n","1512 tensor(0.4058, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7799184247378853 5.6\n","1513 tensor(0.4306, device='cuda:0', grad_fn=<MeanBackward0>) 14 0.7801385063131474 6.8\n","1514 tensor(0.4701, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.7803583678068342 6.8\n","1515 tensor(0.4673, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.7805780094390274 7.5\n","1516 tensor(0.4693, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.7807974314295885 7.7\n","1517 tensor(0.4827, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.7810166339981588 7.5\n","1518 tensor(0.4089, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7812356173641607 7.7\n","1519 tensor(0.4569, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.7814543817467965 8.7\n","1520 tensor(0.3988, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7816729273650498 7.8\n","1521 tensor(0.4080, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.7818912544376847 8.3\n","1522 tensor(0.4591, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.782109363183247 8.5\n","1523 tensor(0.4602, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7823272538200637 8.2\n","1524 tensor(0.4306, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.7825449265662436 8.0\n","1525 tensor(0.4082, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.7827623816396775 8.4\n","1526 tensor(0.4290, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.7829796192580378 8.0\n","1527 tensor(0.4706, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7831966396387797 7.1\n","1528 tensor(0.4453, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.783413442999141 6.8\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 64\u001b[0m\n\u001b[1;32m     60\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Perform one step of the optimization (on the policy network)\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m optimize_model()\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Soft update of the target network's weights\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# θ′ ← τ θ + (1 −τ )θ′\u001b[39;00m\n\u001b[1;32m     68\u001b[0m target_net_state_dict \u001b[38;5;241m=\u001b[39m target_net\u001b[38;5;241m.\u001b[39mstate_dict()\n","Cell \u001b[0;32mIn[23], line 69\u001b[0m, in \u001b[0;36moptimize_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# print(loss)\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# if (optimize_model.count % 60 == 0): print(loss)\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# print(loss)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m#     print(loss)\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# Optimize the model\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 69\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# In-place gradient clipping\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m#     torch.nn.utils.clip_grad_value_(policy_net.parameters(), 1)\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    523\u001b[0m )\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m _engine_run_backward(\n\u001b[1;32m    290\u001b[0m     tensors,\n\u001b[1;32m    291\u001b[0m     grad_tensors_,\n\u001b[1;32m    292\u001b[0m     retain_graph,\n\u001b[1;32m    293\u001b[0m     create_graph,\n\u001b[1;32m    294\u001b[0m     inputs,\n\u001b[1;32m    295\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    296\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    297\u001b[0m )\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    769\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    770\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["if torch.cuda.is_available():\n","    num_episodes = 600\n","else:\n","    num_episodes = 500\n","    \n","num_episodes = 1000000\n","\n","for i_episode in range(num_episodes):\n","    # if((i_episode + 1) % 25 == 0):\n","    #     with open(\"train_dqn_\" + str(i_episode + 1) + \".pkl\", 'wb') as file:\n","    # # Serialize and write the object to the file\n","    #         pickle.dump(policy_net, file)\n","\n","    # Initialize the environment and get its state\n","    env.reset()\n","    state = get_state(env.state())\n","#     state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n","    tot_rew = 0\n","\n","    for t in count():\n","        # print(t)\n","        action = select_action(state)\n","        # print(action)\n","        # Act according to the action and observe the transition and reward\n","        reward, done = env.act(action)\n","        observation = get_state(env.state())\n","        # if (np.mean(episode_durations[-10:]) >= 25) :\n","            # env.display_state(500)\n","            # env.close_display()\n","        \n","#         observation, reward, done, info, _= env.step(action.item())\n","        # print(rew)\n","\n","        #For mountain car HEREEEE\n","        # state_0 = state[0][0].item()\n","        # reward = 50 if observation[0]>=0.5 else abs(observation[0] - state_0)*100\n","        # print(reward)\n","        \n","        tot_rew += reward\n","        \n","        reward = torch.tensor([reward], device=device)\n","\n","        # try gamma later\n","        \n","        # print(tot_rew)\n","\n","        \n","\n","        if done:\n","            next_state = None\n","        else:\n","            next_state = (observation)\n","\n","#         done = done or info\n","        \n","        # Store the transition in memory\n","        memory.push(state, action, next_state, reward)\n","        # Move to the next state\n","#         print(policy_net.forward(state))\n","        state = next_state\n","\n","        # Perform one step of the optimization (on the policy network)\n","\n","        optimize_model()\n","\n","        # Soft update of the target network's weights\n","        # θ′ ← τ θ + (1 −τ )θ′\n","        target_net_state_dict = target_net.state_dict()\n","        policy_net_state_dict = policy_net.state_dict()\n","        for key in policy_net_state_dict:\n","            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n","        target_net.load_state_dict(target_net_state_dict)\n","\n","        if done:\n","            episode_durations.append(tot_rew)\n","            corr_mult *= 0.999\n","            if i_episode >= 1:# and np.remainder(i_episode,100) == 0:\n","                print(i_episode,call_correlation_coeff_kmeans(),tot_rew,1- corr_mult,np.mean(episode_durations[-10:]))\n","            # plot_durations()\n","#                 print(i_episode, tot_rew)\n","            break\n","    \n","    # if np.mean(episode_durations[-10:]) > 8:\n","    #     break\n","    if len(episode_durations) >= 3000:\n","        break\n","env.close_display()\n","# print('Complete')\n","# plot_durations(show_result=True)\n","# plt.ioff()\n","# plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Noisy evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# num_episodes = 100\n","# episode_durations = []\n","# for i_episode in range(num_episodes):\n","#     # if((i_episode + 1) % 25 == 0):\n","#     #     with open(\"train_dqn_\" + str(i_episode + 1) + \".pkl\", 'wb') as file:\n","#     # # Serialize and write the object to the file\n","#     #         pickle.dump(policy_net, file)\n","\n","#     # Initialize the environment and get its state\n","#     state, info = env.reset()\n","#     state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n","#     tot_rew = 0\n","\n","#     for t in count():\n","#         # print(t)\n","#         state += torch.randn(state.size())*1\n","#         action = select_action(state)\n","#         # print(action)\n","#         observation, reward, done, info, _= env.step(action.item())\n","#         # print(rew)\n","\n","#         #For mountain car HEREEEE\n","#         # state_0 = state[0][0].item()\n","#         # reward = 50 if observation[0]>=0.5 else abs(observation[0] - state_0)*100\n","#         # print(reward)\n","\n","#         tot_rew += reward\n","        \n","#         reward = torch.tensor([reward], device=device)\n","\n","#         # try gamma later\n","        \n","#         # print(tot_rew)\n","\n","        \n","\n","#         if done:\n","#             next_state = None\n","#         else:\n","#             next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n","\n","#         done = done or info\n","        \n","#         # Store the transition in memory\n","# #         memory.push(state, action, next_state, reward)\n","\n","#         # Move to the next state\n","#         state = next_state\n","\n","#         # Perform one step of the optimization (on the policy network)\n","\n","# #         optimize_model()\n","\n","#         # Soft update of the target network's weights\n","#         # θ′ ← τ θ + (1 −τ )θ′\n","# #         target_net_state_dict = target_net.state_dict()\n","# #         policy_net_state_dict = policy_net.state_dict()\n","# #         for key in policy_net_state_dict:\n","# #             target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n","# #         target_net.load_state_dict(target_net_state_dict)\n","\n","#         if done:\n","#             episode_durations.append(tot_rew)\n","# #             if i_episode > 1:# and np.remainder(i_episode,100) == 0:\n","#             print(i_episode,call_correlation_coeff_kmeans(),tot_rew)\n","#             # plot_durations()\n","#             break\n","# print(np.mean(episode_durations))\n","\n","# # print('Complete')\n","# # plot_durations(show_result=True)\n","# # plt.ioff()\n","# # plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pickle\n","with open(\"dqn_lr_-4.pkl\", 'wb') as file:\n","    # Serialize and write the object to the file\n","    pickle.dump(policy_net, file)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-09-05T15:04:10.520665Z","iopub.status.busy":"2024-09-05T15:04:10.520185Z","iopub.status.idle":"2024-09-05T15:04:10.530274Z","shell.execute_reply":"2024-09-05T15:04:10.528996Z","shell.execute_reply.started":"2024-09-05T15:04:10.520628Z"},"trusted":true},"outputs":[],"source":["import pickle\n","with open(\"/kaggle/input/pickle-file/corr_dqn.pkl\", 'rb') as file:\n","    # Serialize and write the object to the file\n","    policy_net = pickle.load(file)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pickle\n","with open(\"dqn.pkl\", 'wb') as file:\n","    # Serialize and write the object to the file\n","    pickle.dump(policy_net, file)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pickle\n","with open(\"dqn_plain.pkl\", 'wb') as file:\n","    # Serialize and write the object to the file\n","    pickle.dump(policy_net, file)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pickle\n","with open(\"dqn_plain.pkl\", 'rb') as file:\n","    # Serialize and write the object to the file\n","    policy_net = pickle.load(file)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pickle\n","with open(\"dqn.pkl\", 'rb') as file:\n","    # Serialize and write the object to the file\n","    policy_net = pickle.load(file)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T10:24:42.299480Z","iopub.status.busy":"2024-09-06T10:24:42.298582Z","iopub.status.idle":"2024-09-06T10:24:42.307030Z","shell.execute_reply":"2024-09-06T10:24:42.305413Z","shell.execute_reply.started":"2024-09-06T10:24:42.299444Z"},"trusted":true},"outputs":[],"source":["def phi_wrapper(state, marker = 0):\n","    if(marker == 1): state = state[0]\n","    # print(\"hello\" + str(state.shape))\n","    state = get_state(state)\n","    x = policy_net.forward_correlation((state)).detach().cpu().numpy()\n","    return x #x/np.linalg.norm(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class phi(nn.Module):\n","\n","    def __init__(self, dqn):\n","        super(phi, self).__init__()\n","        self.layer1 = dqn.layer1\n","        self.layer2 = dqn.layer2\n","#         self.layer3 = dqn.layer3\n","        # self.layer4 = dqn.layer4\n","\n","        # self.layer3 = nn.Linear(128, n_actions)\n","\n","    # Called with either one element to determine next action, or a batch\n","    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n","    def forward(self, x):         \n","        x = torch.tensor(x)\n","        x = F.relu(self.layer1(x))\n","#         x = F.relu(self.layer2(x))\n","        # x = F.relu(self.layer3(x))\n","        # x = F.relu(self.layer4(x))\n","        # x = F.relu(self.layer2(x))\n","        return F.relu(self.layer2(x))\n","    def forward_correlation(self, x):\n","        x = F.relu(self.layer1(x))\n","#         x = F.relu(self.layer2(x))\n","#         x = F.relu(self.layer3(x))\n","        # x = F.relu(self.layer4(x))\n","        return F.relu(self.layer2(x))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["trained_phi = phi(policy_net)\n"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-09-05T10:18:55.068343Z","iopub.status.busy":"2024-09-05T10:18:55.067888Z","iopub.status.idle":"2024-09-05T10:18:55.078214Z","shell.execute_reply":"2024-09-05T10:18:55.077037Z","shell.execute_reply.started":"2024-09-05T10:18:55.068309Z"},"trusted":true},"outputs":[],"source":["import pickle\n","with open(\"/kaggle/working/corr_dqn.pkl\", \"wb\") as file:\n","    pickle.dump(policy_net, file)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pickle\n","with open(\"trained_phi.pkl\", 'wb') as file:\n","    # Serialize and write the object to the file\n","    pickle.dump(trained_phi, file)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pickle\n","with open(\"/kaggle/working/trained_phi.pkl\", 'rb') as file:\n","    # Serialize and write the object to the file\n","    policy_net = pickle.load(file)"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T15:48:57.735821Z","iopub.status.busy":"2024-09-06T15:48:57.734997Z","iopub.status.idle":"2024-09-06T15:48:57.745344Z","shell.execute_reply":"2024-09-06T15:48:57.743807Z","shell.execute_reply.started":"2024-09-06T15:48:57.735765Z"},"trusted":true},"outputs":[],"source":["num_features = 128  # Number of features (state dimensions)\n","num_actions = env.num_actions()  # Number of actions\n","weights = np.zeros((num_features, num_actions))\n"]},{"cell_type":"markdown","metadata":{},"source":["# new corrected code for script"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T15:48:57.747780Z","iopub.status.busy":"2024-09-06T15:48:57.747297Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1.0 1\n","1.1 2\n","1.7 1\n"]},{"name":"stdout","output_type":"stream","text":["2.3 4\n","2.3 1\n","2.1 2\n","2.6 2\n","2.5 8\n","4.4 0\n","3.2 6\n","3.0 2\n","2.7 3\n","3.7 3\n","3.6 5\n","4.8 2\n","4.5 1\n","3.1 2\n","6.4 1\n","4.0 13\n","3.3 1\n","5.8 3\n","6.2 4\n","10.0 19\n","5.5 8\n","8.9 12\n","10.6 2\n","7.1 2\n","7.4 16\n","10.5 10\n","9.3 16\n","4.4 9\n","8.8 5\n","10.1 7\n","9.0 1\n","8.4 3\n","9.6 4\n","9.4 0\n","9.9 3\n","7.3 6\n","16.1 21\n","12.8 4\n","13.7 7\n","7.8 22\n","5.1 1\n","7.5 11\n","8.8 18\n","5.2 4\n","12.6 35\n","8.7 4\n","10.0 10\n","11.3 17\n","8.8 12\n","12.5 28\n","7.6 13\n","12.3 7\n","9.9 20\n","12.4 11\n","12.3 6\n","4.7 1\n","9.1 19\n","7.5 5\n","15.7 11\n","9.4 9\n","6.1 9\n","8.6 9\n","10.2 21\n","9.2 15\n","16.6 11\n","14.3 23\n","9.9 14\n","15.1 8\n","12.5 7\n","9.3 12\n","11.4 17\n","14.9 9\n","14.8 40\n","7.6 3\n","11.0 36\n","6.4 6\n","11.3 5\n","7.3 7\n","13.4 4\n","17.1 23\n","14.1 7\n","5.5 18\n","16.4 21\n","12.6 7\n","12.8 16\n","7.2 3\n","4.7 10\n","15.0 16\n","11.3 1\n","9.6 19\n","13.3 22\n","9.6 22\n","6.6 7\n","12.2 22\n","8.1 14\n","8.1 5\n","12.8 19\n","10.0 5\n","10.4 11\n","9.0 22\n","16.3 20\n","17.1 20\n","16.9 4\n","8.4 19\n","7.7 6\n","13.1 3\n","12.4 7\n","10.4 2\n","17.1 40\n","12.8 23\n","11.5 8\n","10.6 22\n","15.2 9\n","12.0 2\n","19.0 9\n","18.8 3\n","11.8 4\n","10.9 1\n","6.0 4\n","16.9 0\n","12.6 22\n","10.8 5\n","10.3 15\n","13.7 8\n","14.4 17\n","18.7 22\n","11.7 9\n","15.4 7\n","10.7 23\n","8.8 3\n","8.4 22\n","15.2 17\n","6.2 9\n","14.0 11\n","18.8 20\n","15.2 4\n","14.0 8\n","15.4 23\n","17.1 13\n","6.5 20\n","13.4 18\n","16.0 4\n","9.0 6\n","9.5 4\n","12.6 11\n","10.8 16\n","16.6 14\n","17.0 9\n","14.8 3\n","9.5 6\n","17.9 19\n","10.4 5\n","17.5 47\n","exit at 0 1558\n","2.0 2\n","2.0 1\n","2.2 2\n","3.7 3\n","2.6 2\n","3.4 0\n","3.3 2\n","1.7 4\n","5.2 5\n","4.1 11\n","5.5 5\n","4.8 4\n","5.2 22\n","3.9 5\n","3.3 1\n","5.3 4\n","6.0 2\n","7.8 7\n","5.7 5\n","4.9 1\n","7.4 8\n","6.3 3\n","5.5 9\n","8.5 13\n","4.9 6\n","8.5 4\n","11.3 10\n","11.7 18\n","9.3 20\n","8.5 18\n","10.5 10\n","16.7 3\n","2.1 1\n","8.0 13\n","10.1 18\n","9.9 14\n","6.8 1\n","7.9 2\n","9.5 5\n","11.7 19\n","5.0 5\n","10.1 7\n","8.6 1\n","14.0 4\n","11.4 11\n","4.8 3\n","9.7 7\n","11.6 23\n","12.5 14\n","13.3 3\n","14.8 21\n","10.4 10\n","9.7 6\n","7.4 3\n","7.6 0\n","8.6 4\n","13.2 17\n","8.0 10\n","6.8 10\n","10.7 15\n","7.5 12\n","19.6 12\n","12.3 3\n","14.0 4\n","8.3 3\n","7.5 2\n","2.7 4\n","10.2 10\n","7.4 3\n","8.0 0\n","6.4 7\n","8.9 8\n","10.4 7\n","21.7 6\n","7.4 14\n","11.6 2\n","7.1 1\n","11.5 7\n","10.6 4\n","9.8 6\n","11.9 11\n","10.2 7\n","9.3 6\n","10.7 9\n","16.0 23\n","16.0 18\n","8.2 0\n","15.1 21\n","8.3 2\n","13.6 5\n","10.2 13\n","13.1 4\n","15.6 7\n","18.0 17\n","11.3 6\n","14.4 23\n","9.8 3\n","6.1 6\n","17.9 23\n","19.3 10\n","10.8 3\n","9.7 11\n","14.8 10\n","17.2 23\n","14.0 4\n","12.0 4\n","11.5 3\n","13.8 12\n","11.0 6\n","18.3 14\n","13.5 6\n","14.3 4\n","8.3 7\n","16.8 19\n","8.7 13\n","14.6 16\n","12.6 21\n","13.3 3\n","7.8 7\n","19.8 3\n","10.0 1\n","7.5 3\n","16.9 20\n","18.8 21\n","16.0 22\n","11.5 5\n","11.6 6\n","15.0 7\n","14.1 2\n","22.5 52\n","16.1 4\n","5.5 7\n","14.8 19\n","24.5 40\n","9.0 5\n","18.8 7\n","19.7 47\n","exit at 1 1363\n","4.0 4\n","3.7 3\n","2.6 2\n","1.8 2\n","2.1 1\n","3.3 10\n","2.3 3\n","2.9 1\n","3.2 5\n","2.2 2\n","2.8 4\n","4.7 5\n","4.6 7\n","4.8 1\n","4.1 0\n","5.4 10\n","5.6 17\n","4.3 10\n","3.1 5\n","5.2 2\n","4.6 9\n","5.5 1\n","6.1 6\n","10.1 5\n","7.9 12\n","7.8 16\n","8.3 8\n","7.5 4\n","11.2 8\n","7.0 4\n","10.6 4\n","8.1 5\n","7.2 4\n","5.7 5\n","10.6 10\n","13.1 1\n","7.8 0\n","9.9 20\n","13.7 9\n","13.4 10\n","7.3 3\n","11.4 13\n","9.9 16\n","10.6 18\n","7.7 4\n","13.3 3\n","11.5 2\n","8.9 4\n","5.8 2\n","10.9 6\n","8.9 14\n","12.3 23\n","11.3 0\n","13.7 3\n","16.6 8\n","9.4 6\n","13.9 15\n","4.8 6\n","11.2 23\n","4.6 6\n","8.9 5\n","15.5 4\n","7.6 0\n","10.0 17\n","13.5 18\n","15.3 15\n","6.4 4\n","12.9 22\n","14.1 23\n","11.0 11\n","14.4 7\n","17.4 22\n","5.9 1\n","13.8 2\n","7.8 12\n","9.8 8\n","6.5 13\n","11.0 19\n","16.7 19\n","14.8 8\n","11.7 8\n","11.0 23\n","13.1 20\n","15.2 14\n","11.2 7\n","10.9 11\n","11.1 14\n","4.5 4\n","13.7 23\n","15.7 10\n","16.0 23\n","10.0 11\n","11.0 46\n","11.4 23\n","8.3 1\n","14.4 21\n","7.8 13\n","15.6 22\n","10.7 21\n","8.7 14\n","11.0 22\n","18.5 12\n","13.4 16\n","10.9 11\n","8.4 16\n","15.5 10\n","14.1 21\n","11.7 3\n","8.1 27\n","13.4 17\n","17.6 12\n","13.6 8\n","10.2 12\n","10.0 23\n","7.6 8\n","14.0 23\n","exit at 2 1158\n","3.0 3\n","2.9 1\n","3.2 3\n","2.2 5\n","1.9 5\n","3.0 4\n","2.2 4\n","2.3 2\n","2.3 1\n","2.5 1\n","2.2 1\n","3.8 3\n","4.1 1\n","3.2 1\n","3.1 6\n","4.1 7\n","5.0 2\n","3.6 1\n","6.3 4\n","5.9 1\n","5.8 6\n","9.3 4\n","12.9 8\n","8.9 18\n","9.5 1\n","9.9 8\n","4.8 2\n","9.0 4\n","14.0 15\n","7.7 4\n","9.8 19\n","10.0 24\n","6.7 23\n","11.8 21\n","9.1 11\n","9.2 1\n","10.7 16\n","9.6 4\n","9.5 1\n","17.4 26\n","8.0 2\n","13.0 1\n","10.2 5\n","12.7 5\n","8.0 5\n","13.3 47\n","11.4 14\n","3.2 3\n","5.7 11\n","6.1 14\n","5.5 23\n","10.0 6\n","8.9 19\n","11.9 11\n","6.9 6\n","11.2 14\n","11.5 5\n","10.6 19\n","5.3 3\n","9.2 11\n","13.3 18\n","11.2 18\n","8.0 7\n","9.3 18\n","13.8 7\n","12.9 42\n","14.2 47\n","9.0 4\n","9.5 4\n","12.1 13\n","8.0 6\n","10.2 3\n","17.6 22\n","20.7 6\n","14.5 4\n","10.8 11\n","5.6 3\n","10.9 23\n","18.0 20\n","8.6 0\n","8.2 23\n","12.1 2\n","14.6 5\n","12.3 32\n","10.5 4\n","11.7 9\n","16.7 8\n","16.2 22\n","17.5 18\n","13.0 2\n","13.0 14\n","17.3 6\n","9.4 3\n","7.9 16\n","12.6 23\n","8.2 3\n","11.3 32\n","10.7 7\n","14.4 26\n","15.6 12\n","9.6 1\n","10.3 16\n","14.8 8\n","13.2 4\n","14.2 13\n","11.9 8\n","6.0 9\n","14.2 20\n","10.5 8\n","16.3 17\n","11.2 22\n","9.2 7\n","12.6 7\n","8.5 7\n","18.6 23\n","17.1 43\n","13.6 25\n","15.7 22\n","15.6 43\n","14.8 9\n","13.4 5\n","13.6 23\n","15.3 9\n","13.6 15\n","16.9 10\n","9.1 7\n","16.4 23\n","19.3 18\n","20.1 33\n","13.7 15\n","10.1 7\n","10.8 10\n","19.4 9\n","8.7 13\n","16.0 22\n","8.2 6\n","17.3 53\n","7.4 15\n","9.1 1\n","16.9 18\n","11.8 9\n","22.3 17\n","9.5 9\n","18.2 23\n","18.3 21\n","12.6 43\n","exit at 3 1458\n","0.0 0\n","2.1 2\n","2.5 1\n","3.9 3\n","3.1 3\n","4.2 7\n","3.4 5\n","3.0 0\n","2.6 2\n","5.5 2\n","4.3 1\n","3.1 0\n","2.6 10\n","3.9 0\n","3.7 1\n","4.8 5\n","7.2 2\n","3.2 0\n","6.5 10\n","7.7 7\n","8.9 10\n","5.3 9\n","7.2 11\n","10.8 15\n","10.1 18\n","5.8 2\n","7.0 13\n","16.2 4\n","6.5 3\n","6.4 9\n","5.8 3\n","6.8 12\n","12.2 7\n","5.8 7\n","7.4 5\n","6.7 8\n","8.6 7\n","11.8 12\n","13.0 4\n","10.8 12\n","10.9 14\n","15.4 21\n","8.0 20\n","13.9 17\n","5.2 3\n","7.6 7\n","8.7 9\n","8.0 23\n","8.1 22\n","9.6 8\n","12.3 13\n","15.1 2\n","13.7 23\n","9.6 3\n","4.3 4\n","12.2 15\n","11.6 6\n","12.8 8\n","11.9 12\n","6.4 11\n","12.0 7\n","8.3 17\n","11.3 4\n","8.6 16\n","4.3 5\n","17.3 20\n","8.3 3\n","11.5 5\n","5.7 17\n","6.5 10\n","7.4 7\n","7.1 20\n","14.3 11\n","10.4 4\n","14.3 22\n","11.5 1\n","12.0 3\n","12.0 6\n","10.6 21\n","9.2 5\n","15.0 18\n","9.6 14\n","7.2 11\n","10.1 5\n","8.7 15\n","17.2 3\n","14.6 15\n","7.2 10\n","10.5 4\n","10.0 11\n","15.2 10\n","8.9 10\n","7.8 5\n","12.5 20\n","3.3 4\n","7.2 11\n","6.1 5\n","7.6 15\n","15.6 23\n","10.8 8\n","14.9 7\n","7.0 11\n","15.2 5\n","10.2 34\n","13.3 11\n","15.2 1\n","8.2 5\n","9.8 18\n","10.9 3\n","13.2 11\n","12.3 7\n","8.2 25\n","11.0 6\n","10.6 0\n","9.4 5\n","19.5 22\n","7.5 1\n","13.7 23\n","10.0 7\n","6.0 2\n","15.7 6\n","14.3 23\n","8.9 0\n","9.7 17\n","16.7 22\n","20.7 23\n","9.9 3\n","13.1 21\n","11.7 23\n","exit at 4 1289\n","8.0 8\n","2.1 0\n","3.6 7\n","2.2 3\n","3.1 1\n","2.4 3\n","3.1 1\n","4.1 0\n","2.1 2\n","1.9 3\n","3.4 2\n","3.5 5\n","5.0 5\n","3.2 6\n","1.8 2\n","6.1 6\n","2.8 1\n","8.9 2\n","3.8 10\n","5.3 3\n","5.1 5\n","10.3 8\n","11.1 4\n","8.8 23\n","9.1 4\n","6.7 4\n","3.9 6\n","6.6 5\n","7.2 4\n","5.9 4\n","9.5 23\n","6.4 7\n","10.7 8\n","9.7 4\n","7.9 3\n","4.9 5\n","10.4 2\n","9.0 15\n","8.4 2\n","5.8 11\n","7.4 3\n","8.8 13\n","7.7 18\n","10.6 23\n","12.8 9\n","9.9 6\n","12.5 23\n","15.9 16\n","7.5 0\n","7.5 11\n","12.4 11\n","9.7 4\n","10.8 0\n","6.8 5\n","9.3 8\n","7.7 19\n","10.0 2\n","7.6 23\n","9.6 7\n","8.6 11\n","9.2 2\n","7.6 41\n","12.0 10\n","17.3 9\n","15.2 26\n","8.0 2\n","8.3 11\n","11.1 12\n","11.9 1\n","8.1 19\n","13.4 3\n","9.4 21\n","13.9 8\n","7.4 23\n","17.4 5\n","9.6 4\n","7.2 12\n","12.4 21\n","12.3 34\n","10.1 8\n","13.8 6\n","11.1 5\n","10.2 8\n","12.1 13\n","13.8 17\n","6.2 15\n","13.7 3\n","14.0 11\n","7.8 4\n","11.0 22\n","11.1 3\n","10.4 11\n","11.7 2\n","14.8 5\n","8.1 7\n","18.0 42\n","17.5 20\n","16.3 6\n","14.8 18\n","13.7 2\n","14.4 17\n","13.6 16\n","11.5 4\n","14.1 23\n","8.8 12\n","12.1 6\n","7.7 27\n","10.4 23\n","17.2 21\n","20.3 2\n","12.1 23\n","18.2 2\n","11.8 11\n","11.2 11\n","14.8 7\n","11.7 12\n","15.8 4\n","13.5 0\n","11.4 17\n","7.8 9\n","15.2 23\n","17.1 6\n","7.0 5\n","5.4 0\n","9.6 3\n","12.7 22\n","10.1 1\n","10.8 13\n","14.5 16\n","13.6 3\n","12.1 26\n","9.5 12\n","19.1 8\n","11.1 6\n","15.8 10\n","16.7 3\n","16.2 6\n","16.0 20\n","13.6 2\n","12.2 6\n","11.3 5\n","12.2 2\n","11.7 28\n","12.0 5\n","13.7 23\n","14.4 5\n","14.4 10\n","16.2 4\n","10.9 1\n","10.2 8\n","16.9 10\n","13.5 13\n","13.4 8\n","22.3 47\n","9.6 14\n","11.8 8\n","9.0 12\n","23.4 23\n","14.1 45\n","15.2 12\n","11.7 0\n","8.7 8\n","12.5 17\n","19.2 22\n","13.7 9\n","8.4 5\n","11.0 9\n","16.3 23\n","14.8 19\n","17.4 6\n","17.6 21\n","15.5 16\n","18.2 22\n","11.9 2\n","18.0 23\n","17.8 17\n","9.8 5\n","8.3 22\n","12.3 11\n","15.5 4\n","8.6 2\n","12.4 6\n","14.9 6\n","16.7 23\n","8.1 22\n","15.4 2\n","19.2 21\n","15.3 20\n","18.7 19\n","12.5 21\n","6.1 5\n","7.6 1\n","14.6 23\n","16.8 13\n","12.5 14\n","16.1 14\n","16.2 11\n","23.3 23\n","19.4 22\n","25.0 45\n","12.7 7\n","14.8 10\n","14.3 6\n","13.3 21\n","exit at 5 2039\n","5.0 5\n","1.6 1\n","2.7 1\n","3.0 4\n","3.1 10\n","1.7 3\n","4.7 6\n","4.1 6\n","3.4 2\n","3.8 4\n","3.5 4\n","3.4 1\n","4.5 4\n","6.0 8\n","3.3 5\n","6.3 4\n","1.0 1\n","6.4 3\n","6.9 9\n","4.7 2\n","4.0 7\n","6.5 3\n","7.4 17\n","4.5 5\n","4.0 5\n","5.7 3\n","10.1 7\n","7.3 1\n","10.6 4\n","6.5 7\n","9.0 7\n","4.4 3\n","8.9 5\n","8.6 6\n","6.9 12\n","8.0 5\n","9.5 3\n","10.2 1\n","9.5 4\n","8.7 12\n","9.4 6\n","7.3 12\n","11.1 10\n","9.9 10\n","11.8 20\n","3.9 12\n","9.8 16\n","6.5 11\n","8.0 10\n","7.5 21\n","14.3 23\n","9.8 13\n","3.6 4\n","8.3 6\n","9.5 10\n","5.8 11\n","8.8 4\n","4.6 4\n","8.7 11\n","8.9 12\n","9.4 10\n","5.3 6\n","13.2 12\n","7.6 13\n","10.3 3\n","9.4 7\n","10.3 11\n","12.1 4\n","12.0 23\n","9.9 21\n","5.9 3\n","7.1 10\n","15.7 13\n","11.3 3\n","17.3 2\n","7.6 3\n","7.0 5\n","10.6 19\n","7.9 7\n","10.4 5\n","10.9 22\n","13.2 21\n","13.8 10\n","13.6 6\n","11.2 16\n","13.9 9\n","12.8 23\n","17.3 7\n","10.7 22\n","7.2 3\n","13.0 7\n","17.0 19\n","4.6 3\n","5.7 3\n","11.9 20\n","14.0 4\n","7.2 1\n","11.3 12\n","20.4 30\n","12.1 11\n","15.5 23\n","12.2 10\n","11.0 23\n","13.7 22\n","8.9 15\n","9.2 12\n","15.7 6\n","10.0 10\n","16.7 23\n","9.7 1\n","14.4 15\n","9.9 6\n","8.4 0\n","11.2 4\n","12.2 20\n","15.4 8\n","7.8 6\n","9.5 10\n","11.9 5\n","9.3 1\n","8.9 2\n","9.5 3\n","14.1 11\n","10.9 13\n","13.4 23\n","11.4 3\n","5.4 9\n","11.8 12\n","12.8 8\n","9.0 27\n","19.9 17\n","11.3 4\n","19.0 17\n","6.6 3\n","22.5 8\n","17.5 23\n","18.3 2\n","14.7 6\n","15.7 39\n","11.9 23\n","12.9 23\n","17.0 10\n","24.9 34\n","5.6 5\n","11.0 5\n","13.9 45\n","12.4 8\n","15.0 25\n","16.9 13\n","15.7 10\n","13.0 23\n","16.0 23\n","15.1 11\n","5.3 5\n","14.7 20\n","14.0 23\n","6.1 4\n","14.5 21\n","17.8 21\n","15.6 8\n","7.4 8\n","13.9 21\n","18.0 18\n","18.8 19\n","9.9 0\n","16.3 4\n","14.1 25\n","6.3 19\n","11.9 6\n","12.5 18\n","8.9 11\n","11.2 13\n","8.8 6\n","18.4 22\n","14.0 3\n","15.0 7\n","12.2 26\n","15.9 22\n","18.4 19\n","17.7 4\n","5.3 4\n","19.1 22\n","14.1 2\n","14.2 22\n","11.7 12\n","13.1 18\n","exit at 6 1854\n","1.0 1\n","4.2 1\n","2.1 4\n","2.6 6\n","3.5 2\n","3.5 3\n","2.8 3\n","2.8 0\n","2.4 6\n","3.2 4\n","3.3 4\n","4.0 7\n","2.7 1\n","2.9 1\n","6.3 0\n","4.5 4\n","3.9 4\n","6.9 14\n","7.5 9\n","3.0 2\n","5.1 4\n","5.1 4\n","4.3 5\n","5.6 7\n","7.5 0\n","5.8 10\n","8.4 7\n","5.7 6\n","5.1 5\n","5.8 1\n","7.4 3\n","4.4 3\n","4.8 5\n","11.2 3\n","9.4 4\n","10.7 4\n","11.6 23\n","10.5 16\n","6.1 2\n","6.4 3\n","8.0 7\n","6.4 5\n","8.0 4\n","11.0 13\n","5.5 4\n","5.1 1\n","6.1 15\n","8.6 9\n","9.9 23\n","11.5 13\n","9.0 8\n","10.2 21\n","10.7 8\n","12.3 15\n","10.6 8\n","11.2 3\n","15.5 22\n","13.3 3\n","12.3 21\n","10.0 6\n","18.0 4\n","7.8 3\n","5.7 10\n","7.7 9\n","7.9 5\n","9.5 1\n","13.4 16\n","8.0 8\n","12.6 9\n","15.9 12\n","11.1 0\n","4.8 0\n","9.5 5\n","9.6 3\n","13.8 23\n","11.2 4\n","13.0 2\n","7.5 6\n","8.2 4\n","13.2 5\n","10.9 17\n","7.9 4\n","11.0 19\n","11.6 15\n","9.6 23\n","5.8 4\n","7.6 3\n","18.6 10\n","9.2 9\n","11.3 21\n","11.2 7\n","11.4 8\n","13.8 17\n","11.2 5\n","4.2 6\n","13.7 8\n","10.9 11\n","17.5 18\n","17.0 19\n","11.2 13\n","13.4 11\n","10.0 11\n","17.2 6\n","9.9 2\n","5.5 7\n","7.1 5\n","15.7 27\n","11.8 5\n","4.8 2\n","19.1 17\n","18.9 7\n","9.5 2\n","15.5 8\n","8.4 13\n","12.4 6\n","10.2 9\n","8.5 12\n","7.3 18\n","6.7 5\n","12.5 11\n","15.1 3\n","7.9 4\n","16.4 5\n","17.2 63\n","11.1 4\n","24.0 23\n","exit at 7 1251\n","6.0 6\n","2.6 0\n","2.7 3\n","5.0 1\n","3.3 5\n","2.6 1\n","2.9 3\n","3.5 1\n","2.8 1\n","4.0 10\n","5.1 0\n","3.6 1\n","4.3 1\n","6.4 3\n","6.0 4\n","3.0 3\n","5.4 3\n","8.4 3\n","4.1 9\n","7.5 7\n","7.6 11\n","4.6 7\n","10.5 15\n","3.9 0\n","4.1 9\n","11.4 7\n","9.5 35\n","11.2 9\n","9.5 2\n","9.6 6\n","10.8 13\n","5.1 13\n","11.4 16\n","10.8 11\n","7.7 6\n","13.1 26\n","4.6 1\n","11.5 19\n","5.2 3\n","4.1 7\n","13.4 2\n","11.9 13\n","7.4 8\n","5.6 7\n","8.6 8\n","6.2 5\n","12.5 16\n","5.9 3\n","11.4 2\n","6.0 0\n","6.5 5\n","8.6 9\n","5.6 8\n","7.3 5\n","10.5 12\n","7.2 2\n","9.3 10\n","7.7 14\n","12.0 7\n","17.4 12\n","8.7 26\n","13.9 18\n","8.8 5\n","13.4 13\n","4.5 6\n","8.3 13\n","10.1 6\n","11.8 20\n","10.2 5\n","6.6 18\n","15.6 3\n","9.7 4\n","9.5 2\n","6.8 14\n","7.3 23\n","15.4 19\n","12.3 3\n","13.6 8\n","7.7 3\n","15.7 20\n","14.8 2\n","3.6 5\n","10.1 11\n","10.4 6\n","12.9 15\n","11.7 11\n","6.0 4\n","9.5 29\n","14.5 43\n","12.1 17\n","7.7 19\n","10.8 1\n","7.5 19\n","11.8 23\n","14.1 6\n","10.2 15\n","8.8 3\n","5.7 9\n","7.8 6\n","13.1 4\n","8.4 4\n","12.7 4\n","8.3 12\n","12.0 12\n","9.5 10\n","18.6 20\n","12.6 3\n","10.0 6\n","14.4 5\n","10.6 3\n","7.2 4\n","18.1 45\n","13.8 13\n","9.1 12\n","13.2 6\n","14.5 16\n","11.7 3\n","12.2 22\n","12.5 1\n","12.7 21\n","14.8 7\n","4.4 8\n","9.5 6\n","12.9 10\n","8.4 11\n","19.0 5\n","9.8 3\n","11.6 7\n","15.0 23\n","9.9 10\n","8.1 3\n","11.3 19\n","12.0 2\n","24.6 3\n","14.1 14\n","exit at 8 1345\n","7.0 7\n","3.4 3\n","2.5 3\n","4.2 3\n","4.8 0\n","2.3 3\n","3.0 1\n","4.6 0\n","4.0 5\n","4.5 0\n","3.7 7\n","5.3 9\n","2.9 1\n","4.5 2\n","4.0 1\n","3.6 1\n","4.4 5\n","3.7 3\n","3.5 3\n","7.2 3\n","7.1 2\n","8.3 15\n","9.9 16\n","7.1 4\n","6.3 2\n","7.4 1\n","6.2 9\n","4.6 4\n","8.7 19\n","7.3 3\n","10.7 9\n","9.3 0\n","11.1 35\n","5.3 5\n","13.3 29\n","11.6 5\n","13.2 10\n","9.0 1\n","8.8 10\n","14.7 29\n","4.8 14\n","8.7 15\n","12.2 23\n","14.4 10\n","12.0 23\n","14.9 29\n","12.0 23\n","8.6 1\n","8.4 9\n","10.5 8\n","12.8 9\n","7.4 5\n","9.4 7\n","14.4 12\n","19.9 21\n","11.5 5\n","12.7 11\n","10.2 15\n","11.5 21\n","14.9 8\n","12.8 10\n","11.4 43\n","11.9 5\n","9.1 3\n","13.3 5\n","6.5 3\n","15.4 10\n","17.0 22\n","5.7 10\n","12.7 12\n","10.1 4\n","7.5 4\n","8.9 1\n","3.0 3\n","9.8 24\n","8.0 2\n","10.2 12\n","8.9 23\n","13.2 21\n","5.2 0\n","12.0 2\n","14.5 1\n","12.2 20\n","13.3 4\n","7.5 23\n","10.6 2\n","16.6 17\n","18.9 14\n","12.2 15\n","12.9 8\n","5.6 3\n","14.3 8\n","13.6 5\n","20.3 22\n","12.4 9\n","9.9 54\n","11.4 5\n","9.6 9\n","18.7 21\n","12.5 7\n","12.4 3\n","15.3 11\n","12.2 18\n","16.7 45\n","9.3 10\n","11.5 14\n","9.4 7\n","12.5 36\n","13.2 5\n","21.3 18\n","13.4 11\n","9.5 23\n","12.4 2\n","19.9 2\n","16.8 22\n","17.1 3\n","20.2 20\n","15.7 12\n","23.7 11\n","exit at 9 1181\n","[1558, 1363, 1158, 1458, 1289, 2039, 1854, 1251, 1345, 1181]\n","1449.6\n"]}],"source":["# import gym\n","import numpy as np\n","# import copy\n","\n","# Hyperparameters\n","alpha = 0.001  # Learning rate, 0.001 for mountaincar\n","gamma = 0.99 # Discount factor\n","  # Epsilon-greedy exploration parameter\n","num_episodes = 10000# Number of episodes\n","# steps_compl = 0\n","# Create the CartPole environment\n","# env = gym.make('CartPole-v1', render_mode = 'none')\n","# env = gym.make('LunarLander-v2', render_mode = 'none')\n","# Initialize the weights for the linear function approximation\n","\n","# weights = np.random.rand(num_features, num_actions)\n","# weights = copy.deepcopy(curr_nn_weights)\n","\n","# print(\"hskgd\")\n","\n","\n","# Linear function approximation\n","def approximate_q(state, weights):\n","    return np.dot(phi_wrapper(state), weights).reshape(-1,1)\n","\n","# curr_test_state = env.observation_space.sample()\n","# print(\"hello\", (approximate_q(curr_test_state), curr_policy_net(torch.tensor(curr_test_state)).detach().numpy()))\n","\n","# Epsilon-greedy policy\n","def epsilon_greedy_policy(state,tot_steps,weights):\n","    epsilon = 0.1 + math.exp(-1. * tot_steps / 5000)\n","    if np.random.rand() < epsilon:\n","        return random.randrange(env.num_actions())  # Random action\n","    else:\n","        q_values = approximate_q(state,weights)\n","        return np.argmax(q_values)  # Greedy action\n","\n","# Q-learning algorithm with linear function approximation\n","# env = gym.make(\n","#     \"LunarLander-v2\",\n","#     continuous = False,\n","#     gravity = -10.0,\n","#     enable_wind = False,\n","#     wind_power = 15.0,\n","#     turbulence_power = 1.5,\n","#     render_mode = 'human'\n","# )\n","res = []\n","for i in range(10):\n","    weights = np.zeros((num_features, num_actions))\n","    duration_list = []\n","    tot_steps = 0 \n","    for episode in range(num_episodes):\n","\n","        env.reset()\n","        \n","        state = env.state()\n","#         state = state[0]\n","#         state_length = state.size\n","        # print(len(state))\n","        done = False\n","        steps = 0\n","        # episode_duration  = 0\n","        tot_rew = 0\n","        while not done:\n","    #         env.render()\n","            steps +=1\n","            tot_steps +=1\n","            # episode_duration += 1\n","    #         state += np.random.normal(0,0.1,state_length)\n","            action = epsilon_greedy_policy(state,tot_steps,weights)\n","            # print(action)\n","            # print(action)\n","            # print((env.step(action)))\n","            # env.close_display()\n","            reward, done = env.act(action)\n","            next_state = (env.state())\n","            # env.display_state(500)\n","            # env.close_display()  \n","#             next_state, reward, done, _, _ = env.step(action)\n","    #         if done == False:\n","    #             reward += 1 \n","            tot_rew += reward\n","\n","            # print(state)\n","            # Update Q-value using the Q-learning update rule\n","            # print((next_state).shape)\n","            # print(np.max(approximate_q((next_state))).shape)\n","            # print(next_state)\n","            if done:\n","                td_target = reward\n","            else:\n","                td_target = reward + gamma * np.max(approximate_q(next_state,weights))\n","            td_error = td_target - approximate_q(state,weights)[action]\n","#             print(td_error)\n","    #         print(td_target, td_error)\n","            weights[:, action] += alpha * td_error * phi_wrapper(state).reshape(num_features,)\n","            # print(nn_weights)\n","            # print(alpha * td_error * phi_wrapper(state))\n","\n","            state = next_state\n","\n","            if steps >= 1000:\n","                break\n","        duration_list.append(tot_rew)\n","    #     plt.plot(duration_list)\n","    #     plt.pause(0.001)  # pause a bit so that plots are updated\n","    #     display.display(plt.gcf())\n","    #     display.clear_output(wait=True)\n","#         print(tot_rew)\n","        if(episode % 10 == 0):\n","            print(np.mean(duration_list[-10:]), tot_rew)\n","        if np.mean(duration_list[-10:]) > 25:\n","            print(\"exit at\", i, episode)\n","            res.append(episode)\n","            break\n","    \n","    else:\n","        res.append(num_episodes)\n","  \n","        \n","        \n","print(res)\n","print(sum(res)/len(res))\n","    # if (episode + 1) % 100 == 0:\n","#     print(f\"Episode {episode + 1}/{num_episodes}\")\n","\n","# plt.pause(0.001)  # pause a bit so that plots are updated\n","# display.display(plt.gcf())\n","\n","# plt.show()\n","\n","# Close the environment\n","# env.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# # import gym\n","# import numpy as np\n","# import copy\n","\n","# # Hyperparameters\n","# alpha = 0.00001  # Learning rate, 0.001 for mountaincar\n","# gamma = 0.99  # Discount factor\n","#   # Epsilon-greedy exploration parameter\n","# num_episodes = 10000# Number of episodes\n","# steps_compl = 0\n","# # Create the CartPole environment\n","# # env = gym.make('CartPole-v1', render_mode = 'none')\n","# # env = gym.make('LunarLander-v2', render_mode = 'none')\n","# # Initialize the weights for the linear function approximation\n","\n","# # weights = np.random.rand(num_features, num_actions)\n","# # weights = copy.deepcopy(curr_nn_weights)\n","\n","# # print(\"hskgd\")\n","\n","\n","# # Linear function approximation\n","# def approximate_q(state, weights = weights):\n","#     # state = state[0]\n","#     # print(np.array(state).shape)\n","#     # print(phi_wrapper(state).shape)\n","#     # print(phi_wrapper(state).shape)\n","#     # print(weights.shape)\n","#     return np.dot(phi_wrapper(state), weights)\n","\n","# curr_test_state = env.observation_space.sample()\n","# # print(\"hello\", (approximate_q(curr_test_state), curr_policy_net(torch.tensor(curr_test_state)).detach().numpy()))\n","\n","# # Epsilon-greedy policy\n","# def epsilon_greedy_policy(state):\n","#     global steps_compl\n","#     epsilon = 0.1 + math.exp(-1. * steps_compl / 5000)\n","#     # print(epsilon)\n","# #     epsilon = 0.3\n","# #     epsilon = 0.3\n","#     steps_compl += 1\n","#     if np.random.rand() < epsilon:\n","#         return env.action_space.sample()  # Random action\n","#     else:\n","#         q_values = approximate_q(state)\n","#         # print(q_values.shape)\n","#         return np.argmax(q_values)  # Greedy action\n","\n","# # Q-learning algorithm with linear function approximation\n","# # env = gym.make(\n","# #     \"LunarLander-v2\",\n","# #     continuous = False,\n","# #     gravity = -10.0,\n","# #     enable_wind = False,\n","# #     wind_power = 15.0,\n","# #     turbulence_power = 1.5,\n","# #     render_mode = 'human'\n","# # )\n","# # for i in range(2):\n","# duration_list = []\n","# #     weights = np.zeros((num_features, num_actions))\n","# #     steps_compl = 0\n","# for episode in range(num_episodes):\n","\n","#     state = env.reset()\n","#     state = state[0]\n","#     state_length = state.size\n","#     # print(len(state))\n","#     done = False\n","#     steps = 0\n","#     # episode_duration  = 0\n","#     tot_rew = 0\n","#     while not done:\n","# #         env.render()\n","#         steps +=1\n","#         # episode_duration += 1\n","# #         state += np.random.normal(0,0.1,state_length)\n","#         action = epsilon_greedy_policy(state)\n","#         # print(action)\n","#         # print(action)\n","#         # print((env.step(action)))\n","#         next_state, reward, done, _, _ = env.step(action)\n","# #         if done == False:\n","# #             reward = 0\n","#         tot_rew += reward\n","\n","#     # print(state)\n","#     # Update Q-value using the Q-learning update rule\n","#     # print((next_state).shape)\n","#     # print(np.max(approximate_q((next_state))).shape)\n","#     # print(next_state)\n","#         if done:\n","#             td_target = reward\n","#         else:\n","#             td_target = reward + gamma * np.max(approximate_q((next_state)))\n","#         td_error = td_target - approximate_q((state))[action]\n","# #         print(td_target, td_error)\n","#         weights[:, action] += alpha * td_error * phi_wrapper(state)\n","#         # print(nn_weights)\n","#         # print(alpha * td_error * phi_wrapper(state))\n","\n","#         state = next_state\n","#         if steps >= 1000:\n","#             break\n","#     duration_list.append(tot_rew)\n","# #     plt.plot(duration_list)\n","# #     plt.pause(0.001)  # pause a bit so that plots are updated\n","# #     display.display(plt.gcf())\n","# #     display.clear_output(wait=True)\n","#     if episode%100==0: print(tot_rew)\n","#     if np.mean(duration_list[-10:]) > 200:\n","#         print(\"exit at\", episode)\n","#         break\n","#     # if (episode + 1) % 100 == 0:\n","# #     print(f\"Episode {episode + 1}/{num_episodes}\")\n","\n","# # plt.pause(0.001)  # pause a bit so that plots are updated\n","# # display.display(plt.gcf())\n","\n","# # plt.show()\n","\n","# # Close the environment\n","# # env.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# # import gym\n","# import numpy as np\n","# import copy\n","\n","# # Hyperparameters\n","# alpha = 0.00001  # Learning rate, 0.001 for mountaincar\n","# gamma = 0.99  # Discount factor\n","#   # Epsilon-greedy exploration parameter\n","# num_episodes = 10000# Number of episodes\n","# steps_compl = 0\n","# # Create the CartPole environment\n","# # env = gym.make('CartPole-v1', render_mode = 'none')\n","\n","# # Initialize the weights for the linear function approximation\n","# num_features = 32  # Number of features (state dimensions)\n","# num_actions = env.action_space.n  # Number of actions\n","# # weights = np.random.rand(num_features, num_actions)\n","# # weights = copy.deepcopy(curr_nn_weights)\n","# # weights = np.zeros((num_features, num_actions))\n","\n","# # print(\"hskgd\")\n","\n","\n","# # Linear function approximation\n","# def approximate_q(state, weights = weights):\n","#     # state = state[0]\n","#     # print(np.array(state).shape)\n","#     # print(phi_wrapper(state).shape)\n","#     # print(phi_wrapper(state).shape)\n","#     # print(weights.shape)\n","#     return np.dot(phi_wrapper(state), weights)\n","\n","# curr_test_state = env.observation_space.sample()\n","# # print(\"hello\", (approximate_q(curr_test_state), curr_policy_net(torch.tensor(curr_test_state)).detach().numpy()))\n","\n","# # Epsilon-greedy policy\n","# def epsilon_greedy_policy(state):\n","#     global steps_compl\n","#     epsilon = 0.1 + math.exp(-1. * steps_compl / 5000)\n","# #     print(epsilon)\n","# #     epsilon = 0.3\n","#     epsilon = 0\n","#     steps_compl += 1\n","#     if np.random.rand() < epsilon:\n","#         return env.action_space.sample()  # Random action\n","#     else:\n","#         q_values = approximate_q(state)\n","#         # print(q_values.shape)\n","#         return np.argmax(q_values)  # Greedy action\n","\n","# # Q-learning algorithm with linear function approximation\n","# # env = gym.make(\n","# #     \"LunarLander-v2\",\n","# #     continuous = False,\n","# #     gravity = -10.0,\n","# #     enable_wind = False,\n","# #     wind_power = 15.0,\n","# #     turbulence_power = 1.5,\n","# #     render_mode = 'human'\n","# # )\n","# duration_list = []\n","# for episode in range(num_episodes):\n","    \n","#     state = env.reset()\n","#     state = state[0]\n","#     state_length = state.size\n","#     # print(len(state))\n","#     done = False\n","#     steps = 0\n","#     # episode_duration  = 0\n","#     tot_rew = 0\n","#     while not done:\n","# #         env.render()\n","#         steps +=1\n","#         # episode_duration += 1\n","# #         state += np.random.normal(0,0.1,state_length)\n","#         action = epsilon_greedy_policy(state)\n","#         # print(action)\n","#         # print(action)\n","#         # print((env.step(action)))\n","#         next_state, reward, done, _, _ = env.step(action)\n","#         tot_rew += reward\n","\n","#         # print(state)\n","#         # Update Q-value using the Q-learning update rule\n","#         # print((next_state).shape)\n","#         # print(np.max(approximate_q((next_state))).shape)\n","#         # print(next_state)\n","#         if done:\n","#             td_target = reward\n","#         else:\n","#             td_target = reward + gamma * np.max(approximate_q((next_state)))\n","#         td_error = td_target - approximate_q((state))[action]\n","# #         print(td_target, td_error)\n","#         weights[:, action] += alpha * td_error * phi_wrapper(state)\n","#         # print(nn_weights)\n","#         # print(alpha * td_error * phi_wrapper(state))\n","        \n","#         state = next_state\n","#         if steps >= 1000:\n","#             break\n","#     duration_list.append(tot_rew)\n","# #     plt.plot(duration_list)\n","# #     plt.pause(0.001)  # pause a bit so that plots are updated\n","# #     display.display(plt.gcf())\n","# #     display.clear_output(wait=True)\n","#     print(tot_rew)\n","#     # if (episode + 1) % 100 == 0:\n","# #     print(f\"Episode {episode + 1}/{num_episodes}\")\n","\n","# # plt.pause(0.001)  # pause a bit so that plots are updated\n","# # display.display(plt.gcf())\n","\n","# # plt.show()\n","# print(\"The mean is\", np.mean(duration_list),np.std(duration_list))\n","# # Close the environment\n","# # env.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["curr_test_state"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["weights"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["phi_wrapper(state)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["env = gym.make('LunarLander-v2')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5650541,"sourceId":9326810,"sourceType":"datasetVersion"}],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":4}
