{"cells":[{"cell_type":"markdown","metadata":{"id":"nm2uk2yDFugI"},"source":["\\\n","# Reinforcement Learning (DQN) Tutorial\n","**Author**: [Adam Paszke](https://github.com/apaszke)\n","            [Mark Towers](https://github.com/pseudo-rnd-thoughts)\n","\n","\n","This tutorial shows how to use PyTorch to train a Deep Q Learning (DQN) agent\n","on the CartPole-v1 task from [Gymnasium](https://gymnasium.farama.org)_.\n","\n","**Task**\n","\n","The agent has to decide between two actions - moving the cart left or\n","right - so that the pole attached to it stays upright. You can find more\n","information about the environment and other more challenging environments at\n","[Gymnasium's website](https://gymnasium.farama.org/environments/classic_control/cart_pole/)_.\n","\n",".. figure:: /_static/img/cartpole.gif\n","   :alt: CartPole\n","\n","   CartPole\n","\n","As the agent observes the current state of the environment and chooses\n","an action, the environment *transitions* to a new state, and also\n","returns a reward that indicates the consequences of the action. In this\n","task, rewards are +1 for every incremental timestep and the environment\n","terminates if the pole falls over too far or the cart moves more than 2.4\n","units away from center. This means better performing scenarios will run\n","for longer duration, accumulating larger return.\n","\n","The CartPole task is designed so that the inputs to the agent are 4 real\n","values representing the environment state (position, velocity, etc.).\n","We take these 4 inputs without any scaling and pass them through a\n","small fully-connected network with 2 outputs, one for each action.\n","The network is trained to predict the expected value for each action,\n","given the input state. The action with the highest expected value is\n","then chosen.\n","\n","\n","**Packages**\n","\n","\n","First, let's import needed packages. Firstly, we need\n","[gymnasium](https://gymnasium.farama.org/)_ for the environment,\n","installed by using `pip`. This is a fork of the original OpenAI\n","Gym project and maintained by the same team since Gym v0.19.\n","If you are running this in Google Colab, run:\n"]},{"cell_type":"markdown","metadata":{"id":"hCNb6nixFugK"},"source":["We'll also use the following from PyTorch:\n","\n","-  neural networks (``torch.nn``)\n","-  optimization (``torch.optim``)\n","-  automatic differentiation (``torch.autograd``)\n"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T09:38:12.806805Z","iopub.status.busy":"2024-09-06T09:38:12.805761Z","iopub.status.idle":"2024-09-06T09:38:30.599226Z","shell.execute_reply":"2024-09-06T09:38:30.597072Z","shell.execute_reply.started":"2024-09-06T09:38:12.806752Z"},"trusted":true},"outputs":[],"source":["# %matplotlib inline\n","# %matplotlib qt\n","# # !pip install swig\n","# !pip install minatar==1.0.13\n","# # !pip install gymnasium\n","# # !pip install \"gymnasium[all]\"\n","# # "]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T09:38:30.608228Z","iopub.status.busy":"2024-09-06T09:38:30.607570Z","iopub.status.idle":"2024-09-06T09:38:37.865809Z","shell.execute_reply":"2024-09-06T09:38:37.864425Z","shell.execute_reply.started":"2024-09-06T09:38:30.608180Z"},"id":"Vs-RXSibFugK","trusted":true},"outputs":[],"source":["from minatar import Environment\n","# import gymnasium as gym\n","import math\n","import random\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from collections import namedtuple, deque\n","from itertools import count\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as f\n","\n","# SEED = 42\n","\n","# # # Set random seed for NumPy\n","# np.random.seed(SEED)\n","\n","# # # Set random seed for Python's built-in random module\n","# random.seed(SEED)\n","\n","\n","# torch.manual_seed(SEED)\n","# if torch.cuda.is_available():\n","#     torch.cuda.manual_seed(SEED)\n","#     torch.cuda.manual_seed_all(SEED)\n","#     torch.backends.cudnn.deterministic = True\n","# #     # torch.backends.cudnn.benchmark = False\n","\n","\n","\n","# env = gym.make(\n","#     \"LunarLander-v2\",\n","#     continuous = False,\n","#     gravity = -10.0,\n","#     enable_wind = False,\n","#     wind_power = 15.0,\n","#     turbulence_power = 1.5,\n","# )\n","\n","# env.seed(SEED)\n","\n","# env = gym.make('LunarLander-v2')\n","env = Environment('asterix')\n","\n","# env = gym.make('CartPole-v1')\n","# env = gym.make('MountainCar-v0', max_episode_steps=1000)\n","# env = gym.make('MountainCar-v0', max_episode_steps=500)\n","# env = gym.make(\"Acrobot-v1\")\n","\n","# env = gym.make(\"BipedalWalker-v3\")\n","# env.action_space.seed(SEED)\n","# set up matplotlib\n","is_ipython = 'inline' in matplotlib.get_backend()\n","if is_ipython:\n","    from IPython import display\n","\n","plt.ion()\n","\n","# if GPU is to be used\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"WSzvivYYFugK"},"source":["## Replay Memory\n","\n","We'll be using experience replay memory for training our DQN. It stores\n","the transitions that the agent observes, allowing us to reuse this data\n","later. By sampling from it randomly, the transitions that build up a\n","batch are decorrelated. It has been shown that this greatly stabilizes\n","and improves the DQN training procedure.\n","\n","For this, we're going to need two classes:\n","\n","-  ``Transition`` - a named tuple representing a single transition in\n","   our environment. It essentially maps (state, action) pairs\n","   to their (next_state, reward) result, with the state being the\n","   screen difference image as described later on.\n","-  ``ReplayMemory`` - a cyclic buffer of bounded size that holds the\n","   transitions observed recently. It also implements a ``.sample()``\n","   method for selecting a random batch of transitions for training.\n","\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T09:38:37.868151Z","iopub.status.busy":"2024-09-06T09:38:37.867512Z","iopub.status.idle":"2024-09-06T09:38:37.878804Z","shell.execute_reply":"2024-09-06T09:38:37.877395Z","shell.execute_reply.started":"2024-09-06T09:38:37.868115Z"},"id":"WFlJl7ZAFugK","trusted":true},"outputs":[],"source":["Transition = namedtuple('Transition',\n","                        ('state', 'action', 'next_state', 'reward'))\n","\n","\n","class ReplayMemory(object):\n","\n","    def __init__(self, capacity):\n","        self.memory = deque([], maxlen=capacity)\n","\n","    def push(self, *args):\n","        \"\"\"Save a transition\"\"\"\n","        self.memory.append(Transition(*args))\n","\n","    def sample(self, batch_size):\n","        return random.sample(self.memory, batch_size)\n","\n","    def __len__(self):\n","        return len(self.memory)"]},{"cell_type":"markdown","metadata":{"id":"jHxgRpvRFugK"},"source":["Now, let's define our model. But first, let's quickly recap what a DQN is.\n","\n","## DQN algorithm\n","\n","Our environment is deterministic, so all equations presented here are\n","also formulated deterministically for the sake of simplicity. In the\n","reinforcement learning literature, they would also contain expectations\n","over stochastic transitions in the environment.\n","\n","Our aim will be to train a policy that tries to maximize the discounted,\n","cumulative reward\n","$R_{t_0} = \\sum_{t=t_0}^{\\infty} \\gamma^{t - t_0} r_t$, where\n","$R_{t_0}$ is also known as the *return*. The discount,\n","$\\gamma$, should be a constant between $0$ and $1$\n","that ensures the sum converges. A lower $\\gamma$ makes\n","rewards from the uncertain far future less important for our agent\n","than the ones in the near future that it can be fairly confident\n","about. It also encourages agents to collect reward closer in time\n","than equivalent rewards that are temporally far away in the future.\n","\n","The main idea behind Q-learning is that if we had a function\n","$Q^*: State \\times Action \\rightarrow \\mathbb{R}$, that could tell\n","us what our return would be, if we were to take an action in a given\n","state, then we could easily construct a policy that maximizes our\n","rewards:\n","\n","\\begin{align}\\pi^*(s) = \\arg\\!\\max_a \\ Q^*(s, a)\\end{align}\n","\n","However, we don't know everything about the world, so we don't have\n","access to $Q^*$. But, since neural networks are universal function\n","approximators, we can simply create one and train it to resemble\n","$Q^*$.\n","\n","For our training update rule, we'll use a fact that every $Q$\n","function for some policy obeys the Bellman equation:\n","\n","\\begin{align}Q^{\\pi}(s, a) = r + \\gamma Q^{\\pi}(s', \\pi(s'))\\end{align}\n","\n","The difference between the two sides of the equality is known as the\n","temporal difference error, $\\delta$:\n","\n","\\begin{align}\\delta = Q(s, a) - (r + \\gamma \\max_a' Q(s', a))\\end{align}\n","\n","To minimize this error, we will use the [Huber\n","loss](https://en.wikipedia.org/wiki/Huber_loss)_. The Huber loss acts\n","like the mean squared error when the error is small, but like the mean\n","absolute error when the error is large - this makes it more robust to\n","outliers when the estimates of $Q$ are very noisy. We calculate\n","this over a batch of transitions, $B$, sampled from the replay\n","memory:\n","\n","\\begin{align}\\mathcal{L} = \\frac{1}{|B|}\\sum_{(s, a, s', r) \\ \\in \\ B} \\mathcal{L}(\\delta)\\end{align}\n","\n","\\begin{align}\\text{where} \\quad \\mathcal{L}(\\delta) = \\begin{cases}\n","     \\frac{1}{2}{\\delta^2}  & \\text{for } |\\delta| \\le 1, \\\\\n","     |\\delta| - \\frac{1}{2} & \\text{otherwise.}\n","   \\end{cases}\\end{align}\n","\n","### Q-network\n","\n","Our model will be a feed forward  neural network that takes in the\n","difference between the current and previous screen patches. It has two\n","outputs, representing $Q(s, \\mathrm{left})$ and\n","$Q(s, \\mathrm{right})$ (where $s$ is the input to the\n","network). In effect, the network is trying to predict the *expected return* of\n","taking each action given the current input.\n","\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T09:38:37.883784Z","iopub.status.busy":"2024-09-06T09:38:37.882450Z","iopub.status.idle":"2024-09-06T09:38:37.901650Z","shell.execute_reply":"2024-09-06T09:38:37.900225Z","shell.execute_reply.started":"2024-09-06T09:38:37.883726Z"},"id":"umFHM0K0FugK","trusted":true},"outputs":[],"source":["class DQN(nn.Module):\n","\n","    def __init__(self, in_channels, n_actions):\n","        super(DQN, self).__init__()\n","        # One hidden 2D convolution layer:\n","        #   in_channels: variable\n","        #   out_channels: 16\n","        #   kernel_size: 3 of a 3x3 filter matrix\n","        #   stride: 1\n","        self.conv = nn.Conv2d(in_channels, 16, kernel_size=3, stride=1)\n","        # Final fully connected hidden layer:\n","        #   the number of linear unit depends on the output of the conv\n","        #   the output consist 128 rectified units\n","        def size_linear_unit(size, kernel_size=3, stride=1):\n","            return (size - (kernel_size - 1) - 1) // stride + 1\n","        num_linear_units = size_linear_unit(10) * size_linear_unit(10) * 16\n","        self.fc_hidden = nn.Linear(in_features=num_linear_units, out_features=128)\n","        \n","        self.output = nn.Linear(in_features=128, out_features=n_actions)\n","        \n","#         self.layer1 = nn.Linear(n_observations, 128)\n","#         self.layer2 = nn.Linear(128,128)\n","# #         self.layer3 = nn.Linear(128,128)\n","#         # self.layer4 = nn.Linear(128,128)\n","#         self.layer4 = nn.Linear(128, n_actions)\n","        \n","        \n","\n","    # As per implementation instructions according to pytorch, the forward function should be overwritten by all\n","    # subclasses\n","    def forward(self, x):\n","        # Rectified output from the first conv layer\n","        x = f.relu(self.conv(x))\n","\n","        # Rectified output from the final hidden layer\n","        x = f.relu(self.fc_hidden(x.view(x.size(0), -1)))\n","\n","        # Returns the output from the fully-connected linear layer\n","        return self.output(x)\n","\n","\n","    # Called with either one element to determine next action, or a batch\n","    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n","#     def forward(self, x):\n","#         x = F.relu(self.layer1(x))\n","#         x = F.relu(self.layer2(x))\n","# #         x = F.relu(self.layer3(x))\n","#         # x = F.relu(self.layer4(x))\n","#         return self.layer4(x)\n","\n","#     def forward_correlation(self, x):\n","#         x = F.relu(self.layer1(x))\n","# #         x = F.relu(self.layer2(x))\n","# #         x = F.relu(self.layer3(x))\n","#         # x = F.relu(self.layer4(x))\n","#         return F.relu(self.layer2(x))\n","\n","    def forward_correlation(self, x):\n","     # Rectified output from the first conv layer\n","        x = f.relu(self.conv(x))\n","\n","        # Rectified output from the final hidden layer\n","        return f.relu(self.fc_hidden(x.view(x.size(0), -1)))"]},{"cell_type":"markdown","metadata":{"id":"Geq4Fg3jFugK"},"source":["## Training\n","\n","### Hyperparameters and utilities\n","This cell instantiates our model and its optimizer, and defines some\n","utilities:\n","\n","-  ``select_action`` - will select an action accordingly to an epsilon\n","   greedy policy. Simply put, we'll sometimes use our model for choosing\n","   the action, and sometimes we'll just sample one uniformly. The\n","   probability of choosing a random action will start at ``EPS_START``\n","   and will decay exponentially towards ``EPS_END``. ``EPS_DECAY``\n","   controls the rate of the decay.\n","-  ``plot_durations`` - a helper for plotting the duration of episodes,\n","   along with an average over the last 100 episodes (the measure used in\n","   the official evaluations). The plot will be underneath the cell\n","   containing the main training loop, and will update after every\n","   episode.\n","\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T15:46:14.556932Z","iopub.status.busy":"2024-09-06T15:46:14.556247Z","iopub.status.idle":"2024-09-06T15:46:14.910189Z","shell.execute_reply":"2024-09-06T15:46:14.908619Z","shell.execute_reply.started":"2024-09-06T15:46:14.556884Z"},"id":"TPPr8pR6FugL","trusted":true},"outputs":[],"source":["# BATCH_SIZE is the number of transitions sampled from the replay buffer\n","# GAMMA is the discount factor as mentioned in the previous section\n","# EPS_START is the starting value of epsilon\n","# EPS_END is the final value of epsilon\n","# EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n","# TAU is the update rate of the target network\n","# LR is the learning rate of the ``AdamW`` optimizer\n","BATCH_SIZE = 64\n","GAMMA = 0.99\n","EPS_START = 0.9\n","EPS_END = 0.05\n","EPS_DECAY = 1000\n","TAU = 0.005\n","LR = 1e-4\n","\n","# Get number of actions from gym action space\n","n_actions = env.num_actions()\n","in_channels = env.state_shape()[2]\n","\n","# Get the number of state observations\n","# state, info = env.reset()\n","\n","policy_net = DQN(in_channels, n_actions).to(device)\n","target_net = DQN(in_channels, n_actions).to(device)\n","target_net.load_state_dict(policy_net.state_dict())\n","\n","# optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n","optimizer = optim.Adam(policy_net.parameters(), lr = LR)\n","# faster_lr = 1e-3\n","# slower_lr = 1e-3\n","\n","###  CHANGE THISSSSSS\n","# slower_lr = 1e-3\n","\n","# # Create separate parameter groups for layers 1-3 and layer 4\n","# slower_params = list(map(id, policy_net.layer1.parameters() + policy_net.layer2.parameters() + policy_net.layer3.parameters()))\n","# faster_params = list(map(id, policy_net.layer4.parameters()))\n","\n","# # Create an optimizer with different learning rates for each parameter group\n","# optimizer = optim.AdamW(\n","#     [\n","#         {\"params\": [p for p in policy_net.parameters() if id(p) in faster_params], \"lr\": faster_lr},\n","#         {\"params\": [p for p in policy_net.parameters() if id(p) in slower_params], \"lr\": slower_lr},\n","#     ]\n","# )\n","\n","# params = [\n","#     {'params': policy_net.layer1.parameters(), 'lr':slower_lr },\n","#     {'params': policy_net.layer2.parameters(), 'lr': slower_lr},\n","# #     {'params': policy_net.layer3.parameters(), 'lr': slower_lr},  # Last two layers\n","#     {'params': policy_net.layer4.parameters(), 'lr': faster_lr},  # Last two layers\n","# ]\n","\n","# Define your optimizer with different learning rates for each parameter group\n","# optimizer = optim.Adam(params)\n","\n","\n","\n","memory = ReplayMemory(50000)\n","\n","\n","steps_done = 0\n","\n","\n","def select_action(state):\n","    global steps_done\n","    sample = random.random()\n","    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n","        math.exp(-1. * steps_done / EPS_DECAY)\n","    steps_done += 1\n","    if sample > eps_threshold:\n","        with torch.no_grad():\n","            # t.max(1) will return the largest column value of each row.\n","            # second column on max result is index of where max element was\n","            # found, so we pick action with the larger expected reward.\n","            return policy_net(state).max(1).indices.view(1, 1)\n","    else:\n","        return torch.tensor([[random.randrange(n_actions)]], device=device)\n","\n","\n","episode_durations = []\n","\n","\n","def plot_durations(show_result=False):\n","    plt.figure(1)\n","    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n","    if show_result:\n","        plt.title('Result')\n","    else:\n","        plt.clf()\n","        plt.title('Training...')\n","    plt.xlabel('Episode')\n","    plt.ylabel('Duration')\n","    plt.plot(durations_t.numpy())\n","    # Take 100 episode averages and plot them too\n","    if len(durations_t) >= 100:\n","        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n","        means = torch.cat((torch.zeros(99), means))\n","        plt.plot(means.numpy())\n","\n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","    if is_ipython:\n","        if not show_result:\n","            display.display(plt.gcf())\n","            display.clear_output(wait=True)\n","        else:\n","            display.display(plt.gcf())"]},{"cell_type":"markdown","metadata":{"id":"9A1xqvpZFugL"},"source":["### Training loop\n","\n","Finally, the code for training our model.\n","\n","Here, you can find an ``optimize_model`` function that performs a\n","single step of the optimization. It first samples a batch, concatenates\n","all the tensors into a single one, computes $Q(s_t, a_t)$ and\n","$V(s_{t+1}) = \\max_a Q(s_{t+1}, a)$, and combines them into our\n","loss. By definition we set $V(s) = 0$ if $s$ is a terminal\n","state. We also use a target network to compute $V(s_{t+1})$ for\n","added stability. The target network is updated at every step with a\n","[soft update](https://arxiv.org/pdf/1509.02971.pdf)_ controlled by\n","the hyperparameter ``TAU``, which was previously defined.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Y8VdiiKxigRg"},"source":["K means and then sampling from those clusters\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T09:38:39.679693Z","iopub.status.busy":"2024-09-06T09:38:39.679075Z","iopub.status.idle":"2024-09-06T09:38:39.686371Z","shell.execute_reply":"2024-09-06T09:38:39.684679Z","shell.execute_reply.started":"2024-09-06T09:38:39.679658Z"},"trusted":true},"outputs":[],"source":["def get_state(s):\n","    return (torch.tensor(s, device=device).permute(2, 0, 1)).unsqueeze(0).float()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-09-06T15:46:19.306936Z","iopub.status.busy":"2024-09-06T15:46:19.306430Z","iopub.status.idle":"2024-09-06T15:46:21.034370Z","shell.execute_reply":"2024-09-06T15:46:21.032557Z","shell.execute_reply.started":"2024-09-06T15:46:19.306894Z"},"id":"6mu4iEHyife-","outputId":"5336272e-5ae5-44e5-9e78-dfadd329795f","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/scl/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n"]}],"source":["\n","from sklearn.cluster import KMeans\n","\n","# Create your Gym environment\n","# env = gym.make('YourEnvNameHere')\n","\n","# Define the number of clusters (bins)\n","k = 25\n","# k=10\n","# k=50\n","\n","# Initialize an empty list to store the clustered states\n","clustered_states = []\n","\n","# Reset the environment to get the initial state\n","state = env.reset()\n","\n","# Initialize an empty list to store all states\n","all_states = []\n","\n","# Collect a bunch of states from the environment\n","for _ in range(2000):  # You can adjust the number of samples as needed\n","    action = random.randrange(env.num_actions())\n","    # print(env.step(action))\n","    _, done = env.act(action)\n","    state = env.state().reshape(-1,)\n","    all_states.append(state)\n","    if done:\n","        state = env.reset()\n","\n","# Convert the list of states into a numpy array\n","all_states = np.array(all_states)\n","\n","# Perform K-means clustering\n","kmeans = KMeans(n_clusters=k, random_state=0).fit(all_states)\n","# Get the indices of states belonging to each cluster\n","cluster_indices = [np.where(kmeans.labels_ == i)[0] for i in range(k)]\n","\n","# Sample a random state from each cluster\n","# print(cluster_indices)\n","# Print the sampled states from each cluster\n","# for i, sampled_state in enumerate(clustered_states):\n","#     print(f\"Sampled state from cluster {i+1}: {sampled_state}\")\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T09:38:47.114543Z","iopub.status.busy":"2024-09-06T09:38:47.114018Z","iopub.status.idle":"2024-09-06T09:38:47.125520Z","shell.execute_reply":"2024-09-06T09:38:47.124225Z","shell.execute_reply.started":"2024-09-06T09:38:47.114507Z"},"id":"P02goxQG8Xew","trusted":true},"outputs":[],"source":["import math\n","def call_correlation_coeff_kmeans():\n","\n","    state_vector = []\n","    for indices in cluster_indices:\n","    # Randomly select an index from the cluster\n","      sampled_index = np.random.choice(indices)\n","      # Get the corresponding state\n","      sampled_state = get_state(all_states[sampled_index].reshape(env.state().shape))\n","      # Add the sampled state to the list\n","      state_vector.append(policy_net.forward_correlation(sampled_state))\n","      # state_vector.append(sampled_state)\n","\n","    stacked_tensor = torch.stack(state_vector)\n","    reshaped_tensor = stacked_tensor.reshape(len(state_vector), -1)\n","    correlation_matrix = torch.corrcoef(reshaped_tensor)\n","#     print(correlation_matrix)\n","    correlation_values = torch.masked_select(correlation_matrix, torch.triu(torch.ones_like(correlation_matrix), diagonal=1).bool())\n","    # print(state_vector)\n","    # Average correlation across all pairs of tensor vectors\n","    average_correlation = correlation_values.mean()\n","    if math.isnan(average_correlation): \n","#         print(\"nan-correlation\")\n","        return 0\n","    return average_correlation"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-09-06T15:46:23.682716Z","iopub.status.busy":"2024-09-06T15:46:23.682181Z","iopub.status.idle":"2024-09-06T15:46:23.708371Z","shell.execute_reply":"2024-09-06T15:46:23.706812Z","shell.execute_reply.started":"2024-09-06T15:46:23.682665Z"},"id":"AivVdWiHWMlT","outputId":"2e1b9978-e145-4463-e01d-c80a2282a32c","trusted":true},"outputs":[{"data":{"text/plain":["tensor(0.6249, device='cuda:0', grad_fn=<MeanBackward0>)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["call_correlation_coeff_kmeans()"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T14:19:05.001327Z","iopub.status.busy":"2024-09-06T14:19:05.000557Z","iopub.status.idle":"2024-09-06T14:19:05.021084Z","shell.execute_reply":"2024-09-06T14:19:05.018981Z","shell.execute_reply.started":"2024-09-06T14:19:05.001283Z"},"id":"OTqRsgdgFugL","trusted":true},"outputs":[],"source":["import pickle\n","from torch.autograd import Variable\n","global corr_mult \n","corr_mult =1\n","\n","def optimize_model():\n","    if not hasattr(optimize_model, \"count\"):\n","        optimize_model.count = 0\n","\n","    optimize_model.count += 1\n","\n","\n","\n","    if len(memory) < BATCH_SIZE:\n","        return\n","    transitions = memory.sample(BATCH_SIZE)\n","    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n","    # detailed explanation). This converts batch-array of Transitions\n","    # to Transition of batch-arrays.\n","    batch = Transition(*zip(*transitions))\n","\n","    # Compute a mask of non-final states and concatenate the batch elements\n","    # (a final state would've been the one after which simulation ended)\n","    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n","                                          batch.next_state)), device=device, dtype=torch.bool)\n","    non_final_next_states = torch.cat([s for s in batch.next_state\n","                                                if s is not None])\n","    state_batch = torch.cat(batch.state)\n","    action_batch = torch.cat(batch.action)\n","    reward_batch = torch.cat(batch.reward)\n","\n","    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n","    # columns of actions taken. These are the actions which would've been taken\n","    # for each batch state according to policy_net\n","    # print(\"works until here\")\n","    state_action_values = policy_net(state_batch).gather(1, action_batch)\n","    # print(state_batch[0])\n","    # print(\"policy\"  + str(state_action_values[0]))\n","\n","\n","    # Compute V(s_{t+1}) for all next states.\n","    # Expected values of actions for non_final_next_states are computed based\n","    # on the \"older\" target_net; selecting their best reward with max(1).values\n","    # This is merged based on the mask, such that we'll have either the expected\n","    # state value or 0 in case the state was final.\n","    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n","    with torch.no_grad():\n","        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1).values\n","    # Compute the expected Q values\n","    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n","    # print(reward_batch)\n","    # print(\"expected\" + str(expected_state_action_values[0]))\n","\n","    # Compute Huber loss\n","    criterion = nn.SmoothL1Loss()\n","    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n","    # print(loss)\n","    # if (optimize_model.count % 60 == 0): print(loss)\n","    # print(loss)\n","\n","    # loss = Variable(loss, requires_grad = True)\n","\n","    # with torch.no_grad():\n","    correlation_coeff = call_correlation_coeff_kmeans()\n","    # print(correlation_coeff)\n","\n","    # Define regularization strength\n","\n","    # For LUNAAAA\n","    lambda_corr = 0.1 # You can adjust this parameter as needed\n","\n","    #for ACROOOO\n","    lambda_corr = 0.1\n","#     print(loss, correlation_coeff)\n","\n","     #for Mountyainnnnn\n","    \n","#     corr_mult = 1\n","    lambda_corr = 1 - corr_mult\n","#     lambda_corr = 0.1\n","#     print(loss, correlation_coeff)\n","#     print(lambda_corr)\n","    # Add correlation coefficient regularization term to the loss\n","    loss += (min(0.01,lambda_corr) * correlation_coeff) #(lambda_corr* correlation_coeff)\n","#     print(loss)\n","    # Optimize the model\n","    optimizer.zero_grad()\n","    loss.backward()\n","    # In-place gradient clipping\n","#     torch.nn.utils.clip_grad_value_(policy_net.parameters(), 1)\n","    optimizer.step()\n","    # return correlation_coeff"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T15:46:27.915795Z","iopub.status.busy":"2024-09-06T15:46:27.914569Z","iopub.status.idle":"2024-09-06T15:46:27.932289Z","shell.execute_reply":"2024-09-06T15:46:27.930884Z","shell.execute_reply.started":"2024-09-06T15:46:27.915747Z"},"trusted":true},"outputs":[],"source":["# # For plain dqn\n","# import pickle\n","# from torch.autograd import Variable\n","# global corr_mult \n","# corr_mult =1\n","# def optimize_model():\n","#     if not hasattr(optimize_model, \"count\"):\n","#         optimize_model.count = 0\n","\n","#     optimize_model.count += 1\n","\n","\n","\n","#     if len(memory) < BATCH_SIZE:\n","#         return\n","#     transitions = memory.sample(BATCH_SIZE)\n","#     # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n","#     # detailed explanation). This converts batch-array of Transitions\n","#     # to Transition of batch-arrays.\n","#     batch = Transition(*zip(*transitions))\n","\n","#     # Compute a mask of non-final states and concatenate the batch elements\n","#     # (a final state would've been the one after which simulation ended)\n","#     non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n","#                                           batch.next_state)), device=device, dtype=torch.bool)\n","#     non_final_next_states = torch.cat([s for s in batch.next_state\n","#                                                 if s is not None])\n","#     state_batch = torch.cat(batch.state)\n","#     action_batch = torch.cat(batch.action)\n","#     reward_batch = torch.cat(batch.reward)\n","\n","#     # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n","#     # columns of actions taken. These are the actions which would've been taken\n","#     # for each batch state according to policy_net\n","#     # print(\"works until here\")\n","#     state_action_values = policy_net(state_batch).gather(1, action_batch)\n","#     # print(state_batch[0])\n","#     # print(\"policy\"  + str(state_action_values[0]))\n","\n","\n","#     # Compute V(s_{t+1}) for all next states.\n","#     # Expected values of actions for non_final_next_states are computed based\n","#     # on the \"older\" target_net; selecting their best reward with max(1).values\n","#     # This is merged based on the mask, such that we'll have either the expected\n","#     # state value or 0 in case the state was final.\n","#     next_state_values = torch.zeros(BATCH_SIZE, device=device)\n","#     with torch.no_grad():\n","#         next_state_values[non_final_mask] = target_net(non_final_next_states).max(1).values\n","#     # Compute the expected Q values\n","#     expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n","#     # print(reward_batch)\n","#     # print(\"expected\" + str(expected_state_action_values[0]))\n","\n","#     # Compute Huber loss\n","#     criterion = nn.SmoothL1Loss()\n","#     loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n","\n","#     correlation_coeff = call_correlation_coeff_kmeans()\n","#     # print(loss)\n","#     # if (optimize_model.count % 60 == 0): print(loss)\n","#     # print(loss)\n","\n","#     # loss = Variable(loss, requires_grad = True)\n","\n","    \n","# #     print(loss)\n","#     # Optimize the model\n","#     optimizer.zero_grad()\n","#     loss.backward()\n","#     # In-place gradient clipping\n","# #     torch.nn.utils.clip_grad_value_(policy_net.parameters(), 1)\n","#     optimizer.step()\n","#     return correlation_coeff"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T15:46:30.982185Z","iopub.status.busy":"2024-09-06T15:46:30.981617Z","iopub.status.idle":"2024-09-06T15:48:57.705345Z","shell.execute_reply":"2024-09-06T15:48:57.703934Z","shell.execute_reply.started":"2024-09-06T15:46:30.982147Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1 tensor(0.8411, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.001998999999999973 2.5\n","2 tensor(0.6436, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.002997000999999999 1.6666666666666667\n","3 tensor(0.5573, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.003994003998999962 1.25\n","4 tensor(0.3330, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.004990009995000988 1.0\n","5 tensor(0.2794, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.0059850199850060015 0.8333333333333334\n","6 tensor(0.1593, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.006979034965020947 0.8571428571428571\n","7 tensor(0.1160, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.007972055930055899 0.75\n","8 tensor(0.0567, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.008964083874125839 0.7777777777777778\n","9 tensor(0.0617, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.009955119790251765 1.0\n","10 tensor(0.0371, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.010945164670461471 0.7\n","11 tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.011934219505790988 0.5\n","12 tensor(0.0317, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.012922285286285251 0.5\n","13 tensor(0.0224, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.013909363000998987 0.5\n","14 tensor(0.0099, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.014895453637997935 0.5\n","15 tensor(0.0188, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.01588055818435996 0.5\n","16 tensor(0.0116, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.016864677626175606 0.4\n","17 tensor(-0.0021, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.017847812948549424 0.5\n","18 tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.018829965135600868 0.4\n","19 tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.01981113517046529 0.1\n","20 tensor(-0.0051, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.020791324035294823 0.1\n","21 tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.021770532711259505 0.1\n","22 tensor(0.0134, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.022748762178548265 0.2\n","23 tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.023726013416369707 0.3\n","24 tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.024702287402953327 0.3\n","25 tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.025677585115550405 0.4\n","26 tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.026651907530434893 0.4\n","27 tensor(-0.0016, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.02762525562290441 0.3\n","28 tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.028597630367281468 0.4\n","29 tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.029569032736914136 0.4\n","30 tensor(0.0072, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.03053946370417726 0.4\n","31 tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.031508924240473135 0.4\n","32 tensor(-0.0039, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.032477415316232716 0.4\n","33 tensor(-0.0010, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.033444937900916516 0.3\n","34 tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.0344114929630156 0.3\n","35 tensor(-0.0043, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.035377081470052585 0.2\n","36 tensor(-0.0034, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.03634170438858253 0.2\n","37 tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.03730536268419393 0.3\n","38 tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.03826805732150973 0.2\n","39 tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.039229789264188186 0.2\n","40 tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.040190559474924004 0.2\n","41 tensor(0.0093, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.0411503689154491 0.3\n","42 tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.0421092185465336 0.3\n","43 tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.043067109327987074 0.3\n","44 tensor(-0.0037, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.044024042218659076 0.3\n","45 tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.04498001817644037 0.4\n","46 tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.04593503815826394 0.4\n","47 tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.046889103120105635 0.3\n","48 tensor(0.0108, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.04784221401698552 0.3\n","49 tensor(0.0156, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.04879437180296853 0.3\n","50 tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.04974557743116559 0.3\n","51 tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.050695831853734385 0.2\n","52 tensor(-0.0024, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.0516451360218807 0.2\n","53 tensor(0.0098, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.05259349088585885 0.4\n","54 tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.05354089739497303 0.4\n","55 tensor(-0.0025, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.05448735649757808 0.3\n","56 tensor(0.0406, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.055432869141080476 0.6\n","57 tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.05637743627193936 0.7\n","58 tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.057321058835667404 0.7\n","59 tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.05826373777683169 0.8\n","60 tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.05920547403905485 0.8\n","61 tensor(-6.1290e-05, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.060146268565015815 0.8\n","62 tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.06108612229645083 0.7\n","63 tensor(0.0116, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.062025036174154335 0.6\n","64 tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.0629630111379802 0.8\n","65 tensor(0.0224, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.06390004812684225 0.9\n","66 tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.0648361480787154 0.9\n","67 tensor(-0.0002, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.06577131193063668 0.8\n","68 tensor(0.0349, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.06670554061870604 0.8\n","69 tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.06763883507808732 0.7\n","70 tensor(-0.0004, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.06857119624300922 0.7\n","71 tensor(0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.06950262504676619 0.7\n","72 tensor(-0.0026, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.0704331224217194 0.8\n","73 tensor(0.0358, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.07136268929929768 0.8\n","74 tensor(0.0134, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.07229132660999837 0.6\n","75 tensor(0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.07321903528338836 0.5\n","76 tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.07414581624810501 0.2\n","77 tensor(0.0098, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.07507167043185692 0.2\n","78 tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.07599659876142506 0.2\n","79 tensor(-0.0017, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.07692060216266361 0.2\n","80 tensor(0.0075, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.07784368156050092 0.2\n","81 tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.07876583787894043 0.2\n","82 tensor(-0.0082, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.07968707204106151 0.1\n","83 tensor(-0.0052, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.08060738496902042 0.1\n","84 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.08152677758405136 0.1\n","85 tensor(-0.0064, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.08244525080646725 0.1\n","86 tensor(-0.0016, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.08336280555566078 0.1\n","87 tensor(-0.0052, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.08427944275010513 0.1\n","88 tensor(-0.0092, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.08519516330735499 0.1\n","89 tensor(-0.0020, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.08610996814404759 0.3\n","90 tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.08702385817590352 0.3\n","91 tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.08793683431772759 0.5\n","92 tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.08884889748340985 0.5\n","93 tensor(0.0134, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.08976004858592646 0.5\n","94 tensor(-0.0025, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.0906702885373405 0.5\n","95 tensor(-0.0085, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.09157961824880312 0.5\n","96 tensor(-7.1360e-05, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.09248803863055433 0.7\n","97 tensor(-0.0039, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.09339555059192373 0.7\n","98 tensor(-0.0058, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.09430215504133177 0.7\n","99 tensor(-0.0025, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.09520785288629041 0.5\n","100 tensor(-0.0053, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.09611264503340411 0.6\n","101 tensor(-0.0045, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.09701653238837071 0.5\n","102 tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.09791951585598235 0.5\n","103 tensor(-0.0081, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.09882159634012633 0.4\n","104 tensor(-0.0025, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.09972277474378621 0.4\n","105 tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.10062305196904242 0.5\n","106 tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.10152242891707342 0.4\n","107 tensor(-0.0035, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.10242090648815638 0.4\n","108 tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.10331848558166823 0.4\n","109 tensor(-0.0011, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.10421516709608658 0.5\n","110 tensor(-0.0039, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.10511095192899045 0.4\n","111 tensor(-0.0019, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.10600584097706145 0.3\n","112 tensor(-0.0009, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.10689983513608436 0.4\n","113 tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.10779293530094824 0.5\n","114 tensor(-0.0074, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.1086851423656473 0.6\n","115 tensor(-0.0001, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.10957645722328169 0.5\n","116 tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.11046688076605837 0.4\n","117 tensor(-0.0066, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.11135641388529227 0.4\n","118 tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.112245057471407 0.4\n","119 tensor(-0.0051, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.11313281241393558 0.3\n","120 tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.1140196796015216 0.3\n","121 tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.11490565992192003 0.3\n","122 tensor(-0.0052, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.11579075426199814 0.2\n","123 tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.1166749635077361 0.4\n","124 tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.11755828854422834 0.4\n","125 tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.11844073025568413 0.4\n","126 tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.11932228952542845 0.4\n","127 tensor(0.0076, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.12020296723590307 0.4\n","128 tensor(-0.0092, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.12108276426866715 0.4\n","129 tensor(0.0338, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.12196168150439846 0.4\n","130 tensor(-0.0041, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.1228397198228941 0.4\n","131 tensor(-0.0028, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.12371688010307125 0.4\n","132 tensor(-0.0063, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.1245931632229682 0.4\n","133 tensor(-0.0058, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.1254685700597452 0.1\n","134 tensor(-0.0021, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.12634310148968542 0.0\n","135 tensor(0.0228, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.12721675838819568 0.0\n","136 tensor(-0.0044, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.12808954162980746 0.0\n","137 tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.12896145208817766 0.0\n","138 tensor(-0.0035, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.12983249063608948 0.0\n","139 tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.13070265814545334 0.0\n","140 tensor(-0.0019, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.13157195548730793 0.0\n","141 tensor(-0.0045, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.13244038353182064 0.0\n","142 tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.13330794314828887 0.0\n","143 tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.1341746352051406 0.0\n","144 tensor(0.0087, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.13504046056993546 0.0\n","145 tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.13590542010936557 0.2\n","146 tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.13676951468925624 0.2\n","147 tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.13763274517456703 0.2\n","148 tensor(-0.0018, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.1384951124293925 0.2\n","149 tensor(0.0075, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.13935661731696314 0.3\n","150 tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.14021726069964613 0.3\n","151 tensor(-0.0049, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.14107704343894645 0.3\n","152 tensor(0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.14193596639550754 0.3\n","153 tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.14279403042911198 0.3\n","154 tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.14365123639868282 0.3\n","155 tensor(0.0136, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.14450758516228412 0.1\n","156 tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.14536307757712186 0.1\n","157 tensor(-0.0064, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.14621771449954468 0.2\n","158 tensor(0.0184, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.14707149678504516 0.2\n","159 tensor(-0.0040, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.1479244252882601 0.1\n","160 tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.1487765008629719 0.1\n","161 tensor(-0.0046, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.14962772436210892 0.3\n","162 tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.1504780966377468 0.4\n","163 tensor(-0.0054, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.1513276185411091 0.5\n","164 tensor(-0.0043, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.152176290922568 0.5\n","165 tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.15302411463164545 0.5\n","166 tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.15387109051701375 0.6\n","167 tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.15471721942649674 0.5\n","168 tensor(-0.0013, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.15556250220707024 0.7\n","169 tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.1564069397048632 0.7\n","170 tensor(-0.0086, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.15725053276515832 0.8\n","171 tensor(-0.0102, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.15809328223239316 0.7\n","172 tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.1589351889501608 0.8\n","173 tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.15977625376121063 0.7\n","174 tensor(-0.0078, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.16061647750744945 0.7\n","175 tensor(-0.0023, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.16145586102994203 0.7\n","176 tensor(-0.0084, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.16229440516891214 0.9\n","177 tensor(-0.0067, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.16313211076374323 1.1\n","178 tensor(-0.0023, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.16396897865297944 1.0\n","179 tensor(-0.0004, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.16480500967432643 1.0\n","180 tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.16564020466465212 1.0\n","181 tensor(-0.0036, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.16647456445998743 1.0\n","182 tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.16730808989552748 0.9\n","183 tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.16814078180563197 1.0\n","184 tensor(-0.0026, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.16897264102382636 1.0\n","185 tensor(-0.0034, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.1698036683828026 1.0\n","186 tensor(-0.0048, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.17063386471441977 1.0\n","187 tensor(-0.0029, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.17146323084970538 0.8\n","188 tensor(-0.0032, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.17229176761885567 0.9\n","189 tensor(-0.0029, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.17311947585123677 0.9\n","190 tensor(-0.0052, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.17394635637538558 0.8\n","191 tensor(-0.0067, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.17477241001901023 0.7\n","192 tensor(-0.0015, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.17559763760899116 0.9\n","193 tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.17642203997138217 0.8\n","194 tensor(0.0138, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.1772456179314108 1.0\n","195 tensor(0.0065, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.17806837231347938 1.0\n","196 tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.1788903039411659 1.0\n","197 tensor(-0.0083, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.17971141363722476 1.0\n","198 tensor(-0.0010, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.1805317022235875 0.8\n","199 tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.18135117052136396 0.8\n","200 tensor(-0.0056, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.18216981935084264 0.9\n","201 tensor(-0.0035, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.18298764953149182 0.9\n","202 tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.18380466188196032 0.6\n","203 tensor(-0.0043, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.18462085722007837 0.6\n","204 tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.18543623636285833 0.5\n","205 tensor(-0.0019, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.18625080012649542 0.5\n","206 tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.18706454932636896 0.2\n","207 tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.18787748477704258 0.2\n","208 tensor(-0.0040, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.18868960729226558 0.2\n","209 tensor(-0.0082, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.18950091768497335 0.3\n","210 tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.19031141676728835 0.4\n","211 tensor(-0.0042, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.19112110535052107 0.5\n","212 tensor(0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.1919299842451706 0.5\n","213 tensor(0.0087, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.19273805426092538 0.5\n","214 tensor(-0.0043, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.19354531620666449 0.4\n","215 tensor(0.0071, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.19435177089045785 0.5\n","216 tensor(0.0060, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.1951574191195674 0.6\n","217 tensor(-0.0012, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.19596226170044784 0.6\n","218 tensor(-0.0076, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.19676629943874735 0.6\n","219 tensor(-0.0024, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.19756953313930858 0.5\n","220 tensor(-0.0016, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.19837196360616927 0.3\n","221 tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.1991735916425631 0.2\n","222 tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.19997441805092053 0.2\n","223 tensor(-0.0021, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.20077444363286956 0.5\n","224 tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2015736691892367 0.5\n","225 tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.20237209552004742 0.4\n","226 tensor(-0.0042, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.20316972342452733 0.3\n","227 tensor(-0.0058, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.20396655370110284 0.3\n","228 tensor(-0.0009, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.2047625871474017 0.4\n","229 tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2055578245602543 0.4\n","230 tensor(-0.0067, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.20635226673569407 0.4\n","231 tensor(-0.0085, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.20714591446895836 0.4\n","232 tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.20793876855448945 0.5\n","233 tensor(-0.0041, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.20873082978593493 0.2\n","234 tensor(-0.0040, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.20952209895614904 0.3\n","235 tensor(0.0148, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.21031257685719285 0.5\n","236 tensor(0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.21110226428033563 0.6\n","237 tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.2118911620160553 0.7\n","238 tensor(-0.0032, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.21267927085403926 0.6\n","239 tensor(-0.0080, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.21346659158318526 0.6\n","240 tensor(-0.0055, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.2142531249916021 0.7\n","241 tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.21503887186661053 0.7\n","242 tensor(-0.0059, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.21582383299474395 0.6\n","243 tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.21660800916174916 0.6\n","244 tensor(-0.0014, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.21739140115258737 0.5\n","245 tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.21817400975143475 0.3\n","246 tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.2189558357416833 0.4\n","247 tensor(-0.0064, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.2197368799059416 0.6\n","248 tensor(0.0196, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.22051714302603564 0.6\n","249 tensor(-0.0025, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.22129662588300958 0.6\n","250 tensor(-0.0027, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.22207532925712659 0.5\n","251 tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.22285325392786948 0.6\n","252 tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.22363040067394158 0.6\n","253 tensor(-0.0050, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.2244067702732676 0.8\n","254 tensor(0.0118, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.22518236350299436 0.9\n","255 tensor(-0.0053, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.22595718113949137 0.9\n","256 tensor(-0.0040, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.22673122395835188 0.7\n","257 tensor(-0.0067, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.22750449273439355 0.4\n","258 tensor(-0.0052, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2282769882416592 0.4\n","259 tensor(-0.0051, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.22904871125341753 0.4\n","260 tensor(-0.0024, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.22981966254216413 0.4\n","261 tensor(0.0099, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.23058984287962192 0.3\n","262 tensor(-0.0044, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.23135925303674232 0.3\n","263 tensor(-0.0069, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.23212789378370557 0.1\n","264 tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.2328957658899219 0.1\n","265 tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.23366287012403197 0.1\n","266 tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.23442920725390792 0.1\n","267 tensor(-0.0042, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.235194778046654 0.1\n","268 tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.23595958326860733 0.2\n","269 tensor(0.0093, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.23672362368533872 0.3\n","270 tensor(-0.0027, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.2374869000616534 0.4\n","271 tensor(-0.0046, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.23824941316159176 0.4\n","272 tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.23901116374843012 0.4\n","273 tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.23977215258468165 0.4\n","274 tensor(-0.0039, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.24053238043209701 0.4\n","275 tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.24129184805166493 0.4\n","276 tensor(-0.0060, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.24205055620361327 0.4\n","277 tensor(-0.0023, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.24280850564740963 0.6\n","278 tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.24356569714176224 0.6\n","279 tensor(0.0070, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.24432213144462045 0.5\n","280 tensor(-0.0016, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2450778093131758 0.4\n","281 tensor(0.0068, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.24583273150386264 0.4\n","282 tensor(-0.0008, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.24658689877235873 0.4\n","283 tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.2473403118735864 0.5\n","284 tensor(-0.0014, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.24809297156171284 0.4\n","285 tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.24884487859015114 0.5\n","286 tensor(-0.0036, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.24959603371156103 0.5\n","287 tensor(-0.0063, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.2503464376778495 0.4\n","288 tensor(-0.0004, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2510960912401716 0.3\n","289 tensor(0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.25184499514893144 0.3\n","290 tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2525931501537825 0.3\n","291 tensor(-0.0039, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.2533405570036287 0.4\n","292 tensor(-0.0052, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.254087216446625 0.4\n","293 tensor(0.0070, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2548331292301784 0.3\n","294 tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2555782961009483 0.3\n","295 tensor(-0.0049, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.2563227178048474 0.3\n","296 tensor(-0.0066, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.25706639508704254 0.3\n","297 tensor(-0.0025, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.2578093286919555 0.4\n","298 tensor(-0.0072, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2585515193632636 0.4\n","299 tensor(-0.0066, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.2592929678439003 0.5\n","300 tensor(0.0093, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.26003367487605644 0.5\n","301 tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2607736412011804 0.4\n","302 tensor(-0.0007, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.26151286755997927 0.4\n","303 tensor(-0.0031, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.26225135469241934 0.6\n","304 tensor(-0.0080, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.26298910333772696 0.7\n","305 tensor(0.0156, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.2637261142343892 0.8\n","306 tensor(-0.0024, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.26446238812015477 0.8\n","307 tensor(0.0098, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2651979257320346 0.6\n","308 tensor(-0.0028, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.2659327278063026 0.8\n","309 tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.26666679507849633 0.8\n","310 tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.26740012828341786 0.8\n","311 tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.26813272815513445 0.8\n","312 tensor(-0.0075, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.26886459542697927 0.8\n","313 tensor(0.0184, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2695957308315523 0.6\n","314 tensor(-0.0022, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.2703261351007208 0.6\n","315 tensor(-0.0058, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.2710558089656201 0.5\n","316 tensor(-0.0022, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2717847531566545 0.5\n","317 tensor(-0.0004, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2725129684034978 0.5\n","318 tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.27324045543509434 0.3\n","319 tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.27396721497965926 0.2\n","320 tensor(-0.0021, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2746932477646796 0.2\n","321 tensor(-0.0012, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.275418554516915 0.2\n","322 tensor(0.0076, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.27614313596239803 0.2\n","323 tensor(-0.0003, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2768669928264357 0.2\n","324 tensor(-0.0032, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2775901258336092 0.1\n","325 tensor(-0.0002, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.2783125357077756 0.2\n","326 tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.27903422317206783 0.3\n","327 tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.2797551889488957 0.4\n","328 tensor(-0.0029, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2804754337599469 0.4\n","329 tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2811949583261869 0.4\n","330 tensor(-0.0027, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.28191376336786067 0.6\n","331 tensor(-0.0014, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.28263184960449284 0.8\n","332 tensor(0.0077, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2833492177548883 0.8\n","333 tensor(-0.0042, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.28406586853713345 1.0\n","334 tensor(-0.0021, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.2847818026685963 1.1\n","335 tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.28549702086592776 1.0\n","336 tensor(-0.0026, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.2862115238450619 1.0\n","337 tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.28692531232121676 1.0\n","338 tensor(-0.0007, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.28763838700889555 1.0\n","339 tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2883507486218867 1.0\n","340 tensor(-0.0039, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2890623978732648 0.8\n","341 tensor(-0.0039, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.2897733354753915 1.0\n","342 tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.2904835621399161 1.4\n","343 tensor(-0.0047, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2911930785777762 1.2\n","344 tensor(-0.0055, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.2919018854991985 1.2\n","345 tensor(-0.0006, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2926099836136993 1.1\n","346 tensor(-0.0028, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2933173736300856 1.0\n","347 tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.29402405625645556 0.9\n","348 tensor(-0.0009, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.2947300322001991 1.1\n","349 tensor(-0.0015, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.29543530216799896 1.1\n","350 tensor(-0.0012, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.29613986686583094 1.3\n","351 tensor(-0.0074, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2968437269989651 0.9\n","352 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.2975468832719661 0.6\n","353 tensor(-0.0057, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.2982493363886941 0.6\n","354 tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.29895108705230544 0.7\n","355 tensor(-0.0036, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.2996521359652531 0.8\n","356 tensor(-0.0041, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3003524838292878 0.8\n","357 tensor(-0.0039, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.3010521313454585 0.9\n","358 tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.30175107921411304 0.7\n","359 tensor(-0.0019, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3024493281348989 0.7\n","360 tensor(-0.0012, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.30314687880676394 0.5\n","361 tensor(-0.0058, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3038437319279572 0.5\n","362 tensor(-0.0067, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3045398881960293 0.4\n","363 tensor(-0.0052, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.3052353483078333 0.5\n","364 tensor(-0.0034, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.30593011295952544 0.4\n","365 tensor(-0.0051, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3066241828465659 0.3\n","366 tensor(-0.0050, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.30731755866371935 0.3\n","367 tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.3080102411050556 0.3\n","368 tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.30870223086395054 0.3\n","369 tensor(0.0129, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.30939352863308656 0.3\n","370 tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.31008413510445343 0.3\n","371 tensor(-0.0035, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.31077405096934896 0.3\n","372 tensor(-0.0083, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3114632769183796 0.3\n","373 tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.3121518136414613 0.3\n","374 tensor(-0.0043, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.31283966182781986 0.2\n","375 tensor(-0.0035, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.31352682216599204 0.3\n","376 tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.314213295343826 0.4\n","377 tensor(-0.0058, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.31489908204848216 0.5\n","378 tensor(-0.0055, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.31558418296643365 0.5\n","379 tensor(-0.0046, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.31626859878346725 0.5\n","380 tensor(0.0136, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.31695233018468383 1.1\n","381 tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.31763537785449913 1.3\n","382 tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3183177424766447 1.3\n","383 tensor(-0.0061, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3189994247341681 1.2\n","384 tensor(-0.0053, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.31968042530943397 1.3\n","385 tensor(-0.0011, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3203607448841246 1.2\n","386 tensor(-0.0061, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.3210403841392404 1.2\n","387 tensor(-0.0068, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.32171934375510114 1.3\n","388 tensor(-0.0066, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.322397624411346 1.4\n","389 tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3230752267869347 1.4\n","390 tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3237521515601477 0.8\n","391 tensor(-0.0063, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.3244283994085876 0.7\n","392 tensor(-0.0044, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.325103971009179 0.8\n","393 tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.32577886703816983 0.8\n","394 tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3264530881711316 0.7\n","395 tensor(-0.0004, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.32712663508296047 0.8\n","396 tensor(-0.0051, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.32779950844787753 0.7\n","397 tensor(-0.0042, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.3284717089394297 0.5\n","398 tensor(-0.0026, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3291432372304902 0.4\n","399 tensor(-0.0067, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.32981409399325967 0.5\n","400 tensor(-0.0084, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.33048427989926643 0.5\n","401 tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3311537956193672 0.4\n","402 tensor(-0.0067, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3318226418237479 0.3\n","403 tensor(-0.0036, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.33249081918192414 0.4\n","404 tensor(-5.0008e-05, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.3331583283627422 0.5\n","405 tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.3338251700343794 0.5\n","406 tensor(-0.0090, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.33449134486434506 0.6\n","407 tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.33515685351948077 0.8\n","408 tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.3358216966659613 0.9\n","409 tensor(0.0056, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3364858749692953 0.8\n","410 tensor(0.0085, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.337149389094326 0.9\n","411 tensor(-0.0051, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.33781223970523166 1.2\n","412 tensor(-0.0005, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.3384744274655265 1.3\n","413 tensor(0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.339135953038061 1.2\n","414 tensor(-0.0032, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.33979681708502296 1.1\n","415 tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3404570202679379 1.0\n","416 tensor(-0.0063, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3411165632476699 0.9\n","417 tensor(-0.0058, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3417754466844223 0.6\n","418 tensor(0.0138, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3424336712377378 0.5\n","419 tensor(-0.0065, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.34309123756650006 0.5\n","420 tensor(-0.0046, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3437481463289336 0.4\n","421 tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.3444043981826046 0.3\n","422 tensor(-0.0059, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.345059993784422 0.2\n","423 tensor(-0.0035, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.34571493379063756 0.2\n","424 tensor(0.0097, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.3463692188568469 0.4\n","425 tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.34702284963799 0.7\n","426 tensor(-0.0002, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.34767582678835207 0.8\n","427 tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.34832815096156367 0.8\n","428 tensor(-0.0040, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.34897982281060214 0.8\n","429 tensor(-0.0029, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.34963084298779157 0.9\n","430 tensor(-0.0052, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.3502812121448038 1.0\n","431 tensor(-0.0021, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.35093093093265904 0.9\n","432 tensor(-0.0053, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3515800000017264 0.9\n","433 tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3522284200017247 0.9\n","434 tensor(-8.2141e-05, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.352876191581723 0.7\n","435 tensor(-0.0045, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.35352331539014126 0.4\n","436 tensor(-8.4462e-05, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3541697920747511 0.3\n","437 tensor(-0.0031, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.3548156222826764 0.5\n","438 tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3554608066603937 0.5\n","439 tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3561053458537333 0.4\n","440 tensor(-0.0093, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3567492405078796 0.3\n","441 tensor(-0.0037, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3573924912673717 0.2\n","442 tensor(0.0072, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3580350987761044 0.2\n","443 tensor(-0.0064, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3586770636773283 0.2\n","444 tensor(-0.0008, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.359318386613651 0.2\n","445 tensor(-0.0029, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3599590682270374 0.2\n","446 tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3605991091588103 0.2\n","447 tensor(-0.0038, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.36123851004965146 0.3\n","448 tensor(-0.0037, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.3618772715396018 0.5\n","449 tensor(-0.0043, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.36251539426806223 0.5\n","450 tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3631528788737942 0.5\n","451 tensor(-0.0011, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.36378972599492043 0.6\n","452 tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3644259362689255 0.6\n","453 tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.36506151033265655 0.6\n","454 tensor(-0.0051, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3656964488223239 0.6\n","455 tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.36633075237350154 0.6\n","456 tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3669644216211281 0.6\n","457 tensor(-0.0038, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.367597457199507 0.6\n","458 tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3682298597423075 0.4\n","459 tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3688616298825652 0.4\n","460 tensor(-0.0059, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3694927682526826 0.4\n","461 tensor(-0.0024, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3701232754844299 0.3\n","462 tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.37075315220894545 0.4\n","463 tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.37138239905673653 0.4\n","464 tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.37201101665767977 0.6\n","465 tensor(-0.0106, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.37263900564102215 0.7\n","466 tensor(-0.0016, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.37326636663538115 0.7\n","467 tensor(-0.0085, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.3738931002687458 0.6\n","468 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.3745192071684771 0.7\n","469 tensor(-0.0014, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3751446879613086 0.7\n","470 tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.37576954327334733 0.7\n","471 tensor(-0.0098, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.376393773730074 0.7\n","472 tensor(-0.0033, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3770173799563439 0.6\n","473 tensor(-0.0088, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.37764036257638756 0.7\n","474 tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3782627222138112 0.5\n","475 tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3788844594915973 0.4\n","476 tensor(-0.0065, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3795055750321057 0.4\n","477 tensor(-0.0066, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.3801260694570736 0.3\n","478 tensor(-0.0058, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3807459433876166 0.2\n","479 tensor(-0.0074, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3813651974442289 0.2\n","480 tensor(-0.0091, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.38198383224678467 0.2\n","481 tensor(-0.0032, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3826018484145379 0.2\n","482 tensor(-0.0054, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3832192465661234 0.2\n","483 tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.38383602731955724 0.1\n","484 tensor(-0.0006, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.38445219129223773 0.1\n","485 tensor(-0.0038, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3850677391009455 0.1\n","486 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.38568267136184453 0.4\n","487 tensor(-0.0068, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.3862969886904827 0.5\n","488 tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.38691069170179215 0.6\n","489 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.38752378101009033 0.6\n","490 tensor(-0.0065, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3881362572290802 0.6\n","491 tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.3887481209718511 0.8\n","492 tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3893593728508792 0.8\n","493 tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3899700134780283 0.8\n","494 tensor(-0.0068, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3905800434645502 0.8\n","495 tensor(0.0142, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3911894634210856 0.8\n","496 tensor(-0.0083, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.39179827395766453 0.5\n","497 tensor(-0.0032, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.3924064756837069 0.4\n","498 tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.3930140692080232 0.4\n","499 tensor(-0.0011, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.3936210551388152 0.8\n","500 tensor(-0.0111, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.39422743408367633 0.8\n","501 tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.39483320664959265 1.0\n","502 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3954383734429431 1.0\n","503 tensor(-0.0069, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.39604293506950017 1.0\n","504 tensor(-0.0085, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3966468921344307 1.0\n","505 tensor(-0.0010, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.39725024524229624 1.2\n","506 tensor(-0.0068, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.39785299499705395 1.5\n","507 tensor(-0.0018, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3984551420020569 1.4\n","508 tensor(-0.0064, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3990566868600548 1.3\n","509 tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.3996576301731948 0.9\n","510 tensor(-0.0070, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.40025797254302153 0.9\n","511 tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4008577145704785 0.5\n","512 tensor(-0.0049, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.40145685685590804 0.5\n","513 tensor(-0.0026, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.40205539999905215 0.5\n","514 tensor(-0.0017, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.4026533445990531 0.6\n","515 tensor(-0.0029, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.403250691254454 0.4\n","516 tensor(-0.0008, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.40384744056319954 0.2\n","517 tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.40444359312263634 0.2\n","518 tensor(-0.0079, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.4050391495295137 0.3\n","519 tensor(-0.0034, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.4056341103799842 0.6\n","520 tensor(-0.0044, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.40622847626960423 0.6\n","521 tensor(-0.0042, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.40682224779333465 0.6\n","522 tensor(-0.0132, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.40741542554554133 0.6\n","523 tensor(-0.0053, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.40800801011999577 0.8\n","524 tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4086000021098758 0.7\n","525 tensor(-5.7791e-05, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.40919140210776594 0.9\n","526 tensor(-0.0039, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.40978221070565823 0.9\n","527 tensor(-0.0099, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4103724284949526 0.9\n","528 tensor(-0.0049, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.41096205606645764 0.8\n","529 tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.41155109401039114 0.5\n","530 tensor(-0.0053, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.4121395429163808 0.7\n","531 tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.41272740337346436 0.8\n","532 tensor(-0.0033, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.41331467597009086 1.0\n","533 tensor(-0.0041, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4139013612941208 0.8\n","534 tensor(-0.0031, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.41448745993282665 0.8\n","535 tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4150729724728939 0.6\n","536 tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.415657899500421 0.6\n","537 tensor(-0.0084, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4162422416009206 0.6\n","538 tensor(-0.0076, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.41682599935931963 0.6\n","539 tensor(-0.0088, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4174091733599603 0.6\n","540 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.41799176418660033 0.4\n","541 tensor(-0.0093, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4185737724224138 0.3\n","542 tensor(-0.0050, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4191551986499914 0.1\n","543 tensor(-0.0047, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4197360434513414 0.1\n","544 tensor(-0.0049, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.42031630740789006 0.1\n","545 tensor(-0.0021, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.42089599110048215 0.1\n","546 tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.42147509510938164 0.0\n","547 tensor(-0.0093, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.42205362001427227 0.0\n","548 tensor(-0.0089, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.42263156639425803 0.1\n","549 tensor(-0.0069, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.4232089348278638 0.2\n","550 tensor(-0.0057, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.423785725893036 0.2\n","551 tensor(-0.0112, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4243619401671429 0.2\n","552 tensor(-0.0057, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.42493757822697575 0.2\n","553 tensor(-0.0086, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.42551264064874883 0.2\n","554 tensor(-0.0046, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4260871280081001 0.2\n","555 tensor(-0.0029, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.42666104088009205 0.2\n","556 tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.427234379839212 0.4\n","557 tensor(-0.0072, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.4278071454593728 0.5\n","558 tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4283793383139134 0.4\n","559 tensor(-0.0066, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.42895095897559943 0.4\n","560 tensor(-0.0071, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4295220080166239 0.4\n","561 tensor(-0.0063, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4300924860086073 0.4\n","562 tensor(0.0069, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.4306623935225987 0.5\n","563 tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4312317311290761 0.5\n","564 tensor(-0.0016, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.43180049939794707 0.6\n","565 tensor(-0.0021, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4323686988985491 0.6\n","566 tensor(-0.0020, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4329363301996506 0.4\n","567 tensor(-0.0076, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4335033938694509 0.3\n","568 tensor(-0.0065, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4340698904755814 0.3\n","569 tensor(-0.0059, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.43463582058510586 0.2\n","570 tensor(0.0070, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.43520118476452074 0.2\n","571 tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.43576598357975627 0.2\n","572 tensor(-0.0030, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.4363302175961765 0.7\n","573 tensor(-0.0092, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.43689388737858037 0.8\n","574 tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.4374569934912018 0.8\n","575 tensor(-0.0075, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.43801953649771064 0.9\n","576 tensor(-0.0024, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.43858151696121295 1.1\n","577 tensor(-0.0061, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.43914293544425176 1.1\n","578 tensor(-0.0094, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.43970379250880753 1.2\n","579 tensor(-0.0044, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.44026408871629874 1.2\n","580 tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.4408238246275824 1.6\n","581 tensor(-0.0028, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4413830008029548 1.6\n","582 tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4419416178021518 1.0\n","583 tensor(-0.0033, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.4424996761843496 1.0\n","584 tensor(-0.0073, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.44305717650816523 0.9\n","585 tensor(-0.0019, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.44361411933165706 1.0\n","586 tensor(-0.0023, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4441705052123254 0.8\n","587 tensor(8.2440e-05, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.4447263347071131 0.9\n","588 tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.44528160837240593 0.8\n","589 tensor(-0.0032, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.4458363267640335 0.9\n","590 tensor(-0.0042, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.4463904904372695 0.6\n","591 tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.44694409994683226 0.6\n","592 tensor(-0.0116, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.44749715584688543 0.6\n","593 tensor(-0.0090, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.4480496586910385 0.7\n","594 tensor(-0.0096, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.44860160903234747 0.7\n","595 tensor(-0.0026, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.4491530074233151 0.7\n","596 tensor(-0.0097, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4497038544158918 0.7\n","597 tensor(-0.0090, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.4502541505614759 0.9\n","598 tensor(-0.0094, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.45080389641091445 0.9\n","599 tensor(-0.0059, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.4513530925145035 1.1\n","600 tensor(-0.0079, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.45190173942198897 1.1\n","601 tensor(-0.0016, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.45244983768256697 1.1\n","602 tensor(-0.0044, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4529973878448844 1.1\n","603 tensor(-0.0057, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.45354439045703954 1.1\n","604 tensor(-0.0042, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.45409084606658245 1.1\n","605 tensor(-0.0091, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.45463675522051583 1.2\n","606 tensor(-0.0052, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.4551821184652953 1.6\n","607 tensor(-0.0042, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.45572693634683004 1.3\n","608 tensor(-0.0015, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.45627120941048316 1.3\n","609 tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.45681493820107266 1.0\n","610 tensor(-0.0045, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4573581232628716 0.9\n","611 tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.45790076513960876 0.9\n","612 tensor(-0.0041, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.45844286437446913 0.9\n","613 tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.45898442151009466 0.7\n","614 tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.4595254370885846 0.8\n","615 tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.460065911651496 0.5\n","616 tensor(-0.0061, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.46060584573984453 0.1\n","617 tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.4611452398941047 0.3\n","618 tensor(-0.0052, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.46168409465421056 0.3\n","619 tensor(-0.0096, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4622224105595564 0.3\n","620 tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4627601881489968 0.3\n","621 tensor(-0.0098, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.46329742796084783 0.3\n","622 tensor(0.0108, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.463834130532887 0.4\n","623 tensor(0.0096, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.46437029640235417 0.4\n","624 tensor(-0.0004, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.46490592610595183 0.3\n","625 tensor(-0.0009, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.4654410201798459 0.4\n","626 tensor(-0.0039, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.46597557915966603 0.4\n","627 tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4665096035805064 0.2\n","628 tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.4670430939769259 0.4\n","629 tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.46757605088294896 0.6\n","630 tensor(-0.0023, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.46810847483206597 0.9\n","631 tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.46864036635723394 1.0\n","632 tensor(-0.0070, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.46917172599087675 0.9\n","633 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.46970255426488583 0.9\n","634 tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4702328517106209 0.9\n","635 tensor(-0.0090, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.47076261885891024 0.8\n","636 tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4712918562400513 0.8\n","637 tensor(-0.0042, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.47182056438381126 0.9\n","638 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.4723487438194275 0.9\n","639 tensor(-0.0042, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4728763950756081 0.7\n","640 tensor(-0.0063, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.47340351868053243 0.5\n","641 tensor(-0.0051, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4739301151618519 0.4\n","642 tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.47445618504669007 0.7\n","643 tensor(-0.0059, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.47498172886164336 0.8\n","644 tensor(-0.0078, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.47550674713278174 0.9\n","645 tensor(0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4760312403856489 0.9\n","646 tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.4765552091452633 1.0\n","647 tensor(-0.0062, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.47707865393611804 0.9\n","648 tensor(-0.0058, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.47760157528218194 0.9\n","649 tensor(-0.0060, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.47812397370689974 0.9\n","650 tensor(-0.0074, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.4786458497331928 0.9\n","651 tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.47916720388345957 1.0\n","652 tensor(-0.0062, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.47968803667957616 1.0\n","653 tensor(-0.0050, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.48020834864289663 1.0\n","654 tensor(-0.0049, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.4807281402942537 1.0\n","655 tensor(-0.0009, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4812474121539595 1.0\n","656 tensor(-0.0081, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.48176616474180556 1.0\n","657 tensor(-0.0054, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.48228439857706373 1.0\n","658 tensor(-0.0084, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.4828021141784866 0.9\n","659 tensor(-0.0052, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.4833193120643081 1.0\n","660 tensor(-0.0012, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.48383599275224376 0.9\n","661 tensor(-0.0065, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4843521567594915 0.8\n","662 tensor(-0.0037, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.48486780460273204 0.5\n","663 tensor(-0.0021, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.48538293679812927 0.5\n","664 tensor(-0.0060, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.48589755386133116 0.6\n","665 tensor(-0.0089, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.48641165630746985 0.6\n","666 tensor(-0.0053, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.4869252446511624 0.7\n","667 tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.48743831940651117 0.7\n","668 tensor(0.0068, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4879508810871046 0.6\n","669 tensor(-0.0029, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.4884629302060175 0.6\n","670 tensor(-0.0020, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.4889744672758115 0.7\n","671 tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.4894854928085357 1.0\n","672 tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4899960073157271 1.0\n","673 tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4905060113084114 0.9\n","674 tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.491015505297103 0.8\n","675 tensor(-0.0047, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.49152448979180596 0.9\n","676 tensor(-0.0077, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4920329653020141 0.7\n","677 tensor(-0.0045, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.49254093233671215 0.7\n","678 tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.4930483914043754 0.8\n","679 tensor(0.0188, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.493555343012971 0.8\n","680 tensor(-0.0036, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.494061787669958 0.7\n","681 tensor(-0.0098, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.49456772588228803 0.4\n","682 tensor(-0.0072, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.49507315815640573 0.4\n","683 tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4955780849982493 0.4\n","684 tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.49608250691325106 0.3\n","685 tensor(-0.0042, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4965864244063378 0.2\n","686 tensor(-0.0114, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4970898379819315 0.2\n","687 tensor(-0.0049, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.4975927481439496 0.4\n","688 tensor(-0.0090, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.4980951553958056 0.4\n","689 tensor(-0.0076, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.49859706024040984 0.4\n","690 tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.4990984631801695 0.4\n","691 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.4995993647169893 0.5\n","692 tensor(-0.0060, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.5000997653522723 0.8\n","693 tensor(-0.0069, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.50059966558692 0.8\n","694 tensor(-0.0015, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5010990659213331 0.9\n","695 tensor(-0.0029, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5015979668554118 0.9\n","696 tensor(-0.0108, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5020963688885565 1.1\n","697 tensor(-0.0100, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5025942725196679 0.9\n","698 tensor(-0.0076, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5030916782471482 0.8\n","699 tensor(-0.0041, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5035885865689012 0.7\n","700 tensor(-0.0068, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5040849979823322 0.7\n","701 tensor(-0.0092, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5045809129843499 0.7\n","702 tensor(-0.0079, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5050763320713656 0.5\n","703 tensor(-0.0025, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5055712557392942 0.6\n","704 tensor(-0.0044, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5060656844835549 0.5\n","705 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5065596187990713 0.5\n","706 tensor(-0.0022, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5070530591802722 0.4\n","707 tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.5075460061210919 0.7\n","708 tensor(-0.0064, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5080384601149709 0.7\n","709 tensor(-0.0050, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5085304216548558 0.8\n","710 tensor(-0.0086, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5090218912332011 0.8\n","711 tensor(-0.0091, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5095128693419679 0.7\n","712 tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5100033564726258 0.6\n","713 tensor(-0.0045, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5104933531161533 0.5\n","714 tensor(-0.0042, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5109828597630371 0.5\n","715 tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5114718769032741 0.5\n","716 tensor(-0.0016, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5119604050263709 0.6\n","717 tensor(0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5124484446213444 0.5\n","718 tensor(-0.0033, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5129359961767231 0.5\n","719 tensor(-0.0057, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.5134230601805464 0.7\n","720 tensor(-0.0006, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5139096371203659 0.7\n","721 tensor(-0.0042, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5143957274832455 0.9\n","722 tensor(-0.0061, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5148813317557622 0.9\n","723 tensor(-0.0038, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5153664504240065 0.9\n","724 tensor(-0.0041, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5158510839735825 0.9\n","725 tensor(-0.0065, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5163352328896089 0.9\n","726 tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5168188976567193 0.7\n","727 tensor(-0.0092, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5173020787590625 0.5\n","728 tensor(-0.0047, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5177847766803035 0.5\n","729 tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5182669919036232 0.2\n","730 tensor(-0.0003, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5187487249117196 0.3\n","731 tensor(-0.0027, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.519229976186808 0.2\n","732 tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5197107462106212 0.2\n","733 tensor(-0.0055, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5201910354644106 0.2\n","734 tensor(8.2867e-05, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5206708444289461 0.2\n","735 tensor(-0.0057, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5211501735845172 0.2\n","736 tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5216290234109326 0.3\n","737 tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5221073943875217 0.4\n","738 tensor(-0.0050, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5225852869931342 0.4\n","739 tensor(-0.0053, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5230627017061411 0.5\n","740 tensor(-0.0006, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5235396390044349 0.4\n","741 tensor(-0.0088, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5240160993654306 0.4\n","742 tensor(-0.0061, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.5244920832660651 0.8\n","743 tensor(-0.0012, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5249675911827991 1.0\n","744 tensor(-0.0043, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5254426235916163 1.0\n","745 tensor(-0.0044, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5259171809680246 1.0\n","746 tensor(-0.0042, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5263912637870567 1.0\n","747 tensor(-0.0038, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5268648725232696 0.9\n","748 tensor(-0.0070, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5273380076507463 0.9\n","749 tensor(-0.0023, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5278106696430955 0.9\n","750 tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5282828589734525 0.9\n","751 tensor(-0.0046, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.528754576114479 0.8\n","752 tensor(9.6832e-06, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5292258215383645 0.4\n","753 tensor(-0.0077, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5296965957168263 0.3\n","754 tensor(0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5301668991211094 0.4\n","755 tensor(-0.0046, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5306367322219883 0.4\n","756 tensor(-0.0076, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5311060954897663 0.3\n","757 tensor(-0.0040, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5315749893942765 0.3\n","758 tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5320434144048822 0.3\n","759 tensor(-0.0038, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5325113709904774 0.2\n","760 tensor(-0.0055, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5329788596194869 0.2\n","761 tensor(-0.0055, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5334458807598674 0.3\n","762 tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5339124348791076 0.3\n","763 tensor(-0.0061, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5343785224442283 0.2\n","764 tensor(-0.0035, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5348441439217841 0.1\n","765 tensor(-0.0096, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5353092997778623 0.2\n","766 tensor(-0.0047, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5357739904780845 0.3\n","767 tensor(-0.0030, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5362382164876064 0.3\n","768 tensor(-0.0049, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5367019782711188 0.4\n","769 tensor(-0.0002, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5371652762928476 0.4\n","770 tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5376281110165548 0.5\n","771 tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5380904829055383 0.4\n","772 tensor(-0.0040, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5385523924226328 0.4\n","773 tensor(-0.0014, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5390138400302101 0.4\n","774 tensor(-0.0059, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.53947482619018 0.7\n","775 tensor(-0.0044, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5399353513639897 0.6\n","776 tensor(-0.0067, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5403954160126259 0.5\n","777 tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5408550205966132 0.5\n","778 tensor(-0.0011, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5413141655760165 0.5\n","779 tensor(-0.0001, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5417728514104405 0.5\n","780 tensor(0.0082, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5422310785590301 0.4\n","781 tensor(-0.0067, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5426888474804711 0.4\n","782 tensor(-0.0033, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5431461586329906 0.4\n","783 tensor(-0.0034, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5436030124743576 0.4\n","784 tensor(-0.0033, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5440594094618832 0.2\n","785 tensor(-0.0049, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5445153500524214 0.2\n","786 tensor(-0.0057, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.544970834702369 0.2\n","787 tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5454258638676666 0.2\n","788 tensor(-0.0012, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5458804380037989 0.3\n","789 tensor(-0.0066, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5463345575657951 0.4\n","790 tensor(-0.0060, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5467882230082293 0.4\n","791 tensor(-0.0003, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.547241434785221 0.4\n","792 tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5476941933504358 0.4\n","793 tensor(-0.0064, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5481464991570854 0.6\n","794 tensor(-0.0031, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5485983526579283 0.5\n","795 tensor(-0.0027, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5490497543052704 0.6\n","796 tensor(-0.0063, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.5495007045509651 0.9\n","797 tensor(-0.0040, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5499512038464142 1.1\n","798 tensor(-0.0025, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5504012526425677 0.9\n","799 tensor(0.0255, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5508508513899252 0.9\n","800 tensor(-0.0063, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5513000005385352 0.9\n","801 tensor(-0.0028, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5517487005379966 0.9\n","802 tensor(-0.0075, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.5521969518374588 1.4\n","803 tensor(-0.0039, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5526447548856213 1.4\n","804 tensor(-0.0018, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5530921101307356 1.4\n","805 tensor(-0.0006, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5535390180206049 1.4\n","806 tensor(-0.0007, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5539854790025842 1.2\n","807 tensor(-0.0025, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5544314935235817 1.0\n","808 tensor(-0.0081, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.554877062030058 1.0\n","809 tensor(-0.0020, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5553221849680281 0.9\n","810 tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5557668627830601 1.1\n","811 tensor(-0.0024, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.556211095920277 1.2\n","812 tensor(-0.0073, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5566548848243567 0.7\n","813 tensor(-0.0019, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5570982299395323 0.5\n","814 tensor(-0.0060, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5575411317095927 0.6\n","815 tensor(-0.0026, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5579835905778832 0.5\n","816 tensor(-0.0061, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5584256069873053 0.4\n","817 tensor(-0.0108, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5588671813803179 0.4\n","818 tensor(-0.0117, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5593083141989377 0.6\n","819 tensor(-0.0084, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5597490058847387 0.6\n","820 tensor(-0.0080, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.560189256878854 0.4\n","821 tensor(-0.0044, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5606290676219752 0.4\n","822 tensor(-0.0077, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5610684385543532 0.4\n","823 tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5615073701157988 0.4\n","824 tensor(-0.0070, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.561945862745683 0.3\n","825 tensor(0.0098, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5623839168829373 0.3\n","826 tensor(-0.0036, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5628215329660544 0.4\n","827 tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5632587114330883 0.4\n","828 tensor(-0.0059, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5636954527216552 0.4\n","829 tensor(-0.0053, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5641317572689335 0.4\n","830 tensor(-0.0017, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5645676255116646 0.5\n","831 tensor(-0.0098, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5650030578861529 0.6\n","832 tensor(-0.0035, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5654380548282668 0.7\n","833 tensor(-0.0067, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5658726167734385 0.8\n","834 tensor(-0.0069, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5663067441566652 0.8\n","835 tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5667404374125085 0.8\n","836 tensor(-0.0035, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.567173696975096 0.7\n","837 tensor(-0.0075, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.5676065232781209 1.1\n","838 tensor(-0.0067, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5680389167548427 1.1\n","839 tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5684708778380878 1.1\n","840 tensor(-0.0056, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5689024069602497 1.0\n","841 tensor(-0.0048, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5693335045532896 0.9\n","842 tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5697641710487362 0.8\n","843 tensor(-0.0092, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5701944068776875 0.7\n","844 tensor(-0.0068, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5706242124708099 0.7\n","845 tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5710535882583391 0.9\n","846 tensor(-0.0062, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5714825346700807 0.9\n","847 tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5719110521354107 0.5\n","848 tensor(-9.3988e-05, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5723391410832752 0.3\n","849 tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.572766801942192 0.4\n","850 tensor(-0.0060, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5731940351402498 0.4\n","851 tensor(-0.0073, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5736208411051096 0.3\n","852 tensor(-0.0068, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5740472202640045 0.4\n","853 tensor(-0.0039, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5744731730437405 0.4\n","854 tensor(-0.0044, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5748986998706966 0.4\n","855 tensor(-0.0043, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5753238011708259 0.3\n","856 tensor(-0.0028, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5757484773696552 0.4\n","857 tensor(-0.0032, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5761727288922855 0.4\n","858 tensor(-0.0022, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5765965561633932 0.4\n","859 tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5770199596072298 0.3\n","860 tensor(-0.0018, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5774429396476226 0.3\n","861 tensor(-0.0088, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.577865496707975 0.3\n","862 tensor(-0.0057, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.578287631211267 0.2\n","863 tensor(-0.0056, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5787093435800559 0.4\n","864 tensor(-0.0035, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5791306342364757 0.4\n","865 tensor(-0.0071, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5795515036022393 0.3\n","866 tensor(-0.0091, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5799719520986371 0.2\n","867 tensor(-0.0056, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5803919801465385 0.4\n","868 tensor(-0.0068, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5808115881663919 0.4\n","869 tensor(-0.0045, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5812307765782254 0.5\n","870 tensor(-0.0049, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5816495458016473 0.7\n","871 tensor(-0.0017, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5820678962558457 0.7\n","872 tensor(-0.0083, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5824858283595897 0.7\n","873 tensor(-0.0033, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5829033425312302 0.5\n","874 tensor(-0.0021, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5833204391886989 0.5\n","875 tensor(-0.0069, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5837371187495102 0.5\n","876 tensor(-0.0057, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5841533816307607 0.5\n","877 tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5845692282491299 0.5\n","878 tensor(-0.0009, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5849846590208809 0.7\n","879 tensor(0.0071, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5853996743618599 0.6\n","880 tensor(-0.0076, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5858142746874981 0.4\n","881 tensor(-0.0012, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5862284604128105 0.5\n","882 tensor(-0.0075, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5866422319523978 0.5\n","883 tensor(-0.0129, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5870555897204455 0.5\n","884 tensor(-0.0065, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.587468534130725 0.5\n","885 tensor(-0.0054, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5878810655965943 0.6\n","886 tensor(-0.0085, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.5882931845309977 1.1\n","887 tensor(-0.0011, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5887048913464666 0.9\n","888 tensor(-0.0065, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5891161864551202 0.7\n","889 tensor(-0.0017, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.589527070268665 0.7\n","890 tensor(-0.0069, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5899375431983964 0.7\n","891 tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.590347605655198 1.0\n","892 tensor(-0.0018, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5907572580495428 1.2\n","893 tensor(-0.0058, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5911665007914932 1.2\n","894 tensor(-0.0054, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5915753342907017 1.2\n","895 tensor(-0.0072, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.591983758956411 1.1\n","896 tensor(-0.0114, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5923917751974546 0.6\n","897 tensor(-0.0070, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5927993834222571 0.6\n","898 tensor(-0.0033, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.593206584038835 0.9\n","899 tensor(-0.0044, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.593613377454796 1.0\n","900 tensor(-0.0116, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.5940197640773413 1.1\n","901 tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5944257443132639 0.7\n","902 tensor(-0.0058, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5948313185689507 0.5\n","903 tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5952364872503817 0.5\n","904 tensor(-0.0078, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5956412507631312 0.5\n","905 tensor(-0.0025, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5960456095123682 0.5\n","906 tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5964495639028558 0.5\n","907 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.5968531143389529 0.7\n","908 tensor(-0.0053, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.597256261224614 0.5\n","909 tensor(-0.0083, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5976590049633894 0.4\n","910 tensor(-0.0069, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5980613459584261 0.3\n","911 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5984632846124676 0.3\n","912 tensor(-0.0096, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5988648213278551 0.3\n","913 tensor(-0.0078, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5992659565065273 0.3\n","914 tensor(-0.0007, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.5996666905500208 0.3\n","915 tensor(-0.0076, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6000670238594707 0.5\n","916 tensor(-0.0053, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6004669568356114 0.5\n","917 tensor(-0.0058, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.6008664898787757 0.8\n","918 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6012656233888969 0.7\n","919 tensor(-0.0053, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.601664357765508 0.7\n","920 tensor(-0.0018, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6020626934077424 0.8\n","921 tensor(-0.0044, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6024606307143348 0.8\n","922 tensor(-0.0043, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6028581700836204 0.9\n","923 tensor(-0.0029, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6032553119135369 1.1\n","924 tensor(-0.0071, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6036520566016232 1.1\n","925 tensor(-0.0067, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6040484045450216 1.0\n","926 tensor(-0.0062, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6044443561404766 1.0\n","927 tensor(-0.0006, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6048399117843362 0.5\n","928 tensor(-0.0016, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6052350718725519 0.6\n","929 tensor(-0.0046, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6056298368006793 0.7\n","930 tensor(-0.0059, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6060242069638786 0.6\n","931 tensor(-0.0072, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6064181827569147 0.6\n","932 tensor(-0.0060, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6068117645741578 0.6\n","933 tensor(-0.0093, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6072049528095836 0.4\n","934 tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.607597747856774 0.5\n","935 tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6079901501089173 0.4\n","936 tensor(-0.0079, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6083821599588084 0.4\n","937 tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6087737777988496 0.4\n","938 tensor(0.0115, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6091650040210508 0.3\n","939 tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6095558390170297 0.2\n","940 tensor(-0.0067, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6099462831780127 0.2\n","941 tensor(-0.0104, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6103363368948347 0.2\n","942 tensor(-0.0041, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6107260005579398 0.1\n","943 tensor(-0.0044, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6111152745573819 0.1\n","944 tensor(-0.0028, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.6115041592828245 0.4\n","945 tensor(-0.0085, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6118926551235417 0.5\n","946 tensor(-0.0048, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6122807624684181 0.5\n","947 tensor(-0.0056, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6126684817059497 0.6\n","948 tensor(-0.0081, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6130558132242437 0.7\n","949 tensor(-0.0066, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6134427574110195 0.7\n","950 tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.6138293146536085 1.2\n","951 tensor(-0.0056, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.6142154853389549 1.6\n","952 tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.6146012698536159 1.9\n","953 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6149866685837623 1.9\n","954 tensor(-0.0009, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6153716819151784 1.5\n","955 tensor(-0.0050, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6157563102332633 1.6\n","956 tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.61614055392303 1.6\n","957 tensor(0.0071, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.616524413369107 1.6\n","958 tensor(-0.0036, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.616907888955738 1.5\n","959 tensor(-0.0108, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6172909810667822 1.5\n","960 tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6176736900857154 1.1\n","961 tensor(-0.0062, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6180560163956297 0.8\n","962 tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.618437960379234 0.6\n","963 tensor(-0.0040, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6188195224188549 0.7\n","964 tensor(-0.0065, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6192007028964359 0.7\n","965 tensor(-0.0063, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.6195815021935396 1.0\n","966 tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.619961920691346 1.0\n","967 tensor(-0.0078, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6203419587706547 0.9\n","968 tensor(-0.0012, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.620721616811884 0.9\n","969 tensor(-0.0033, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6211008951950721 0.9\n","970 tensor(-0.0035, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6214797942998771 0.8\n","971 tensor(-0.0018, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6218583145055772 0.9\n","972 tensor(0.0065, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6222364561910716 0.9\n","973 tensor(-0.0037, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6226142197348805 0.8\n","974 tensor(-0.0040, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6229916055151457 0.9\n","975 tensor(-0.0069, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6233686139096305 0.4\n","976 tensor(-0.0024, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6237452452957208 0.5\n","977 tensor(0.0056, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6241215000504251 0.5\n","978 tensor(-0.0064, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6244973785503747 0.6\n","979 tensor(-0.0104, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6248728811718243 0.7\n","980 tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6252480082906525 0.9\n","981 tensor(-0.0045, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6256227602823619 0.7\n","982 tensor(-0.0097, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6259971375220794 0.6\n","983 tensor(-0.0013, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.6263711403845573 0.9\n","984 tensor(-0.0037, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6267447692441728 1.0\n","985 tensor(-0.0041, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6271180244749286 1.0\n","986 tensor(-0.0079, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6274909064504537 1.1\n","987 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6278634155440033 1.1\n","988 tensor(-0.0050, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6282355521284593 1.0\n","989 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6286073165763308 0.9\n","990 tensor(0.0071, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6289787092597545 0.7\n","991 tensor(-0.0067, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6293497305504947 0.8\n","992 tensor(-0.0096, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6297203808199442 0.8\n","993 tensor(-0.0092, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6300906604391243 0.5\n","994 tensor(-0.0063, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6304605697786851 0.4\n","995 tensor(-0.0102, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6308301092089065 0.4\n","996 tensor(-0.0056, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6311992790996976 0.2\n","997 tensor(-3.0511e-05, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6315680798205978 0.2\n","998 tensor(-0.0075, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.6319365117407773 0.5\n","999 tensor(-0.0061, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6323045752290365 0.5\n","1000 tensor(-0.0069, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6326722706538075 0.5\n","1001 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6330395983831536 0.4\n","1002 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6334065587847704 0.4\n","1003 tensor(-0.0017, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6337731522259857 0.4\n","1004 tensor(-0.0099, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6341393790737597 0.5\n","1005 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.634505239694686 0.5\n","1006 tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6348707344549913 0.6\n","1007 tensor(-0.0069, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6352358637205362 0.7\n","1008 tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6356006278568157 0.4\n","1009 tensor(-0.0079, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6359650272289589 0.4\n","1010 tensor(-0.0044, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6363290622017299 0.5\n","1011 tensor(-0.0036, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6366927331395282 0.5\n","1012 tensor(-0.0023, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6370560404063886 0.6\n","1013 tensor(-0.0094, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.6374189843659823 0.9\n","1014 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6377815653816163 0.8\n","1015 tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6381437838162347 0.8\n","1016 tensor(-0.0109, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6385056400324185 0.8\n","1017 tensor(-0.0068, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.638867134392386 0.7\n","1018 tensor(-0.0020, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6392282672579936 0.7\n","1019 tensor(0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6395890389907357 0.9\n","1020 tensor(-0.0116, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6399494499517449 0.8\n","1021 tensor(-0.0109, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6403095005017931 0.8\n","1022 tensor(-0.0006, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6406691910012914 0.7\n","1023 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.64102852181029 0.6\n","1024 tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6413874932884798 0.6\n","1025 tensor(-0.0035, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6417461057951912 0.8\n","1026 tensor(-0.0099, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.642104359689396 0.8\n","1027 tensor(-0.0064, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6424622553297066 0.8\n","1028 tensor(-0.0034, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6428197930743769 0.9\n","1029 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6431769732813025 0.7\n","1030 tensor(-0.0043, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6435337963080212 0.7\n","1031 tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6438902625117131 0.8\n","1032 tensor(-0.0024, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6442463722492014 0.8\n","1033 tensor(-0.0077, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6446021258769523 0.6\n","1034 tensor(-0.0023, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6449575237510753 0.5\n","1035 tensor(-0.0053, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6453125662273242 0.4\n","1036 tensor(-0.0039, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6456672536610968 0.4\n","1037 tensor(-0.0063, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6460215864074357 0.4\n","1038 tensor(-0.0096, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6463755648210283 0.3\n","1039 tensor(-0.0016, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6467291892562073 0.3\n","1040 tensor(-0.0067, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.647082460066951 0.3\n","1041 tensor(-0.0025, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6474353776068841 0.2\n","1042 tensor(-0.0045, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6477879422292772 0.4\n","1043 tensor(-0.0097, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.648140154287048 0.4\n","1044 tensor(-0.0108, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6484920141327608 0.5\n","1045 tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6488435221186282 0.4\n","1046 tensor(-0.0029, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6491946785965095 0.4\n","1047 tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6495454839179129 0.4\n","1048 tensor(-0.0094, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.6498959384339951 0.7\n","1049 tensor(-0.0027, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.650246042495561 0.8\n","1050 tensor(-0.0033, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6505957964530654 0.8\n","1051 tensor(-0.0080, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6509452006566123 0.9\n","1052 tensor(-0.0060, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6512942554559558 0.7\n","1053 tensor(-0.0049, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.6516429612004998 1.0\n","1054 tensor(-0.0050, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6519913182392993 0.9\n","1055 tensor(-0.0064, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.65233932692106 1.3\n","1056 tensor(-0.0042, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.652686987594139 1.2\n","1057 tensor(-0.0084, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6530343006065449 1.3\n","1058 tensor(-0.0056, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6533812663059383 1.0\n","1059 tensor(-0.0063, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6537278850396324 1.0\n","1060 tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6540741571545927 1.0\n","1061 tensor(-0.0045, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6544200829974381 1.0\n","1062 tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6547656629144407 1.0\n","1063 tensor(-0.0027, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6551108972515263 0.7\n","1064 tensor(-0.0032, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6554557863542747 0.8\n","1065 tensor(-0.0003, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6558003305679205 0.6\n","1066 tensor(-0.0117, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6561445302373525 0.7\n","1067 tensor(-0.0085, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6564883857071151 0.6\n","1068 tensor(-0.0055, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.656831897321408 0.8\n","1069 tensor(-0.0013, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6571750654240867 0.7\n","1070 tensor(-0.0077, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.6575178903586626 1.0\n","1071 tensor(-0.0069, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6578603724683039 1.0\n","1072 tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6582025120958357 1.0\n","1073 tensor(-0.0062, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6585443095837398 1.1\n","1074 tensor(-0.0020, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.658885765274156 1.0\n","1075 tensor(-0.0044, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6592268795088818 0.8\n","1076 tensor(-0.0070, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.659567652629373 0.7\n","1077 tensor(-0.0088, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6599080849767436 0.8\n","1078 tensor(-0.0092, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.660248176891767 0.7\n","1079 tensor(-0.0067, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6605879287148751 0.8\n","1080 tensor(-0.0045, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6609273407861602 0.7\n","1081 tensor(-0.0059, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6612664134453741 0.6\n","1082 tensor(-0.0010, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6616051470319287 0.6\n","1083 tensor(-0.0007, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6619435418848968 0.5\n","1084 tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.6622815983430119 0.8\n","1085 tensor(-0.0067, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6626193167446688 1.0\n","1086 tensor(-0.0073, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.6629566974279242 1.4\n","1087 tensor(-0.0040, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6632937407304962 1.3\n","1088 tensor(-0.0056, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6636304469897658 1.2\n","1089 tensor(-0.0069, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.663966816542776 1.1\n","1090 tensor(-0.0041, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6643028497262332 0.9\n","1091 tensor(-0.0089, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.664638546876507 0.9\n","1092 tensor(-0.0033, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.6649739083296304 1.4\n","1093 tensor(-0.0043, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6653089344213008 1.6\n","1094 tensor(-0.0067, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6656436254868796 1.5\n","1095 tensor(-0.0075, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6659779818613927 1.3\n","1096 tensor(-0.0028, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6663120038795313 0.9\n","1097 tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6666456918756518 1.0\n","1098 tensor(-0.0054, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6669790461837761 1.1\n","1099 tensor(-0.0018, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.6673120671375923 1.5\n","1100 tensor(-0.0059, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6676447550704547 1.5\n","1101 tensor(-0.0006, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6679771103153842 1.6\n","1102 tensor(-0.0061, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6683091332050688 1.3\n","1103 tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6686408240718638 1.2\n","1104 tensor(-0.0061, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.668972183247792 1.0\n","1105 tensor(-0.0033, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.669303211064544 1.3\n","1106 tensor(-0.0082, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6696339078534795 1.3\n","1107 tensor(-0.0045, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6699642739456261 1.2\n","1108 tensor(-0.0046, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6702943096716805 1.1\n","1109 tensor(-0.0065, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.6706240153620088 1.0\n","1110 tensor(-0.0083, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6709533913466468 1.0\n","1111 tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6712824379553002 0.9\n","1112 tensor(-0.0068, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6716111555173448 0.7\n","1113 tensor(-0.0038, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6719395443618275 0.7\n","1114 tensor(-0.0053, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6722676048174656 0.7\n","1115 tensor(-0.0074, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6725953372126482 0.4\n","1116 tensor(-0.0091, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6729227418754355 0.4\n","1117 tensor(-0.0020, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6732498191335601 0.4\n","1118 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6735765693144266 0.4\n","1119 tensor(-0.0079, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6739029927451121 0.1\n","1120 tensor(-0.0062, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6742290897523671 0.2\n","1121 tensor(-0.0060, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6745548606626146 0.2\n","1122 tensor(-0.0027, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.6748803058019521 0.8\n","1123 tensor(-0.0052, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6752054254961501 0.8\n","1124 tensor(-0.0109, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.675530220070654 1.3\n","1125 tensor(-0.0053, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6758546898505833 1.3\n","1126 tensor(-0.0048, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6761788351607327 1.3\n","1127 tensor(-0.0071, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.676502656325572 1.4\n","1128 tensor(-0.0041, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6768261536692464 1.5\n","1129 tensor(-0.0012, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6771493275155771 1.5\n","1130 tensor(-0.0045, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6774721781880616 1.4\n","1131 tensor(-0.0059, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6777947060098735 1.4\n","1132 tensor(-0.0047, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6781169113038636 0.8\n","1133 tensor(-0.0082, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6784387943925598 0.8\n","1134 tensor(-0.0060, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6787603555981672 0.3\n","1135 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6790815952425691 0.3\n","1136 tensor(-0.0092, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6794025136473265 0.4\n","1137 tensor(-0.0057, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6797231111336792 0.3\n","1138 tensor(-0.0078, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6800433880225455 0.2\n","1139 tensor(-0.0017, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.680363344634523 0.2\n","1140 tensor(-0.0049, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6806829812898885 0.3\n","1141 tensor(-0.0012, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6810022983085986 0.3\n","1142 tensor(-0.0052, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.68132129601029 0.4\n","1143 tensor(-0.0065, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6816399747142797 0.5\n","1144 tensor(-0.0045, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6819583347395655 0.5\n","1145 tensor(-0.0097, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6822763764048259 0.5\n","1146 tensor(-0.0061, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.682594100028421 0.7\n","1147 tensor(-0.0076, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6829115059283927 0.8\n","1148 tensor(-0.0055, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6832285944224643 0.9\n","1149 tensor(-0.0090, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6835453658280417 1.1\n","1150 tensor(-0.0017, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6838618204622138 1.1\n","1151 tensor(-0.0032, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6841779586417516 1.1\n","1152 tensor(-0.0071, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6844937806831097 1.2\n","1153 tensor(-0.0044, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.6848092869024267 1.3\n","1154 tensor(-0.0009, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6851244776155242 1.4\n","1155 tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6854393531379086 1.4\n","1156 tensor(-0.0088, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6857539137847708 1.2\n","1157 tensor(-0.0036, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6860681598709859 1.1\n","1158 tensor(-0.0088, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.686382091711115 1.0\n","1159 tensor(-0.0102, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6866957096194038 0.9\n","1160 tensor(-0.0061, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6870090139097844 0.8\n","1161 tensor(-0.0037, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6873220048958747 0.9\n","1162 tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.6876346828909788 1.0\n","1163 tensor(-0.0020, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6879470482080878 0.7\n","1164 tensor(-0.0025, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.6882591011598798 1.0\n","1165 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.68857084205872 1.0\n","1166 tensor(-0.0078, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6888822712166612 0.9\n","1167 tensor(-0.0056, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6891933889454446 0.9\n","1168 tensor(-0.0064, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.6895041955564991 1.4\n","1169 tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6898146913609426 1.3\n","1170 tensor(-0.0046, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6901248766695817 1.3\n","1171 tensor(-0.0109, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6904347517929121 1.3\n","1172 tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6907443170411192 1.0\n","1173 tensor(-0.0063, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6910535727240781 1.0\n","1174 tensor(-0.0066, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6913625191513539 0.6\n","1175 tensor(-0.0083, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6916711566322026 0.6\n","1176 tensor(-0.0011, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6919794854755703 0.6\n","1177 tensor(-0.0026, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6922875059900948 0.6\n","1178 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6925952184841047 0.2\n","1179 tensor(-0.0055, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6929026232656206 0.2\n","1180 tensor(-0.0083, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6932097206423551 0.2\n","1181 tensor(-0.0059, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6935165109217127 0.1\n","1182 tensor(-0.0024, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.693822994410791 0.1\n","1183 tensor(-0.0089, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6941291714163802 0.1\n","1184 tensor(-0.0008, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6944350422449639 0.2\n","1185 tensor(-0.0050, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6947406072027189 0.4\n","1186 tensor(-0.0055, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6950458665955161 0.4\n","1187 tensor(-0.0069, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6953508207289206 0.5\n","1188 tensor(-0.0001, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6956554699081917 0.5\n","1189 tensor(-0.0068, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6959598144382835 0.5\n","1190 tensor(-0.0090, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6962638546238453 0.5\n","1191 tensor(-0.0060, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6965675907692215 0.5\n","1192 tensor(0.0109, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.6968710231784522 0.7\n","1193 tensor(-0.0029, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6971741521552737 0.8\n","1194 tensor(-0.0046, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6974769780031185 0.8\n","1195 tensor(-0.0026, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6977795010251153 0.7\n","1196 tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6980817215240902 0.7\n","1197 tensor(-0.0066, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6983836398025662 0.7\n","1198 tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.6986852561627637 0.7\n","1199 tensor(-0.0020, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6989865709066008 0.7\n","1200 tensor(-0.0073, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.6992875843356943 1.0\n","1201 tensor(-0.0077, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6995882967513585 1.0\n","1202 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.6998887084546072 0.8\n","1203 tensor(-0.0056, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7001888197461525 0.8\n","1204 tensor(-0.0047, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7004886309264065 0.8\n","1205 tensor(-0.0078, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.70078814229548 1.0\n","1206 tensor(-0.0098, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7010873541531846 1.1\n","1207 tensor(-0.0076, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7013862667990314 1.1\n","1208 tensor(-0.0110, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7016848805322322 1.0\n","1209 tensor(-0.0090, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7019831956517 1.0\n","1210 tensor(-0.0035, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7022812124560484 1.1\n","1211 tensor(-0.0058, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7025789312435924 1.1\n","1212 tensor(-0.0086, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7028763523123487 1.1\n","1213 tensor(-0.0031, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7031734759600363 1.1\n","1214 tensor(-0.0118, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7034703024840763 1.2\n","1215 tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7037668321815922 1.1\n","1216 tensor(-0.0073, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7040630653494107 1.0\n","1217 tensor(-0.0086, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7043590022840612 1.0\n","1218 tensor(-0.0057, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7046546432817772 1.1\n","1219 tensor(-0.0022, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7049499886384953 1.2\n","1220 tensor(-0.0114, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.7052450386498569 1.5\n","1221 tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.705539793611207 1.5\n","1222 tensor(-0.0026, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7058342538175958 1.8\n","1223 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7061284195637783 1.7\n","1224 tensor(-0.0011, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7064222911442144 1.5\n","1225 tensor(-0.0002, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7067158688530701 1.5\n","1226 tensor(-0.0052, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7070091529842171 1.5\n","1227 tensor(-0.0027, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7073021438312329 1.4\n","1228 tensor(-0.0098, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7075948416874016 1.5\n","1229 tensor(-0.0022, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7078872468457142 1.4\n","1230 tensor(-0.0083, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7081793595988686 0.8\n","1231 tensor(-0.0017, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7084711802392696 1.0\n","1232 tensor(-0.0044, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7087627090590304 0.8\n","1233 tensor(-0.0032, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7090539463499714 0.8\n","1234 tensor(-0.0036, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7093448924036214 1.2\n","1235 tensor(-0.0043, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7096355475112178 1.0\n","1236 tensor(-0.0024, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7099259119637066 1.0\n","1237 tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7102159860517429 1.1\n","1238 tensor(-0.0093, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7105057700656912 0.9\n","1239 tensor(-0.0044, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7107952642956255 1.0\n","1240 tensor(-0.0120, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7110844690313298 1.0\n","1241 tensor(-0.0025, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7113733845622985 0.8\n","1242 tensor(-0.0060, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7116620111777361 0.7\n","1243 tensor(-0.0019, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.7119503491665584 1.3\n","1244 tensor(-4.8219e-05, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7122383988173919 0.9\n","1245 tensor(-0.0043, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7125261604185744 1.1\n","1246 tensor(-0.0013, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7128136342581559 1.5\n","1247 tensor(-0.0093, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7131008206238978 1.4\n","1248 tensor(-0.0053, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7133877198032739 1.4\n","1249 tensor(-0.0061, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7136743320834705 1.3\n","1250 tensor(-2.9651e-05, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7139606577513871 1.4\n","1251 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7142466970936356 1.7\n","1252 tensor(-0.0011, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.714532450396542 1.9\n","1253 tensor(-0.0058, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7148179179461456 1.3\n","1254 tensor(-0.0060, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7151031000281993 1.3\n","1255 tensor(-0.0009, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7153879969281711 1.2\n","1256 tensor(-0.0043, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7156726089312431 1.0\n","1257 tensor(-0.0062, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7159569363223117 1.0\n","1258 tensor(-0.0080, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7162409793859894 1.1\n","1259 tensor(-0.0027, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7165247384066035 1.2\n","1260 tensor(-0.0073, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7168082136681968 1.1\n","1261 tensor(-0.0118, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7170914054545287 1.0\n","1262 tensor(-0.0016, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7173743140490741 0.8\n","1263 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7176569397350251 0.8\n","1264 tensor(-0.0056, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7179392827952901 0.9\n","1265 tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.7182213435124948 1.4\n","1266 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7185031221689823 1.3\n","1267 tensor(-0.0088, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7187846190468132 1.4\n","1268 tensor(-0.0084, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7190658344277665 1.4\n","1269 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7193467685933387 1.4\n","1270 tensor(-0.0076, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7196274218247454 1.3\n","1271 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7199077944029206 1.4\n","1272 tensor(-0.0108, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7201878866085176 1.5\n","1273 tensor(-0.0098, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7204676987219092 1.8\n","1274 tensor(-0.0116, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7207472310231873 1.7\n","1275 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.721026483792164 1.2\n","1276 tensor(-0.0120, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7213054573083719 1.1\n","1277 tensor(-0.0102, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7215841518510635 1.4\n","1278 tensor(-0.0142, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7218625676992125 1.6\n","1279 tensor(-0.0013, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7221407051315132 1.5\n","1280 tensor(-0.0011, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7224185644263817 1.5\n","1281 tensor(-0.0123, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7226961458619554 1.2\n","1282 tensor(-0.0076, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7229734497160933 1.1\n","1283 tensor(-0.0042, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7232504762663773 1.0\n","1284 tensor(-0.0093, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7235272257901109 1.0\n","1285 tensor(-0.0049, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7238036985643208 0.9\n","1286 tensor(-0.0115, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7240798948657565 0.9\n","1287 tensor(-0.0064, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7243558149708906 0.6\n","1288 tensor(-0.0117, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7246314591559198 0.4\n","1289 tensor(-0.0070, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7249068276967638 0.4\n","1290 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7251819208690671 0.4\n","1291 tensor(-0.0116, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7254567389481981 0.5\n","1292 tensor(-0.0129, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7257312822092499 0.5\n","1293 tensor(-0.0141, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7260055509270407 0.3\n","1294 tensor(-0.0084, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7262795453761135 0.7\n","1295 tensor(-0.0099, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7265532658307374 1.0\n","1296 tensor(-0.0063, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7268267125649066 1.1\n","1297 tensor(-0.0079, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7270998858523418 1.0\n","1298 tensor(-0.0092, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7273727859664894 0.9\n","1299 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.727645413180523 1.1\n","1300 tensor(-0.0061, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7279177677673424 1.1\n","1301 tensor(-0.0090, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7281898499995751 1.0\n","1302 tensor(-0.0176, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7284616601495755 1.0\n","1303 tensor(-0.0057, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.728733198489426 1.3\n","1304 tensor(-0.0147, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7290044652909365 1.0\n","1305 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7292754608256455 0.8\n","1306 tensor(-0.0146, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.72954618536482 0.9\n","1307 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7298166391794552 1.1\n","1308 tensor(-0.0137, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7300868225402757 1.1\n","1309 tensor(-0.0092, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7303567357177354 1.2\n","1310 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7306263789820177 1.2\n","1311 tensor(-0.0111, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.7308957526030356 1.7\n","1312 tensor(-0.0109, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7311648568504325 1.8\n","1313 tensor(-0.0125, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7314336919935822 1.6\n","1314 tensor(-0.0050, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7317022583015886 1.5\n","1315 tensor(-0.0115, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.731970556043287 1.4\n","1316 tensor(-0.0087, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7322385854872437 1.5\n","1317 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7325063469017564 1.4\n","1318 tensor(-0.0106, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7327738405548547 1.7\n","1319 tensor(-0.0065, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7330410667142998 1.5\n","1320 tensor(-0.0054, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7333080256475855 1.5\n","1321 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7335747176219379 1.0\n","1322 tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.733841142904316 0.9\n","1323 tensor(-0.0138, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7341073017614117 1.2\n","1324 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7343731944596503 1.2\n","1325 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7346388212651906 1.3\n","1326 tensor(-0.0075, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7349041824439255 1.1\n","1327 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7351692782614816 1.0\n","1328 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.73543410898322 0.9\n","1329 tensor(-0.0055, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7356986748742368 0.9\n","1330 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7359629761993626 0.9\n","1331 tensor(-0.0094, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7362270132231632 1.0\n","1332 tensor(-0.0094, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.73649078620994 1.3\n","1333 tensor(-0.0032, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.73675429542373 0.9\n","1334 tensor(-0.0142, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7370175411283063 0.9\n","1335 tensor(-0.0079, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.737280523587178 0.8\n","1336 tensor(-0.0057, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7375432430635909 0.7\n","1337 tensor(-0.0104, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7378056998205272 0.7\n","1338 tensor(-0.0092, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7380678941207067 0.6\n","1339 tensor(-0.0167, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.738329826226586 0.9\n","1340 tensor(-0.0080, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7385914964003595 0.9\n","1341 tensor(-0.0069, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.738852904903959 1.1\n","1342 tensor(-0.0098, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7391140519990551 1.0\n","1343 tensor(-0.0134, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.739374937947056 1.0\n","1344 tensor(-0.0035, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7396355630091089 1.1\n","1345 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7398959274460999 1.1\n","1346 tensor(-0.0163, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7401560315186537 1.2\n","1347 tensor(-0.0136, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7404158754871351 1.2\n","1348 tensor(-0.0134, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.740675459611648 1.1\n","1349 tensor(-0.0025, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7409347841520364 1.0\n","1350 tensor(-0.0068, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7411938493678842 1.0\n","1351 tensor(-0.0158, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7414526555185164 0.7\n","1352 tensor(-0.0086, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.741711202862998 0.5\n","1353 tensor(-0.0083, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7419694916601349 0.5\n","1354 tensor(-0.0085, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7422275221684749 0.4\n","1355 tensor(-0.0076, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7424852946463063 0.7\n","1356 tensor(-0.0093, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.74274280935166 0.8\n","1357 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7430000665423084 0.8\n","1358 tensor(-0.0120, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7432570664757661 0.8\n","1359 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7435138094092903 0.5\n","1360 tensor(-0.0058, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7437702955998811 0.5\n","1361 tensor(-0.0167, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7440265253042811 0.5\n","1362 tensor(-0.0077, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.7442824987789769 1.2\n","1363 tensor(-0.0109, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.7445382162801979 1.8\n","1364 tensor(-0.0118, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7447936780639177 1.9\n","1365 tensor(-0.0109, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.7450488843858538 2.4\n","1366 tensor(-0.0053, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7453038355014678 2.3\n","1367 tensor(-0.0075, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7455585316659664 2.3\n","1368 tensor(-0.0060, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7458129731343004 2.4\n","1369 tensor(-0.0054, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7460671601611661 2.4\n","1370 tensor(-0.0092, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7463210930010049 2.4\n","1371 tensor(-0.0025, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.746574771908004 2.4\n","1372 tensor(-0.0097, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7468281971360959 2.0\n","1373 tensor(-0.0004, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7470813689389599 1.6\n","1374 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7473342875700208 1.6\n","1375 tensor(-0.0097, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7475869532824508 1.1\n","1376 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7478393663291685 1.2\n","1377 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7480915269628392 1.3\n","1378 tensor(-0.0090, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7483434354358764 1.3\n","1379 tensor(-0.0117, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7485950920004405 1.4\n","1380 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7488464969084401 1.5\n","1381 tensor(-0.0058, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7490976504115316 1.5\n","1382 tensor(-0.0091, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7493485527611201 1.2\n","1383 tensor(-0.0054, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.749599204208359 1.0\n","1384 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7498496050041508 0.9\n","1385 tensor(-0.0057, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7500997553991465 0.6\n","1386 tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7503496556437474 0.4\n","1387 tensor(-0.0022, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7505993059881036 0.4\n","1388 tensor(-0.0137, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7508487066821156 0.5\n","1389 tensor(-0.0075, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7510978579754335 0.5\n","1390 tensor(-0.0071, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7513467601174579 0.4\n","1391 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7515954133573406 0.5\n","1392 tensor(-0.0024, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7518438179439833 0.9\n","1393 tensor(-0.0081, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7520919741260392 0.9\n","1394 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.7523398821519132 1.4\n","1395 tensor(-0.0118, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7525875422697612 1.5\n","1396 tensor(-0.0116, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7528349547274915 1.6\n","1397 tensor(-0.0175, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.753082119772764 1.6\n","1398 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7533290376529912 1.5\n","1399 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7535757086153383 1.5\n","1400 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.753822132906723 1.5\n","1401 tensor(-0.0051, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7540683107738162 1.7\n","1402 tensor(-0.0112, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7543142424630424 1.3\n","1403 tensor(-0.0006, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7545599282205793 1.3\n","1404 tensor(-0.0116, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7548053682923588 0.8\n","1405 tensor(-0.0097, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7550505629240664 0.7\n","1406 tensor(-0.0034, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.7552955123611422 1.2\n","1407 tensor(-0.0036, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7555402168487811 1.2\n","1408 tensor(-0.0064, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7557846766319324 1.1\n","1409 tensor(-0.0123, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7560288919553004 1.1\n","1410 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7562728630633451 1.1\n","1411 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7565165902002817 1.0\n","1412 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7567600736100815 1.0\n","1413 tensor(-0.0098, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.7570033135364714 1.6\n","1414 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.757246310222935 1.7\n","1415 tensor(-0.0153, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.757489063912712 1.7\n","1416 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7577315748487993 1.1\n","1417 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7579738432739505 1.3\n","1418 tensor(-0.0120, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7582158694306765 1.3\n","1419 tensor(-0.0170, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7584576535612458 1.2\n","1420 tensor(-0.0162, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7586991959076846 1.2\n","1421 tensor(-0.0075, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.758940496711777 1.0\n","1422 tensor(-0.0120, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7591815562150652 1.1\n","1423 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7594223746588501 0.9\n","1424 tensor(-0.0205, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7596629522841912 1.0\n","1425 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7599032893319071 1.3\n","1426 tensor(-0.0178, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7601433860425751 1.3\n","1427 tensor(-0.0116, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7603832426565326 1.1\n","1428 tensor(-0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7606228594138761 1.5\n","1429 tensor(-0.0182, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7608622365544622 1.6\n","1430 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7611013743179077 1.9\n","1431 tensor(-0.0133, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7613402729435899 2.0\n","1432 tensor(-0.0214, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7615789326706462 2.2\n","1433 tensor(-0.0205, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7618173537379755 2.1\n","1434 tensor(-0.0156, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7620555363842376 1.9\n","1435 tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7622934808478534 1.7\n","1436 tensor(-0.0032, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7625311873670055 1.8\n","1437 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7627686561796385 1.7\n","1438 tensor(-0.0145, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7630058875234589 1.3\n","1439 tensor(-0.0071, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7632428816359355 1.2\n","1440 tensor(-0.0189, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7634796387542995 0.9\n","1441 tensor(-0.0129, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7637161591155452 0.8\n","1442 tensor(-0.0144, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7639524429564296 0.6\n","1443 tensor(-0.0170, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7641884905134733 0.6\n","1444 tensor(-0.0177, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7644243020229597 0.6\n","1445 tensor(-0.0164, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7646598777209368 0.6\n","1446 tensor(-0.0086, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.7648952178432159 1.1\n","1447 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7651303226253727 1.2\n","1448 tensor(-0.0082, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7653651923027474 1.2\n","1449 tensor(-0.0114, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7655998271104445 1.2\n","1450 tensor(-0.0146, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7658342272833341 1.3\n","1451 tensor(-0.0166, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7660683930560508 1.3\n","1452 tensor(-0.0117, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7663023246629947 1.3\n","1453 tensor(-0.0083, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7665360223383317 1.0\n","1454 tensor(-0.0116, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7667694863159934 1.2\n","1455 tensor(-0.0144, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7670027168296775 1.2\n","1456 tensor(-0.0171, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7672357141128477 0.6\n","1457 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7674684783987349 0.6\n","1458 tensor(-0.0168, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7677010099203362 0.7\n","1459 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.7679333089104159 1.5\n","1460 tensor(-0.0056, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7681653756015054 1.4\n","1461 tensor(-0.0153, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7683972102259039 1.5\n","1462 tensor(-0.0114, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.768628813015678 1.5\n","1463 tensor(-0.0181, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7688601842026623 1.6\n","1464 tensor(-0.0196, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7690913240184597 1.4\n","1465 tensor(-0.0160, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7693222326944412 1.3\n","1466 tensor(-0.0179, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7695529104617468 1.3\n","1467 tensor(-0.0155, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7697833575512851 1.3\n","1468 tensor(-0.0065, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.7700135741937337 1.7\n","1469 tensor(-0.0167, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.77024356061954 1.4\n","1470 tensor(-0.0169, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7704733170589205 1.4\n","1471 tensor(-0.0180, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7707028437418616 1.5\n","1472 tensor(-0.0155, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7709321408981197 1.5\n","1473 tensor(-0.0171, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7711612087572216 1.4\n","1474 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7713900475484643 1.7\n","1475 tensor(-0.0157, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7716186575009158 1.7\n","1476 tensor(-0.0114, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.771847038843415 1.8\n","1477 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7720751918045715 1.7\n","1478 tensor(-0.0182, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.772303116612767 1.4\n","1479 tensor(-0.0187, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7725308134961542 0.9\n","1480 tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.772758282682658 1.1\n","1481 tensor(-0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7729855243999754 1.3\n","1482 tensor(-0.0201, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7732125388755754 1.4\n","1483 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7734393263366999 1.6\n","1484 tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7736658870103631 1.4\n","1485 tensor(-0.0115, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7738922211233528 1.4\n","1486 tensor(-0.0206, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7741183289022294 1.3\n","1487 tensor(-0.0174, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7743442105733271 1.3\n","1488 tensor(-0.0182, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7745698663627538 1.1\n","1489 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7747952964963911 1.2\n","1490 tensor(-0.0163, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7750205011998947 1.0\n","1491 tensor(-0.0147, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7752454806986948 0.7\n","1492 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7754702352179961 0.8\n","1493 tensor(-0.0118, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7756947649827781 0.7\n","1494 tensor(-0.0186, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7759190702177954 1.0\n","1495 tensor(-0.0212, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.7761431511475776 1.7\n","1496 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.77636700799643 1.7\n","1497 tensor(-0.0181, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7765906409884336 1.9\n","1498 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7768140503474452 2.1\n","1499 tensor(-0.0156, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7770372362970978 2.0\n","1500 tensor(-0.0176, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7772601990608006 2.0\n","1501 tensor(-0.0136, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7774829388617398 2.2\n","1502 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7777054559228781 2.0\n","1503 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7779277504669553 1.9\n","1504 tensor(-0.0224, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7781498227164882 1.5\n","1505 tensor(-0.0194, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7783716728937717 1.0\n","1506 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.778593301220878 1.0\n","1507 tensor(-0.0158, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7788147079196571 0.8\n","1508 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7790358932117375 0.6\n","1509 tensor(-0.0196, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7792568573185258 1.0\n","1510 tensor(-0.0184, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.7794776004612072 1.5\n","1511 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.779698122860746 1.3\n","1512 tensor(-0.0111, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7799184247378853 1.4\n","1513 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7801385063131474 1.4\n","1514 tensor(-0.0129, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7803583678068342 1.4\n","1515 tensor(-0.0156, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7805780094390274 1.5\n","1516 tensor(-0.0068, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7807974314295885 1.5\n","1517 tensor(-0.0183, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7810166339981588 1.5\n","1518 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7812356173641607 1.7\n","1519 tensor(-0.0153, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7814543817467965 1.3\n","1520 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7816729273650498 0.8\n","1521 tensor(-0.0199, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7818912544376847 0.7\n","1522 tensor(-0.0175, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.782109363183247 0.5\n","1523 tensor(-0.0061, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7823272538200637 0.5\n","1524 tensor(-0.0210, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.7825449265662436 1.0\n","1525 tensor(-0.0086, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7827623816396775 0.7\n","1526 tensor(-0.0185, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7829796192580378 0.9\n","1527 tensor(-0.0160, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7831966396387797 0.9\n","1528 tensor(-0.0079, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.783413442999141 0.7\n","1529 tensor(-0.0166, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7836300295561418 0.9\n","1530 tensor(-0.0116, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.7838463995265856 1.4\n","1531 tensor(-0.0155, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7840625531270591 1.4\n","1532 tensor(-0.0075, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7842784905739321 1.4\n","1533 tensor(-0.0153, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7844942120833581 1.7\n","1534 tensor(-0.0165, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7847097178712747 1.2\n","1535 tensor(-0.0110, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7849250081534035 1.6\n","1536 tensor(-0.0163, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7851400831452501 1.6\n","1537 tensor(-0.0176, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7853549430621047 1.8\n","1538 tensor(-0.0090, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7855695881190426 2.0\n","1539 tensor(-0.0098, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7857840185309236 1.9\n","1540 tensor(-0.0182, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7859982345123927 1.6\n","1541 tensor(-0.0170, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7862122362778803 1.7\n","1542 tensor(-0.0180, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7864260240416024 1.7\n","1543 tensor(-0.0165, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7866395980175609 1.4\n","1544 tensor(-0.0220, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7868529584195433 1.4\n","1545 tensor(-0.0160, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7870661054611238 1.2\n","1546 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7872790393556626 1.1\n","1547 tensor(-0.0180, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.787491760316307 1.0\n","1548 tensor(-0.0179, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7877042685559906 1.1\n","1549 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7879165642874346 1.0\n","1550 tensor(-0.0096, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7881286477231473 1.2\n","1551 tensor(-0.0145, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7883405190754241 1.2\n","1552 tensor(-0.0180, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7885521785563487 1.6\n","1553 tensor(-0.0148, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7887636263777923 1.7\n","1554 tensor(-0.0218, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7889748627514146 1.8\n","1555 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7891858878886631 1.8\n","1556 tensor(-0.0074, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7893967020007744 1.7\n","1557 tensor(-0.0125, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7896073052987737 1.9\n","1558 tensor(-0.0176, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7898176979934749 1.9\n","1559 tensor(-0.0136, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.7900278802954814 2.2\n","1560 tensor(-0.0156, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.790237852415186 2.0\n","1561 tensor(-0.0173, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.7904476145627708 2.8\n","1562 tensor(-0.0137, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.790657166948208 2.8\n","1563 tensor(-0.0200, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.7908665097812597 3.3\n","1564 tensor(-0.0115, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7910756432714785 3.2\n","1565 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.791284567628207 3.2\n","1566 tensor(-0.0195, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7914932830605789 3.2\n","1567 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7917017897775183 2.9\n","1568 tensor(-0.0132, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7919100879877408 2.6\n","1569 tensor(-0.0077, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.792118177899753 2.4\n","1570 tensor(-0.0164, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7923260597218532 2.3\n","1571 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.7925337336621314 1.6\n","1572 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7927411999284693 1.3\n","1573 tensor(-0.0167, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7929484587285408 0.7\n","1574 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7931555102698122 0.8\n","1575 tensor(-0.0163, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7933623547595424 0.7\n","1576 tensor(-0.0165, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7935689924047828 0.7\n","1577 tensor(-0.0032, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7937754234123781 0.7\n","1578 tensor(-0.0142, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7939816479889656 0.8\n","1579 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7941876663409767 0.7\n","1580 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7943934786746357 0.6\n","1581 tensor(-0.0196, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7945990851959611 0.5\n","1582 tensor(-0.0168, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7948044861107652 0.4\n","1583 tensor(-0.0180, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7950096816246544 0.5\n","1584 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.7952146719430297 0.8\n","1585 tensor(-0.0199, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7954194572710866 0.8\n","1586 tensor(-0.0133, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7956240378138156 0.8\n","1587 tensor(-0.0171, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7958284137760018 0.8\n","1588 tensor(-0.0115, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7960325853622258 0.7\n","1589 tensor(-0.0183, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.7962365527768636 1.2\n","1590 tensor(-0.0162, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7964403162240867 1.2\n","1591 tensor(-0.0142, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7966438759078627 1.1\n","1592 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7968472320319547 1.1\n","1593 tensor(-0.0178, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7970503847999229 1.0\n","1594 tensor(-0.0162, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7972533344151229 0.6\n","1595 tensor(-0.0160, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7974560810807078 0.5\n","1596 tensor(-0.0199, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.797658624999627 0.6\n","1597 tensor(-0.0146, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7978609663746274 0.6\n","1598 tensor(-0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7980631054082528 0.6\n","1599 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7982650423028446 0.2\n","1600 tensor(-0.0114, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7984667772605417 0.2\n","1601 tensor(-0.0170, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7986683104832811 0.2\n","1602 tensor(-0.0134, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7988696421727979 0.3\n","1603 tensor(-0.0182, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7990707725306251 0.3\n","1604 tensor(-0.0158, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7992717017580945 0.4\n","1605 tensor(-0.0168, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.7994724300563364 0.4\n","1606 tensor(-0.0198, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.79967295762628 0.4\n","1607 tensor(-0.0151, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.7998732846686537 0.5\n","1608 tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8000734113839851 0.7\n","1609 tensor(-0.0165, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.800273337972601 0.7\n","1610 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8004730646346285 0.8\n","1611 tensor(-0.0162, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8006725915699938 1.2\n","1612 tensor(-0.0179, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8008719189784239 1.1\n","1613 tensor(-0.0144, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8010710470594454 1.3\n","1614 tensor(-0.0165, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.801269976012386 1.4\n","1615 tensor(-0.0114, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8014687060363737 1.5\n","1616 tensor(-0.0176, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8016672373303373 1.4\n","1617 tensor(-0.0166, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8018655700930069 1.4\n","1618 tensor(-0.0045, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8020637045229139 1.2\n","1619 tensor(-0.0153, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.802261640818391 1.2\n","1620 tensor(-0.0116, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8024593791775726 1.3\n","1621 tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.802656919798395 1.0\n","1622 tensor(-0.0166, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8028542628785966 1.0\n","1623 tensor(-0.0142, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.803051408615718 0.8\n","1624 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8032483572071023 0.7\n","1625 tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8034451088498952 0.8\n","1626 tensor(-0.0155, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8036416637410453 1.0\n","1627 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8038380220773043 1.2\n","1628 tensor(-0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.804034184055227 1.2\n","1629 tensor(-0.0177, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8042301498711717 1.2\n","1630 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8044259197213006 1.0\n","1631 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8046214938015792 1.0\n","1632 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8048168723077777 1.1\n","1633 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8050120554354699 1.3\n","1634 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8052070433800345 1.2\n","1635 tensor(-0.0171, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8054018363366544 1.1\n","1636 tensor(-0.0166, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8055964345003177 0.9\n","1637 tensor(-0.0206, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8057908380658174 0.8\n","1638 tensor(-0.0213, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8059850472277517 1.0\n","1639 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8061790621805238 0.9\n","1640 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8063728831183433 1.0\n","1641 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.806566510235225 0.9\n","1642 tensor(-0.0132, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.8067599437249897 1.3\n","1643 tensor(-0.0108, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8069531837812648 1.4\n","1644 tensor(-0.0106, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8071462305974835 1.7\n","1645 tensor(-0.0134, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8073390843668861 1.7\n","1646 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8075317452825191 1.8\n","1647 tensor(-0.0133, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8077242135372367 1.7\n","1648 tensor(-0.0176, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8079164893236994 1.5\n","1649 tensor(-0.0195, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8081085728343756 1.5\n","1650 tensor(-0.0157, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8083004642615413 1.4\n","1651 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8084921637972797 1.4\n","1652 tensor(-0.0171, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8086836716334825 0.9\n","1653 tensor(-0.0198, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8088749879618491 0.6\n","1654 tensor(-0.0111, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8090661129738872 0.5\n","1655 tensor(-0.0201, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8092570468609133 0.5\n","1656 tensor(-0.0078, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8094477898140524 0.7\n","1657 tensor(-0.0156, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8096383420242383 0.6\n","1658 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.809828703682214 0.6\n","1659 tensor(-0.0129, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8100188749785319 0.7\n","1660 tensor(-0.0193, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8102088561035534 0.8\n","1661 tensor(-0.0146, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8103986472474498 1.1\n","1662 tensor(-0.0188, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8105882486002024 1.2\n","1663 tensor(-0.0178, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8107776603516021 1.3\n","1664 tensor(-0.0157, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8109668826912506 1.2\n","1665 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8111559158085593 1.2\n","1666 tensor(-0.0184, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8113447598927508 1.1\n","1667 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.811533415132858 1.7\n","1668 tensor(-0.0153, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8117218817177252 1.8\n","1669 tensor(-0.0165, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8119101598360075 1.9\n","1670 tensor(-0.0137, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.8120982496761715 2.5\n","1671 tensor(-0.0187, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8122861514264953 2.2\n","1672 tensor(-0.0223, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8124738652750688 2.1\n","1673 tensor(-0.0108, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8126613914097938 2.1\n","1674 tensor(-0.0148, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.812848730018384 2.0\n","1675 tensor(-0.0219, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8130358812883656 2.0\n","1676 tensor(-0.0134, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8132228454070771 1.8\n","1677 tensor(-0.0180, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.81340962256167 1.2\n","1678 tensor(-0.0178, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8135962129391084 1.2\n","1679 tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8137826167261693 1.0\n","1680 tensor(-0.0055, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8139688341094431 0.3\n","1681 tensor(-0.0158, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8141548652753337 0.3\n","1682 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8143407104100584 0.4\n","1683 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8145263696996483 0.3\n","1684 tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8147118433299486 0.3\n","1685 tensor(-0.0179, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8148971314866187 0.2\n","1686 tensor(-0.0122, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.815082234355132 0.3\n","1687 tensor(-0.0099, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8152671521207769 0.3\n","1688 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8154518849686562 0.4\n","1689 tensor(-0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8156364330836875 0.5\n","1690 tensor(-0.0109, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8158207966506038 0.9\n","1691 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8160049758539533 0.9\n","1692 tensor(-0.0134, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8161889708780993 0.9\n","1693 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8163727819072212 1.1\n","1694 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8165564091253139 1.2\n","1695 tensor(-0.0174, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8167398527161887 1.4\n","1696 tensor(-0.0083, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8169231128634724 1.6\n","1697 tensor(-0.0171, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.817106189750609 1.7\n","1698 tensor(-0.0122, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.8172890835608584 2.3\n","1699 tensor(-0.0207, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8174717944772976 2.2\n","1700 tensor(-0.0120, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8176543226828202 2.2\n","1701 tensor(-0.0137, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8178366683601375 2.3\n","1702 tensor(-0.0142, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8180188316917772 2.4\n","1703 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8182008128600855 2.3\n","1704 tensor(-0.0136, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8183826120472254 2.6\n","1705 tensor(-0.0210, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8185642294351783 2.4\n","1706 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.818745665205743 2.4\n","1707 tensor(-0.0175, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8189269195405373 2.4\n","1708 tensor(-0.0094, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8191079926209968 2.0\n","1709 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8192888846283758 2.0\n","1710 tensor(-0.0157, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8194695957437474 1.6\n","1711 tensor(-0.0132, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8196501261480036 1.5\n","1712 tensor(-0.0164, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8198304760218557 1.4\n","1713 tensor(-0.0172, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8200106455458338 1.3\n","1714 tensor(-0.0117, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.820190634900288 0.9\n","1715 tensor(-0.0125, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8203704442653876 0.9\n","1716 tensor(-0.0081, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8205500738211222 0.6\n","1717 tensor(-0.0195, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8207295237473011 0.6\n","1718 tensor(-0.0134, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8209087942235538 0.3\n","1719 tensor(-0.0138, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8210878854293303 0.4\n","1720 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.821266797543901 0.8\n","1721 tensor(-0.0145, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8214455307463571 0.8\n","1722 tensor(-0.0160, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.8216240852156107 1.2\n","1723 tensor(-0.0178, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8218024611303951 1.6\n","1724 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8219806586692646 1.8\n","1725 tensor(-0.0181, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8221586780105954 1.8\n","1726 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8223365193325848 1.9\n","1727 tensor(-0.0189, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8225141828132523 2.0\n","1728 tensor(-0.0148, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.822691668630439 1.9\n","1729 tensor(-0.0086, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8228689769618085 1.8\n","1730 tensor(-0.0204, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8230461079848467 1.6\n","1731 tensor(-0.0169, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8232230618768619 1.6\n","1732 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.823399838814985 1.1\n","1733 tensor(-0.0106, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.82357643897617 0.7\n","1734 tensor(-0.0111, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8237528625371938 0.7\n","1735 tensor(-0.0136, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8239291096746566 0.7\n","1736 tensor(-0.0199, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8241051805649819 0.6\n","1737 tensor(-0.0173, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.824281075384417 0.5\n","1738 tensor(-0.0114, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8244567943090326 0.5\n","1739 tensor(-0.0151, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8246323375147235 0.6\n","1740 tensor(-0.0181, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8248077051772088 0.5\n","1741 tensor(-0.0129, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8249828974720317 0.6\n","1742 tensor(-0.0168, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8251579145745596 0.8\n","1743 tensor(-0.0184, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8253327566599851 0.8\n","1744 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8255074239033251 0.7\n","1745 tensor(-0.0024, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8256819164794217 0.9\n","1746 tensor(-0.0078, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8258562345629423 1.0\n","1747 tensor(-0.0109, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8260303783283793 0.9\n","1748 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8262043479500509 1.0\n","1749 tensor(-0.0156, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8263781436021009 1.3\n","1750 tensor(-0.0163, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8265517654584988 1.2\n","1751 tensor(-0.0158, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8267252136930403 1.2\n","1752 tensor(-0.0173, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.8268984884793473 1.6\n","1753 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8270715899908679 1.6\n","1754 tensor(-0.0156, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8272445184008771 1.5\n","1755 tensor(-0.0201, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8274172738824762 1.6\n","1756 tensor(-0.0183, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8275898566085937 1.5\n","1757 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.827762266751985 1.7\n","1758 tensor(-0.0051, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8279345044852331 1.6\n","1759 tensor(-0.0118, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8281065699807479 1.2\n","1760 tensor(-0.0145, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8282784634107672 1.2\n","1761 tensor(-0.0077, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8284501849473563 1.1\n","1762 tensor(-0.0120, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.828621734762409 0.5\n","1763 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8287931130276466 0.6\n","1764 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8289643199146189 0.6\n","1765 tensor(-0.0182, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8291353555947043 0.6\n","1766 tensor(-0.0178, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8293062202391097 0.6\n","1767 tensor(-0.0083, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8294769140188706 0.4\n","1768 tensor(-0.0177, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.8296474371048517 1.1\n","1769 tensor(-0.0133, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8298177896677468 1.1\n","1770 tensor(-0.0163, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.829987971878079 1.7\n","1771 tensor(-0.0132, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.830157983906201 1.8\n","1772 tensor(-0.0123, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8303278259222948 1.8\n","1773 tensor(-0.0188, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8304974980963725 1.8\n","1774 tensor(-0.0142, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8306670005982761 2.1\n","1775 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.8308363335976778 2.4\n","1776 tensor(-0.0098, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.8310054972640801 3.4\n","1777 tensor(-0.0156, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.831174491766816 3.4\n","1778 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8313433172750493 2.7\n","1779 tensor(-0.0170, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8315119739577742 2.8\n","1780 tensor(-0.0169, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8316804619838164 2.5\n","1781 tensor(-0.0202, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8318487815218326 2.5\n","1782 tensor(-0.0200, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.8320169327403107 3.1\n","1783 tensor(-0.0077, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8321849158075705 3.0\n","1784 tensor(-0.0106, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8323527308917629 2.7\n","1785 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8325203781608711 2.2\n","1786 tensor(-0.0118, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8326878577827103 1.6\n","1787 tensor(-0.0137, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8328551699249276 1.6\n","1788 tensor(-0.0164, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8330223147550027 1.6\n","1789 tensor(-0.0104, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.8331892924402475 2.3\n","1790 tensor(-0.0080, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8333561031478074 2.1\n","1791 tensor(-0.0162, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8335227470446596 2.0\n","1792 tensor(-0.0158, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8336892242976148 1.7\n","1793 tensor(-0.0110, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8338555350733172 1.7\n","1794 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.834021679538244 1.8\n","1795 tensor(-0.0048, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8341876578587057 1.7\n","1796 tensor(-0.0176, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.834353470200847 1.4\n","1797 tensor(-0.0122, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8345191167306462 1.5\n","1798 tensor(-0.0199, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8346845976139154 1.7\n","1799 tensor(-0.0201, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8348499130163016 0.9\n","1800 tensor(-0.0163, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8350150631032853 1.2\n","1801 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.835180048040182 1.3\n","1802 tensor(-0.0189, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8353448679921418 1.1\n","1803 tensor(-0.0106, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8355095231241497 1.1\n","1804 tensor(-0.0115, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8356740136010256 1.2\n","1805 tensor(-0.0163, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8358383395874245 1.2\n","1806 tensor(-0.0043, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8360025012478371 1.1\n","1807 tensor(-0.0145, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8361664987465893 1.1\n","1808 tensor(-0.0049, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.8363303322478427 1.5\n","1809 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8364940019155949 1.5\n","1810 tensor(-0.0173, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8366575079136792 1.2\n","1811 tensor(-0.0136, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8368208504057656 1.1\n","1812 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8369840295553598 1.1\n","1813 tensor(-0.0048, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8371470455258044 1.2\n","1814 tensor(-0.0151, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8373098984802786 1.1\n","1815 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8374725885817984 1.1\n","1816 tensor(-0.0100, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8376351159932165 1.1\n","1817 tensor(-0.0109, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.8377974808772233 1.5\n","1818 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8379596833963461 1.1\n","1819 tensor(-0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8381217237129498 1.1\n","1820 tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8382836019892368 1.1\n","1821 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8384453183872476 1.2\n","1822 tensor(-0.0145, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8386068730688603 1.1\n","1823 tensor(-0.0108, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8387682661957915 1.1\n","1824 tensor(-0.0090, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8389294979295957 1.1\n","1825 tensor(-0.0172, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8390905684316661 1.3\n","1826 tensor(-0.0145, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8392514778632344 1.7\n","1827 tensor(-0.0109, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.8394122263853712 1.9\n","1828 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8395728141589858 1.7\n","1829 tensor(-0.0175, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8397332413448269 1.8\n","1830 tensor(-0.0117, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.839893508103482 1.7\n","1831 tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8400536145953785 1.7\n","1832 tensor(-0.0044, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8402135609807831 1.7\n","1833 tensor(-0.0137, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8403733474198023 1.8\n","1834 tensor(-0.0120, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8405329740723826 2.0\n","1835 tensor(-0.0169, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8406924410983102 1.9\n","1836 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8408517486572119 1.5\n","1837 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8410108969085547 1.0\n","1838 tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8411698860116461 1.1\n","1839 tensor(-0.0162, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.8413287161256344 1.6\n","1840 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.8414873874095088 2.5\n","1841 tensor(-0.0100, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8416459000220993 2.4\n","1842 tensor(-0.0125, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8418042541220772 2.6\n","1843 tensor(-0.0191, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8419624498679551 2.5\n","1844 tensor(-0.0134, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8421204874180872 2.3\n","1845 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.842278366930669 2.3\n","1846 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8424360885637384 2.3\n","1847 tensor(-0.0117, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8425936524751747 2.3\n","1848 tensor(-0.0147, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8427510588226995 2.4\n","1849 tensor(-0.0191, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8429083077638768 1.8\n","1850 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8430653994561129 0.9\n","1851 tensor(-0.0085, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8432223340566568 1.1\n","1852 tensor(-0.0210, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8433791117226002 1.1\n","1853 tensor(-0.0196, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.8435357326108776 1.5\n","1854 tensor(-0.0077, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8436921968782667 1.5\n","1855 tensor(-0.0155, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8438485046813884 1.4\n","1856 tensor(-0.0129, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8440046561767071 1.8\n","1857 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8441606515205303 1.9\n","1858 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8443164908690097 1.8\n","1859 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8444721743781407 1.8\n","1860 tensor(-0.0123, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8446277022037626 1.9\n","1861 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8447830745015589 1.8\n","1862 tensor(-0.0138, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8449382914270573 1.8\n","1863 tensor(-0.0179, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8450933531356303 1.4\n","1864 tensor(-0.0097, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.8452482597824946 2.3\n","1865 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8454030115227121 2.3\n","1866 tensor(-0.0180, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8455576085111894 2.2\n","1867 tensor(-0.0138, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8457120509026782 1.9\n","1868 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8458663388517755 2.1\n","1869 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8460204725129238 2.2\n","1870 tensor(-0.0203, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.8461744520404109 2.9\n","1871 tensor(-0.0173, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8463282775883705 2.9\n","1872 tensor(-0.0157, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.846481949310782 2.8\n","1873 tensor(-0.0092, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8466354673614713 2.8\n","1874 tensor(-0.0068, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8467888318941098 1.8\n","1875 tensor(-0.0076, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8469420430622157 1.8\n","1876 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8470951010191535 1.5\n","1877 tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8472480059181343 1.6\n","1878 tensor(-0.0097, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8474007579122163 1.3\n","1879 tensor(-0.0118, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.847553357154304 1.5\n","1880 tensor(-0.0160, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8477058037971497 0.7\n","1881 tensor(-0.0146, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.8478580979933525 1.2\n","1882 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8480102398953593 1.1\n","1883 tensor(-0.0189, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8481622296554638 1.2\n","1884 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8483140674258084 1.2\n","1885 tensor(-0.0160, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8484657533583826 1.2\n","1886 tensor(-0.0125, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8486172876050242 1.2\n","1887 tensor(-0.0137, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8487686703174192 1.2\n","1888 tensor(-0.0181, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8489199016471017 1.2\n","1889 tensor(-0.0099, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.8490709817454547 1.5\n","1890 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8492219107637092 1.7\n","1891 tensor(-0.0108, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8493726888529456 1.5\n","1892 tensor(-0.0134, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8495233161640926 1.6\n","1893 tensor(-0.0096, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8496737928479285 1.5\n","1894 tensor(-0.0155, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8498241190550806 1.5\n","1895 tensor(-0.0085, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8499742949360255 1.6\n","1896 tensor(-0.0073, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8501243206410896 1.6\n","1897 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8502741963204484 1.5\n","1898 tensor(-0.0151, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.850423922124128 1.5\n","1899 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8505734982020039 0.9\n","1900 tensor(-0.0164, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8507229247038018 0.8\n","1901 tensor(-0.0012, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8508722017790981 0.5\n","1902 tensor(-0.0100, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.851021329577319 1.1\n","1903 tensor(-0.0227, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8511703082477416 1.0\n","1904 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8513191379394939 1.0\n","1905 tensor(-0.0188, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8514678188015544 0.9\n","1906 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8516163509827529 1.0\n","1907 tensor(-0.0114, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8517647346317702 1.2\n","1908 tensor(-0.0169, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8519129698971384 1.3\n","1909 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8520610569272412 1.3\n","1910 tensor(-0.0104, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.852208995870314 1.3\n","1911 tensor(-0.0141, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8523567868744436 1.3\n","1912 tensor(-0.0145, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8525044300875692 0.6\n","1913 tensor(-0.0133, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8526519256574816 0.8\n","1914 tensor(-0.0187, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.8527992737318242 1.5\n","1915 tensor(-0.0114, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8529464744580924 1.7\n","1916 tensor(-0.0167, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8530935279836342 1.6\n","1917 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8532404344556506 1.4\n","1918 tensor(-0.0118, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8533871940211949 1.7\n","1919 tensor(-0.0093, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8535338068271737 1.7\n","1920 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8536802730203465 1.7\n","1921 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8538265927473262 1.8\n","1922 tensor(-0.0104, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.8539727661545788 2.4\n","1923 tensor(-0.0111, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8541187933884242 2.6\n","1924 tensor(-0.0118, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8542646745950359 1.9\n","1925 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8544104099204408 1.8\n","1926 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8545559995105204 2.1\n","1927 tensor(-0.0086, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8547014435110099 2.1\n","1928 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8548467420674989 2.0\n","1929 tensor(-0.0179, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8549918953254314 2.3\n","1930 tensor(-0.0058, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.855136903430106 2.4\n","1931 tensor(-0.0168, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8552817665266759 2.3\n","1932 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8554264847601492 1.8\n","1933 tensor(-0.0167, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.855571058275389 1.5\n","1934 tensor(-0.0160, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8557154872171135 1.5\n","1935 tensor(-0.0117, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8558597717298965 1.5\n","1936 tensor(-0.0156, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8560039119581666 1.4\n","1937 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.8561479080462084 1.9\n","1938 tensor(-0.0133, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8562917601381622 1.7\n","1939 tensor(-0.0074, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8564354683780241 1.6\n","1940 tensor(-0.0082, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8565790329096461 1.6\n","1941 tensor(-0.0118, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8567224538767364 1.6\n","1942 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8568657314228597 1.5\n","1943 tensor(-0.0167, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8570088656914369 1.5\n","1944 tensor(-0.0092, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8571518568257455 1.5\n","1945 tensor(-0.0235, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8572947049689197 1.5\n","1946 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8574374102639507 1.6\n","1947 tensor(-0.0166, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8575799728536868 1.5\n","1948 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8577223928808331 1.4\n","1949 tensor(-0.0178, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8578646704879522 1.4\n","1950 tensor(-0.0191, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8580068058174644 1.3\n","1951 tensor(-0.0142, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8581487990116469 1.3\n","1952 tensor(-0.0178, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.8582906502126352 1.8\n","1953 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8584323595624226 1.9\n","1954 tensor(-0.0110, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8585739272028601 2.0\n","1955 tensor(-0.0080, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8587153532756573 2.1\n","1956 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8588566379223816 1.9\n","1957 tensor(-0.0097, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8589977812844592 1.5\n","1958 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8591387835031747 1.5\n","1959 tensor(-0.0076, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8592796447196716 1.4\n","1960 tensor(-0.0163, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8594203650749519 1.7\n","1961 tensor(-0.0145, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.859560944709877 1.8\n","1962 tensor(-0.0166, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.859701383765167 1.5\n","1963 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.8598416823814019 1.8\n","1964 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8599818406990205 1.7\n","1965 tensor(-0.0173, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8601218588583215 1.6\n","1966 tensor(-0.0191, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8602617369994632 1.6\n","1967 tensor(-0.0099, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8604014752624637 1.7\n","1968 tensor(-0.0164, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8605410737872012 1.8\n","1969 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.860680532713414 1.8\n","1970 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8608198521807007 1.7\n","1971 tensor(-0.0196, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.86095903232852 1.6\n","1972 tensor(-0.0041, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.8610980732961915 2.3\n","1973 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8612369752228952 1.8\n","1974 tensor(-0.0042, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8613757382476723 1.8\n","1975 tensor(-0.0162, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8615143625094247 1.7\n","1976 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8616528481469152 1.6\n","1977 tensor(-0.0162, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8617911952987684 1.8\n","1978 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8619294041034696 1.8\n","1979 tensor(-0.0185, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8620674746993662 2.1\n","1980 tensor(-0.0170, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8622054072246668 2.0\n","1981 tensor(-0.0091, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8623432018174421 1.9\n","1982 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8624808586156246 1.0\n","1983 tensor(-0.0210, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.862618377757009 1.0\n","1984 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8627557593792521 1.1\n","1985 tensor(-0.0098, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8628930036198728 1.1\n","1986 tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8630301106162529 1.4\n","1987 tensor(-0.0187, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8631670805056366 1.5\n","1988 tensor(-0.0065, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.863303913425131 1.4\n","1989 tensor(-0.0071, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8634406095117059 1.0\n","1990 tensor(-0.0129, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8635771689021942 1.2\n","1991 tensor(-0.0153, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.863713591733292 1.5\n","1992 tensor(-0.0061, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8638498781415587 1.6\n","1993 tensor(-0.0108, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8639860282634171 1.8\n","1994 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8641220422351537 1.7\n","1995 tensor(-0.0206, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8642579201929186 1.8\n","1996 tensor(-0.0183, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8643936622727256 1.5\n","1997 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8645292686104529 1.1\n","1998 tensor(-0.0094, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8646647393418425 1.1\n","1999 tensor(-0.0117, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8648000746025006 1.1\n","2000 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.8649352745278981 1.3\n","2001 tensor(-0.0174, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8650703392533702 1.1\n","2002 tensor(-0.0020, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8652052689141169 1.0\n","2003 tensor(-0.0132, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8653400636452027 0.8\n","2004 tensor(-0.0120, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8654747235815575 0.8\n","2005 tensor(-0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.865609248857976 0.8\n","2006 tensor(-0.0086, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.865743639609118 0.9\n","2007 tensor(-0.0050, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8658778959695088 1.1\n","2008 tensor(-0.0086, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8660120180735393 1.4\n","2009 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8661460060554658 1.6\n","2010 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8662798600494104 1.0\n","2011 tensor(-0.0141, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8664135801893609 1.2\n","2012 tensor(-0.0109, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8665471666091715 1.4\n","2013 tensor(-0.0176, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8666806194425625 1.4\n","2014 tensor(-0.0158, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8668139388231199 1.8\n","2015 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8669471248842967 2.0\n","2016 tensor(-0.0070, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8670801777594124 1.9\n","2017 tensor(-0.0138, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.867213097581653 2.1\n","2018 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8673458844840713 1.8\n","2019 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8674785385995873 1.9\n","2020 tensor(-0.0147, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8676110600609878 1.9\n","2021 tensor(-0.0132, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8677434490009267 1.7\n","2022 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8678757055519258 1.6\n","2023 tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8680078298463738 1.6\n","2024 tensor(-0.0166, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8681398220165275 1.2\n","2025 tensor(-0.0111, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.868271682194511 0.9\n","2026 tensor(-0.0125, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8684034105123165 0.9\n","2027 tensor(-0.0074, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8685350071018042 0.7\n","2028 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8686664720947024 0.8\n","2029 tensor(-0.0030, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8687978056226077 0.7\n","2030 tensor(-0.0132, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8689290078169851 0.7\n","2031 tensor(-0.0096, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.869060078809168 0.9\n","2032 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.8691910187303589 1.3\n","2033 tensor(-0.0194, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8693218277116286 1.3\n","2034 tensor(-0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8694525058839169 1.3\n","2035 tensor(-0.0183, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.869583053378033 1.4\n","2036 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.869713470324655 1.8\n","2037 tensor(-0.0046, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8698437568543304 1.7\n","2038 tensor(-0.0129, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.869973913097476 1.6\n","2039 tensor(-0.0081, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8701039391843786 1.5\n","2040 tensor(-0.0087, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8702338352451942 1.8\n","2041 tensor(-0.0109, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.870363601409949 1.9\n","2042 tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8704932378085389 1.4\n","2043 tensor(-0.0076, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.8706227445707304 1.9\n","2044 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8707521218261597 2.0\n","2045 tensor(-0.0141, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8708813697043335 2.1\n","2046 tensor(-0.0109, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8710104883346292 1.8\n","2047 tensor(-0.0122, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8711394778462945 1.8\n","2048 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8712683383684483 1.8\n","2049 tensor(-0.0108, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8713970700300798 1.7\n","2050 tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8715256729600498 1.6\n","2051 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8716541472870897 1.3\n","2052 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8717824931398026 1.6\n","2053 tensor(-0.0058, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8719107106466628 1.4\n","2054 tensor(-0.0065, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8720387999360162 1.3\n","2055 tensor(-0.0133, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.8721667611360802 1.7\n","2056 tensor(-0.0158, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.872294594374944 1.6\n","2057 tensor(-0.0146, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8724222997805691 1.8\n","2058 tensor(-0.0172, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8725498774807885 2.2\n","2059 tensor(-0.0134, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8726773276033077 2.2\n","2060 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8728046502757044 2.1\n","2061 tensor(-0.0180, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.8729318456254287 2.6\n","2062 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.8730589137798033 2.9\n","2063 tensor(-0.0133, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8731858548660235 2.8\n","2064 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8733126690111574 3.1\n","2065 tensor(-0.0132, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8734393563421463 2.5\n","2066 tensor(-0.0052, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8735659169858041 2.9\n","2067 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8736923510688184 2.6\n","2068 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8738186587177494 2.2\n","2069 tensor(-0.0091, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8739448400590317 2.2\n","2070 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8740708952189727 2.1\n","2071 tensor(-0.0110, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8741968243237537 1.7\n","2072 tensor(-0.0174, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.87432262749943 1.4\n","2073 tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8744483048719306 1.2\n","2074 tensor(-0.0036, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8745738565670587 1.0\n","2075 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8746992827104916 1.1\n","2076 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.874824583427781 0.8\n","2077 tensor(-0.0096, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8749497588443533 0.9\n","2078 tensor(-0.0147, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8750748090855089 0.9\n","2079 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8751997342764235 1.1\n","2080 tensor(-0.0111, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.875324534542147 1.7\n","2081 tensor(-0.0046, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8754492100076049 1.7\n","2082 tensor(-0.0162, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8755737607975973 1.6\n","2083 tensor(-0.0125, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.8756981870367997 2.3\n","2084 tensor(-0.0136, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8758224888497629 2.6\n","2085 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8759466663609131 2.6\n","2086 tensor(-0.0134, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8760707196945522 2.6\n","2087 tensor(-0.0122, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8761946489748577 2.9\n","2088 tensor(-0.0175, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8763184543258828 3.2\n","2089 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.876442135871557 3.6\n","2090 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8765656937356854 3.1\n","2091 tensor(-0.0087, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8766891280419497 3.1\n","2092 tensor(-0.0167, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8768124389139077 3.1\n","2093 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8769356264749938 2.4\n","2094 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8770586908485188 2.1\n","2095 tensor(-0.0165, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8771816321576703 2.1\n","2096 tensor(-0.0115, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8773044505255126 2.1\n","2097 tensor(-0.0158, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8774271460749872 1.8\n","2098 tensor(-0.0043, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8775497189289121 1.5\n","2099 tensor(-0.0175, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8776721692099833 0.9\n","2100 tensor(-0.0083, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8777944970407733 0.8\n","2101 tensor(-0.0090, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8779167025437324 0.7\n","2102 tensor(-0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8780387858411888 0.9\n","2103 tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8781607470553475 1.2\n","2104 tensor(-0.0032, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8782825863082921 1.2\n","2105 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.878404303721984 1.1\n","2106 tensor(-0.0117, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.8785258994182619 1.5\n","2107 tensor(-0.0046, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8786473735188437 1.4\n","2108 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8787687261453248 1.5\n","2109 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8788899574191795 1.5\n","2110 tensor(-0.0151, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8790110674617603 1.6\n","2111 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8791320563942986 1.5\n","2112 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8792529243379043 1.1\n","2113 tensor(-0.0175, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8793736714135664 0.8\n","2114 tensor(-0.0051, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.8794942977421528 1.2\n","2115 tensor(-0.0163, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8796148034444107 1.3\n","2116 tensor(-0.0137, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.8797351886409662 1.6\n","2117 tensor(-0.0136, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8798554534523253 1.6\n","2118 tensor(-0.0169, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8799755979988729 1.7\n","2119 tensor(-0.0010, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.880095622400874 2.0\n","2120 tensor(-0.0030, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.8802155267784731 2.7\n","2121 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8803353112516947 2.8\n","2122 tensor(-0.0111, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.880454975940443 2.8\n","2123 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8805745209645025 2.8\n","2124 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.880693946443538 2.4\n","2125 tensor(-0.0117, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8808132524970945 2.5\n","2126 tensor(-0.0077, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8809324392445974 1.7\n","2127 tensor(-0.0203, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8810515068053528 1.7\n","2128 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8811704552985474 1.5\n","2129 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8812892848432489 1.3\n","2130 tensor(-0.0039, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8814079955584057 0.8\n","2131 tensor(-0.0104, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8815265875628473 0.7\n","2132 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.8816450609752844 1.2\n","2133 tensor(-0.0086, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8817634159143091 1.3\n","2134 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8818816524983948 1.3\n","2135 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8819997708458964 1.1\n","2136 tensor(-0.0207, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8821177710750505 1.2\n","2137 tensor(-0.0166, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8822356533039755 1.3\n","2138 tensor(-0.0158, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8823534176506715 1.4\n","2139 tensor(-0.0060, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8824710642330208 1.3\n","2140 tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.8825885931687878 1.7\n","2141 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.882706004575619 1.7\n","2142 tensor(-0.0068, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8828232985710434 1.6\n","2143 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8829404752724723 1.5\n","2144 tensor(-0.0115, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8830575347971998 1.4\n","2145 tensor(-0.0122, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.8831744772624027 2.1\n","2146 tensor(-0.0176, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8832913027851403 2.4\n","2147 tensor(-0.0111, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8834080114823551 2.5\n","2148 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8835246034708728 2.5\n","2149 tensor(-0.0151, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.883641078867402 2.7\n","2150 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8837574377885346 2.0\n","2151 tensor(-0.0162, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.883873680350746 2.2\n","2152 tensor(-0.0179, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8839898066703953 2.2\n","2153 tensor(-0.0202, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8841058168637248 2.4\n","2154 tensor(-0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8842217110468611 2.6\n","2155 tensor(-0.0171, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8843374893358142 1.9\n","2156 tensor(-0.0160, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8844531518464784 1.7\n","2157 tensor(-0.0019, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.884568698694632 1.6\n","2158 tensor(-0.0045, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8846841299959374 1.5\n","2159 tensor(-0.0156, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8847994458659414 1.4\n","2160 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8849146464200754 1.8\n","2161 tensor(-0.0085, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8850297317736554 1.6\n","2162 tensor(-0.0174, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8851447020418818 1.4\n","2163 tensor(-0.0184, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8852595573398399 1.6\n","2164 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8853742977825 1.7\n","2165 tensor(-0.0169, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8854889234847175 1.7\n","2166 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8856034345612328 1.7\n","2167 tensor(-0.0162, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8857178311266716 1.6\n","2168 tensor(-0.0134, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8858321132955449 1.8\n","2169 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8859462811822494 1.9\n","2170 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8860603349010671 1.6\n","2171 tensor(-0.0083, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.886174274566166 1.6\n","2172 tensor(-0.0157, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8862881002915999 1.5\n","2173 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.8864018121913082 1.6\n","2174 tensor(-0.0148, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.886515410379117 1.4\n","2175 tensor(-0.0108, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8866288949687378 1.5\n","2176 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.886742266073769 1.3\n","2177 tensor(-0.0122, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8868555238076953 1.5\n","2178 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8869686682838877 1.4\n","2179 tensor(-0.0132, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8870816996156037 1.3\n","2180 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8871946179159881 1.3\n","2181 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8873074232980721 1.6\n","2182 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8874201158747741 1.7\n","2183 tensor(-0.0148, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8875326957588993 1.3\n","2184 tensor(-0.0134, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8876451630631403 1.4\n","2185 tensor(-0.0115, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8877575179000773 1.5\n","2186 tensor(-0.0183, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8878697603821772 1.9\n","2187 tensor(-0.0178, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.887981890621795 1.9\n","2188 tensor(-0.0075, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8880939087311732 1.9\n","2189 tensor(-0.0206, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.8882058148224421 2.5\n","2190 tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8883176090076196 2.6\n","2191 tensor(-0.0064, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8884292913986119 2.4\n","2192 tensor(-0.0148, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.8885408621072134 3.3\n","2193 tensor(-0.0072, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8886523212451062 3.4\n","2194 tensor(-0.0181, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.888763668923861 3.2\n","2195 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8888749052549372 3.3\n","2196 tensor(-0.0099, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8889860303496823 2.9\n","2197 tensor(-0.0162, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8890970443193326 2.7\n","2198 tensor(-0.0185, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8892079472750132 2.8\n","2199 tensor(-0.0157, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.8893187393277382 2.8\n","2200 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8894294205884105 3.0\n","2201 tensor(-0.0180, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8895399911678221 3.1\n","2202 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.8896504511766543 2.6\n","2203 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8897608007254776 2.4\n","2204 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8898710399247521 2.7\n","2205 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8899811688848274 2.7\n","2206 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8900911877159425 3.1\n","2207 tensor(-0.0100, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8902010965282265 3.2\n","2208 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8903108954316984 3.0\n","2209 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8904205845362667 2.3\n","2210 tensor(-0.0148, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8905301639517305 2.3\n","2211 tensor(-0.0008, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.8906396337877787 2.9\n","2212 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8907489941539909 2.4\n","2213 tensor(-0.0166, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8908582451598369 2.5\n","2214 tensor(-0.0097, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.890967386914677 2.2\n","2215 tensor(-0.0179, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8910764195277624 2.0\n","2216 tensor(-0.0100, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8911853431082346 1.8\n","2217 tensor(-0.0199, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8912941577651264 1.8\n","2218 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8914028636073613 2.0\n","2219 tensor(-0.0186, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8915114607437539 2.1\n","2220 tensor(-0.0142, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8916199492830101 1.7\n","2221 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.8917283293337271 1.4\n","2222 tensor(-0.0185, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8918366010043934 1.5\n","2223 tensor(-0.0106, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.891944764403389 2.4\n","2224 tensor(-0.0122, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8920528196389856 2.7\n","2225 tensor(-0.0137, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8921607668193466 2.7\n","2226 tensor(-0.0180, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.8922686060525273 3.3\n","2227 tensor(-0.0155, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8923763374464748 3.4\n","2228 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8924839611090283 3.3\n","2229 tensor(-0.0153, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8925914771479193 3.2\n","2230 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8926988856707714 3.3\n","2231 tensor(-0.0200, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8928061867851006 2.9\n","2232 tensor(-0.0096, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8929133805983155 2.8\n","2233 tensor(-0.0167, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8930204672177172 1.8\n","2234 tensor(-0.0122, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8931274467504995 1.5\n","2235 tensor(-0.0133, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.893234319303749 1.6\n","2236 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8933410849844452 0.8\n","2237 tensor(-0.0167, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8934477438994608 0.9\n","2238 tensor(-0.0117, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.8935542961555614 1.4\n","2239 tensor(-0.0129, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.8936607418594058 1.9\n","2240 tensor(-0.0115, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8937670811175463 1.8\n","2241 tensor(-0.0123, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8938733140364288 2.0\n","2242 tensor(-0.0117, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8939794407223924 1.9\n","2243 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.89408546128167 1.9\n","2244 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8941913758203883 1.9\n","2245 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.894297184444568 1.9\n","2246 tensor(-0.0177, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8944028872601234 2.0\n","2247 tensor(-0.0138, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8945084843728632 1.7\n","2248 tensor(-0.0118, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8946139758884903 1.2\n","2249 tensor(-0.0153, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8947193619126019 0.7\n","2250 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8948246425506893 1.0\n","2251 tensor(-0.0052, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8949298179081386 0.8\n","2252 tensor(-0.0088, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8950348880902305 1.0\n","2253 tensor(-0.0185, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8951398532021402 1.0\n","2254 tensor(-0.0092, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.8952447133489381 1.5\n","2255 tensor(-0.0167, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8953494686355892 1.4\n","2256 tensor(-0.0008, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8954541191669536 1.3\n","2257 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8955586650477866 1.4\n","2258 tensor(-0.0133, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8956631063827388 1.4\n","2259 tensor(-0.0132, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.895767443276356 2.0\n","2260 tensor(-0.0173, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8958716758330797 1.8\n","2261 tensor(-0.0180, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8959758041572466 1.9\n","2262 tensor(-0.0197, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.8960798283530894 2.3\n","2263 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8961837485247364 2.3\n","2264 tensor(-0.0120, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8962875647762116 2.0\n","2265 tensor(-0.0226, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8963912772114354 2.0\n","2266 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.8964948859342239 2.5\n","2267 tensor(-0.0188, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8965983910482898 2.4\n","2268 tensor(-0.0069, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8967017926572414 2.6\n","2269 tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8968050908645842 2.0\n","2270 tensor(-0.0168, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8969082857737196 2.3\n","2271 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8970113774879459 2.2\n","2272 tensor(-0.0145, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8971143661104579 1.6\n","2273 tensor(-0.0160, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8972172517443475 1.6\n","2274 tensor(-0.0142, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8973200344926031 1.4\n","2275 tensor(-0.0188, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8974227144581105 1.7\n","2276 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8975252917436524 1.4\n","2277 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8976277664519088 1.5\n","2278 tensor(-0.0153, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8977301386854568 1.3\n","2279 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.8978324085467714 1.6\n","2280 tensor(-0.0163, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8979345761382246 1.4\n","2281 tensor(-0.0108, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8980366415620864 1.4\n","2282 tensor(-0.0209, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.8981386049205243 1.8\n","2283 tensor(-0.0115, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8982404663156038 1.9\n","2284 tensor(-0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8983422258492881 1.9\n","2285 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8984438836234389 1.5\n","2286 tensor(-0.0193, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8985454397398155 1.4\n","2287 tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.8986468943000756 1.5\n","2288 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8987482474057755 1.4\n","2289 tensor(-0.0177, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8988494991583698 1.1\n","2290 tensor(-0.0085, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8989506496592115 0.9\n","2291 tensor(-0.0175, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8990516990095522 0.9\n","2292 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8991526473105427 0.6\n","2293 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8992534946632321 0.6\n","2294 tensor(-0.0194, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8993542411685689 0.6\n","2295 tensor(-0.0153, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8994548869274003 0.6\n","2296 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.899555432040473 0.5\n","2297 tensor(-0.0192, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8996558766084324 0.4\n","2298 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.899756220731824 0.5\n","2299 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.8998564645110921 0.5\n","2300 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.8999566080465811 0.6\n","2301 tensor(-0.0134, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9000566514385345 0.6\n","2302 tensor(-0.0144, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.900156594787096 0.5\n","2303 tensor(-0.0108, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9002564381923088 0.4\n","2304 tensor(-0.0177, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9003561817541166 0.7\n","2305 tensor(-0.0123, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9004558255723625 1.1\n","2306 tensor(-0.0102, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9005553697467901 1.6\n","2307 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9006548143770433 1.8\n","2308 tensor(-0.0080, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9007541595626662 2.1\n","2309 tensor(-0.0134, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9008534054031037 2.3\n","2310 tensor(-0.0076, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9009525519977005 2.2\n","2311 tensor(-0.0200, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9010515994457028 2.3\n","2312 tensor(-0.0125, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9011505478462571 2.3\n","2313 tensor(-0.0098, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9012493972984108 2.3\n","2314 tensor(-0.0115, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9013481479011124 2.0\n","2315 tensor(-0.0086, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9014467997532113 1.6\n","2316 tensor(-0.0100, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9015453529534581 1.3\n","2317 tensor(-0.0069, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9016438076005047 1.0\n","2318 tensor(-0.0156, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9017421637929042 0.9\n","2319 tensor(-0.0163, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9018404216291113 0.9\n","2320 tensor(-0.0051, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9019385812074822 0.9\n","2321 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9020366426262746 0.9\n","2322 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9021346059836484 1.0\n","2323 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9022324713776647 1.1\n","2324 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.902330238906287 1.3\n","2325 tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9024279086673808 1.3\n","2326 tensor(-0.0083, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9025254807587134 1.6\n","2327 tensor(-0.0111, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9026229552779547 1.7\n","2328 tensor(-0.0064, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9027203323226767 1.7\n","2329 tensor(-0.0156, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.902817611990354 1.6\n","2330 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9029147943783636 1.8\n","2331 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9030118795839853 2.4\n","2332 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9031088677044014 2.9\n","2333 tensor(-0.0169, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.903205758836697 2.9\n","2334 tensor(-0.0175, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9033025530778602 2.8\n","2335 tensor(-0.0090, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9033992505247823 3.6\n","2336 tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9034958512742576 3.1\n","2337 tensor(-0.0092, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9035923554229833 3.3\n","2338 tensor(-0.0187, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9036887630675603 3.1\n","2339 tensor(-0.0153, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9037850743044928 3.5\n","2340 tensor(-0.0141, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9038812892301883 3.3\n","2341 tensor(-0.0100, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9039774079409582 2.8\n","2342 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9040734305330171 2.2\n","2343 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9041693571024841 2.4\n","2344 tensor(-0.0106, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9042651877453817 2.5\n","2345 tensor(-0.0132, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9043609225576362 1.7\n","2346 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9044565616350786 1.7\n","2347 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9045521050734435 1.5\n","2348 tensor(-0.0123, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9046475529683701 1.4\n","2349 tensor(-0.0056, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9047429054154017 0.9\n","2350 tensor(-0.0052, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9048381625099864 1.5\n","2351 tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9049333243474763 1.2\n","2352 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9050283910231289 1.2\n","2353 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9051233626321058 1.0\n","2354 tensor(-0.0160, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9052182392694736 0.8\n","2355 tensor(-0.0116, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9053130210302042 1.0\n","2356 tensor(-0.0182, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9054077080091739 1.2\n","2357 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9055023003011647 1.5\n","2358 tensor(-0.0165, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9055967980008636 1.8\n","2359 tensor(-0.0156, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9056912012028627 1.9\n","2360 tensor(-0.0064, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9057855100016599 1.6\n","2361 tensor(-0.0120, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9058797244916582 1.7\n","2362 tensor(-0.0145, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9059738447671666 1.9\n","2363 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9060678709223994 2.1\n","2364 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.906161803051477 2.5\n","2365 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9062556412484255 2.5\n","2366 tensor(-0.0132, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9063493856071771 2.9\n","2367 tensor(-0.0169, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.90644303622157 3.0\n","2368 tensor(-0.0061, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9065365931853484 3.4\n","2369 tensor(-0.0100, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.906630056592163 3.3\n","2370 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9067234265355708 3.7\n","2371 tensor(-0.0090, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9068167031090353 3.7\n","2372 tensor(-0.0100, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9069098864059263 3.6\n","2373 tensor(-0.0099, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9070029765195203 3.4\n","2374 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9070959735430008 3.0\n","2375 tensor(-0.0145, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9071888775694578 3.4\n","2376 tensor(-0.0083, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9072816886918883 2.8\n","2377 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9073744070031964 2.4\n","2378 tensor(-0.0136, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9074670325961932 1.7\n","2379 tensor(-0.0112, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9075595655635971 1.7\n","2380 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9076520059980334 1.4\n","2381 tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9077443539920355 1.3\n","2382 tensor(-0.0089, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9078366096380434 2.0\n","2383 tensor(-0.0077, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9079287730284054 2.3\n","2384 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.908020844255377 2.3\n","2385 tensor(-0.0136, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9081128234111215 2.4\n","2386 tensor(-0.0151, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9082047105877105 2.6\n","2387 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9082965058771227 2.6\n","2388 tensor(-0.0056, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9083882093712456 2.6\n","2389 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9084798211618743 2.8\n","2390 tensor(-0.0186, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9085713413407125 2.6\n","2391 tensor(-0.0151, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9086627699993718 2.8\n","2392 tensor(-0.0137, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9087541072293723 2.1\n","2393 tensor(-0.0163, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.908845353122143 1.7\n","2394 tensor(-0.0043, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9089365077690209 1.7\n","2395 tensor(-0.0117, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9090275712612519 1.0\n","2396 tensor(-0.0145, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9091185436899906 1.1\n","2397 tensor(-0.0029, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9092094251463005 1.0\n","2398 tensor(-0.0171, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9093002157211543 1.4\n","2399 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9093909155054332 1.6\n","2400 tensor(-0.0133, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9094815245899277 1.7\n","2401 tensor(-0.0099, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9095720430653378 1.5\n","2402 tensor(-0.0186, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9096624710222725 1.5\n","2403 tensor(-0.0092, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9097528085512502 2.3\n","2404 tensor(-0.0097, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.909843055742699 2.7\n","2405 tensor(-0.0050, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9099332126869563 2.8\n","2406 tensor(-0.0176, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9100232794742693 3.1\n","2407 tensor(-0.0075, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.910113256194795 3.3\n","2408 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9102031429386002 2.9\n","2409 tensor(-0.0085, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9102929397956616 3.1\n","2410 tensor(-0.0117, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.910382646855866 2.9\n","2411 tensor(-0.0148, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9104722642090101 3.2\n","2412 tensor(-0.0096, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.910561791944801 3.1\n","2413 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9106512301528563 2.7\n","2414 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9107405789227034 2.4\n","2415 tensor(-0.0147, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9108298383437807 2.6\n","2416 tensor(-0.0010, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.910919008505437 2.3\n","2417 tensor(-0.0168, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9110080894969315 2.4\n","2418 tensor(-0.0148, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9110970814074346 2.4\n","2419 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9111859843260272 2.3\n","2420 tensor(-0.0106, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9112747983417011 2.4\n","2421 tensor(-0.0184, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9113635235433594 2.2\n","2422 tensor(-0.0179, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.911452160019816 2.3\n","2423 tensor(-0.0153, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9115407078597962 2.1\n","2424 tensor(-0.0123, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9116291671519364 2.0\n","2425 tensor(-0.0079, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9117175379847845 1.7\n","2426 tensor(-0.0076, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9118058204467997 1.5\n","2427 tensor(-0.0102, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9118940146263529 1.8\n","2428 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9119821206117266 2.5\n","2429 tensor(-0.0167, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9120701384911148 2.1\n","2430 tensor(-0.0141, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9121580683526237 2.0\n","2431 tensor(-0.0085, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.912245910284271 2.4\n","2432 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9123336643739868 2.5\n","2433 tensor(-0.0125, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9124213307096128 2.6\n","2434 tensor(-0.0180, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9125089093789032 2.6\n","2435 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9125964004695243 2.6\n","2436 tensor(-0.0115, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9126838040690548 2.5\n","2437 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9127711202649857 2.1\n","2438 tensor(-0.0175, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9128583491447207 1.5\n","2439 tensor(-0.0087, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9129454907955761 1.6\n","2440 tensor(-0.0144, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9130325453047805 1.5\n","2441 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9131195127594757 1.2\n","2442 tensor(-0.0122, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9132063932467163 1.0\n","2443 tensor(-0.0158, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9132931868534695 0.9\n","2444 tensor(-0.0096, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.913379893666616 1.4\n","2445 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9134665137729494 1.7\n","2446 tensor(-0.0045, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9135530472591764 1.8\n","2447 tensor(-0.0099, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9136394942119173 1.9\n","2448 tensor(-0.0011, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9137258547177054 1.8\n","2449 tensor(-0.0148, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9138121288629877 2.3\n","2450 tensor(-0.0123, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9138983167341247 2.3\n","2451 tensor(-0.0094, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9139844184173905 2.2\n","2452 tensor(-0.0114, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9140704339989731 2.3\n","2453 tensor(-0.0112, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9141563635649742 2.5\n","2454 tensor(-0.0075, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9142422072014093 2.1\n","2455 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9143279649942078 2.5\n","2456 tensor(-0.0069, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9144136370292136 2.5\n","2457 tensor(-0.0092, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9144992233921844 2.2\n","2458 tensor(-0.0077, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9145847241687922 2.6\n","2459 tensor(-0.0189, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9146701394446234 2.2\n","2460 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9147554693051788 2.2\n","2461 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9148407138358736 2.1\n","2462 tensor(-0.0170, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9149258731220378 2.0\n","2463 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9150109472489157 1.7\n","2464 tensor(-0.0081, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9150959363016667 1.6\n","2465 tensor(-0.0137, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9151808403653652 1.6\n","2466 tensor(-0.0039, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9152656595249997 1.6\n","2467 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9153503938654748 1.8\n","2468 tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9154350434716093 1.4\n","2469 tensor(-0.0100, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9155196084281376 1.1\n","2470 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9156040888197096 1.2\n","2471 tensor(-0.0112, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9156884847308898 1.5\n","2472 tensor(-0.0142, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9157727962461589 1.6\n","2473 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9158570234499128 1.5\n","2474 tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9159411664264628 1.8\n","2475 tensor(-0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9160252252600364 1.1\n","2476 tensor(-0.0093, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9161092000347764 1.2\n","2477 tensor(-0.0052, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9161930908347415 1.0\n","2478 tensor(-0.0054, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9162768977439069 1.0\n","2479 tensor(-0.0110, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.916360620846163 2.2\n","2480 tensor(-0.0050, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9164442602253168 2.4\n","2481 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9165278159650915 2.3\n","2482 tensor(-0.0114, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9166112881491264 2.2\n","2483 tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9166946768609773 2.4\n","2484 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9167779821841162 2.1\n","2485 tensor(-0.0110, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9168612042019322 2.5\n","2486 tensor(-0.0046, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9169443429977302 2.5\n","2487 tensor(-0.0096, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9170273986547325 3.0\n","2488 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.9171103712560777 4.1\n","2489 tensor(-0.0144, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9171932608848217 2.9\n","2490 tensor(-0.0158, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9172760676239369 3.3\n","2491 tensor(-0.0168, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.917358791556313 3.2\n","2492 tensor(-0.0120, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9174414327647566 3.3\n","2493 tensor(-0.0088, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9175239913319918 3.3\n","2494 tensor(-0.0002, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9176064673406599 3.6\n","2495 tensor(-0.0120, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9176888608733191 3.2\n","2496 tensor(-0.0111, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9177711720124458 3.3\n","2497 tensor(-0.0185, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9178534008404334 2.9\n","2498 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.9179355474395929 2.9\n","2499 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9180176118921534 3.0\n","2500 tensor(-0.0096, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9180995942802612 2.5\n","2501 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.918181494685981 2.5\n","2502 tensor(-0.0030, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.918263313191295 3.2\n","2503 tensor(-0.0120, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9183450498781037 3.0\n","2504 tensor(-0.0090, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9184267048282256 3.0\n","2505 tensor(-0.0071, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9185082781233974 3.0\n","2506 tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.918589769845274 3.0\n","2507 tensor(-0.0060, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9186711800754287 3.2\n","2508 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9187525088953533 2.3\n","2509 tensor(-0.0085, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9188337563864579 2.6\n","2510 tensor(-0.0165, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9189149226300715 2.5\n","2511 tensor(-0.0123, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9189960077074414 2.4\n","2512 tensor(-0.0134, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.919077011699734 1.8\n","2513 tensor(-0.0116, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9191579346880343 1.8\n","2514 tensor(-0.0092, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.9192387767533462 2.4\n","2515 tensor(-0.0141, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9193195379765928 3.1\n","2516 tensor(-0.0129, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9194002184386163 3.0\n","2517 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9194808182201777 3.1\n","2518 tensor(-0.0044, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9195613374019574 3.1\n","2519 tensor(-0.0039, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9196417760645555 2.8\n","2520 tensor(-0.0058, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9197221342884909 2.7\n","2521 tensor(-0.0094, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9198024121542024 2.8\n","2522 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9198826097420483 3.3\n","2523 tensor(-0.0065, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9199627271323062 3.4\n","2524 tensor(-0.0138, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.920042764405174 2.7\n","2525 tensor(-0.0123, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9201227216407688 2.3\n","2526 tensor(-0.0050, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.920202598919128 2.2\n","2527 tensor(-0.0099, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9202823963202089 1.9\n","2528 tensor(-0.0084, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9203621139238887 2.1\n","2529 tensor(-0.0068, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9204417518099648 2.1\n","2530 tensor(-0.0097, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9205213100581549 2.1\n","2531 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9206007887480967 2.0\n","2532 tensor(-0.0098, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9206801879593486 1.6\n","2533 tensor(-0.0033, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9207595077713892 2.2\n","2534 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9208387482636178 2.0\n","2535 tensor(-0.0108, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9209179095153541 1.9\n","2536 tensor(-0.0123, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9209969916058388 1.8\n","2537 tensor(-0.0120, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.921075994614233 1.7\n","2538 tensor(-0.0104, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9211549186196187 2.0\n","2539 tensor(-0.0061, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9212337637009991 2.0\n","2540 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9213125299372982 2.1\n","2541 tensor(-0.0054, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9213912174073609 2.1\n","2542 tensor(-0.0058, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9214698261899534 2.3\n","2543 tensor(-0.0155, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9215483563637635 1.9\n","2544 tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9216268080073997 2.1\n","2545 tensor(-0.0162, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9217051811993924 2.3\n","2546 tensor(-0.0073, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.921783476018193 2.8\n","2547 tensor(-0.0138, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9218616925421748 2.9\n","2548 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9219398308496326 2.3\n","2549 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.922017891018783 2.4\n","2550 tensor(-0.0094, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9220958731277642 2.4\n","2551 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9221737772546365 2.4\n","2552 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9222516034773818 2.0\n","2553 tensor(-0.0133, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9223293518739044 1.8\n","2554 tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9224070225220304 1.8\n","2555 tensor(-0.0093, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9224846154995084 1.9\n","2556 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.922562130884009 1.7\n","2557 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9226395687531249 2.3\n","2558 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9227169291843718 2.2\n","2559 tensor(-0.0111, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9227942122551874 2.0\n","2560 tensor(-0.0115, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9228714180429323 1.9\n","2561 tensor(-0.0122, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9229485466248893 2.1\n","2562 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9230255980782645 2.7\n","2563 tensor(-0.0067, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9231025724801861 3.4\n","2564 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9231794699077059 3.3\n","2565 tensor(-0.0076, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9232562904377983 2.8\n","2566 tensor(-0.0091, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.9233330341473605 3.4\n","2567 tensor(-0.0099, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9234097011132131 3.0\n","2568 tensor(-0.0098, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9234862914120999 3.0\n","2569 tensor(-0.0045, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9235628051206878 3.0\n","2570 tensor(-0.0104, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9236392423155672 3.0\n","2571 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9237156030732515 3.0\n","2572 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9237918874701783 2.6\n","2573 tensor(-0.0068, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9238680955827081 1.9\n","2574 tensor(-0.0133, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9239442274871255 1.8\n","2575 tensor(-0.0066, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9240202832596383 1.8\n","2576 tensor(-0.0036, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9240962629763787 1.3\n","2577 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9241721667134023 1.4\n","2578 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9242479945466888 1.7\n","2579 tensor(-0.0133, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9243237465521422 2.2\n","2580 tensor(-0.0079, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9243994228055901 2.4\n","2581 tensor(-0.0091, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9244750233827844 2.7\n","2582 tensor(-0.0184, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9245505483594016 2.5\n","2583 tensor(-0.0081, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9246259978110423 3.0\n","2584 tensor(-0.0151, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9247013718132312 3.0\n","2585 tensor(-0.0042, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.924776670441418 3.0\n","2586 tensor(-0.0089, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9248518937709767 2.6\n","2587 tensor(-0.0085, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9249270418772056 2.4\n","2588 tensor(-0.0076, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9250021148353285 2.1\n","2589 tensor(-0.0084, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9250771127204931 1.8\n","2590 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9251520356077726 2.1\n","2591 tensor(-0.0098, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9252268835721649 1.8\n","2592 tensor(-0.0120, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9253016566885927 1.7\n","2593 tensor(-0.0122, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9253763550319041 1.3\n","2594 tensor(-0.0118, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9254509786768722 1.4\n","2595 tensor(-0.0074, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9255255276981953 1.4\n","2596 tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9256000021704971 2.2\n","2597 tensor(-0.0096, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9256744021683266 2.0\n","2598 tensor(-0.0097, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9257487277661582 2.1\n","2599 tensor(-0.0104, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9258229790383921 1.9\n","2600 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9258971560593537 1.8\n","2601 tensor(-0.0078, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9259712589032943 1.7\n","2602 tensor(-0.0071, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9260452876443911 2.2\n","2603 tensor(-0.0088, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9261192423567467 2.0\n","2604 tensor(-0.0134, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.92619312311439 2.5\n","2605 tensor(-0.0071, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9262669299912756 2.5\n","2606 tensor(-0.0038, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9263406630612843 1.7\n","2607 tensor(-0.0027, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.926414322398223 1.7\n","2608 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9264879080758248 1.6\n","2609 tensor(-0.0074, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.9265614201677489 2.6\n","2610 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9266348587475812 2.7\n","2611 tensor(-0.0018, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9267082238888336 2.8\n","2612 tensor(-0.0115, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9267815156649448 2.9\n","2613 tensor(-0.0138, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9268547341492799 2.9\n","2614 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9269278794151306 2.5\n","2615 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9270009515357154 2.6\n","2616 tensor(-0.0094, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9270739505841797 2.6\n","2617 tensor(-0.0086, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9271468766335955 2.7\n","2618 tensor(-0.0083, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9272197297569619 2.9\n","2619 tensor(-0.0173, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9272925100272049 2.0\n","2620 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9273652175171777 2.3\n","2621 tensor(-0.0201, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9274378522996606 2.1\n","2622 tensor(-0.0064, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9275104144473609 1.9\n","2623 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9275829040329135 2.2\n","2624 tensor(-0.0079, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9276553211288806 2.0\n","2625 tensor(-0.0068, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9277276658077518 1.9\n","2626 tensor(-0.0048, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.927799938141944 2.5\n","2627 tensor(-0.0091, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.927872138203802 2.4\n","2628 tensor(-0.0117, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9279442660655982 2.2\n","2629 tensor(-0.0065, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9280163217995326 2.1\n","2630 tensor(-0.0090, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9280883054777331 1.5\n","2631 tensor(-0.0091, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9281602171722554 1.8\n","2632 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9282320569550832 1.4\n","2633 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.928303824898128 1.2\n","2634 tensor(-0.0115, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.92837552107323 1.2\n","2635 tensor(-0.0029, device='cuda:0', grad_fn=<MeanBackward0>) 19 0.9284471455521567 3.1\n","2636 tensor(-0.0062, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9285186984066045 2.9\n","2637 tensor(-0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9285901797081979 2.9\n","2638 tensor(-0.0114, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9286615895284898 3.1\n","2639 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9287329279389612 3.1\n","2640 tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9288041950110223 2.9\n","2641 tensor(-0.0094, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9288753908160112 2.6\n","2642 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9289465154251952 3.1\n","2643 tensor(-0.0162, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.92901756890977 3.2\n","2644 tensor(-0.0007, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9290885513408602 3.5\n","2645 tensor(-0.0123, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9291594627895194 1.6\n","2646 tensor(-0.0117, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.92923030332673 1.3\n","2647 tensor(-0.0080, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9293010730234031 1.6\n","2648 tensor(-0.0076, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9293717719503798 1.7\n","2649 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9294424001784294 2.3\n","2650 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9295129577782509 2.7\n","2651 tensor(-0.0097, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9295834448204727 2.7\n","2652 tensor(-0.0106, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9296538613756522 2.4\n","2653 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9297242075142766 2.2\n","2654 tensor(-0.0148, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9297944833067623 2.0\n","2655 tensor(-0.0176, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9298646888234555 2.5\n","2656 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9299348241346321 2.9\n","2657 tensor(-0.0110, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9300048893104975 2.8\n","2658 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.930074884421187 2.6\n","2659 tensor(-0.0039, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9301448095367658 2.2\n","2660 tensor(-0.0168, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.930214664727229 2.0\n","2661 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9302844500625018 2.1\n","2662 tensor(-0.0070, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9303541656124392 2.0\n","2663 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9304238114468268 2.1\n","2664 tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.93049338763538 2.0\n","2665 tensor(-0.0074, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9305628942477446 1.6\n","2666 tensor(-0.0062, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.9306323313534969 2.1\n","2667 tensor(-0.0099, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9307016990221434 1.9\n","2668 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9307709973231213 1.8\n","2669 tensor(-0.0141, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9308402263257981 1.7\n","2670 tensor(-0.0075, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9309093860994724 1.9\n","2671 tensor(-0.0091, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9309784767133729 2.2\n","2672 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.9310474982366594 3.0\n","2673 tensor(-0.0030, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9311164507384229 3.1\n","2674 tensor(-0.0129, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9311853342876844 3.1\n","2675 tensor(-0.0123, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9312541489533968 3.5\n","2676 tensor(-0.0081, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9313228948044433 2.5\n","2677 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.9313915719096388 3.8\n","2678 tensor(-0.0098, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9314601803377293 4.3\n","2679 tensor(-0.0008, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9315287201573915 4.5\n","2680 tensor(-0.0054, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9315971914372341 4.8\n","2681 tensor(-0.0094, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9316655942457969 4.5\n","2682 tensor(-0.0120, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9317339286515511 4.0\n","2683 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9318021947228995 4.6\n","2684 tensor(-0.0136, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9318703925281766 4.7\n","2685 tensor(-0.0081, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9319385221356484 4.6\n","2686 tensor(-0.0060, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9320065836135129 4.7\n","2687 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9320745770298993 3.6\n","2688 tensor(-0.0063, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9321425024528693 3.5\n","2689 tensor(-0.0148, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9322103599504166 3.3\n","2690 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9322781495904661 2.6\n","2691 tensor(-0.0147, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9323458714408757 3.0\n","2692 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9324135255694348 3.2\n","2693 tensor(-0.0112, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9324811120438653 2.4\n","2694 tensor(-0.0094, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9325486309318214 2.6\n","2695 tensor(-0.0087, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9326160823008897 2.2\n","2696 tensor(-0.0100, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9326834662185888 2.5\n","2697 tensor(-0.0094, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9327507827523701 2.4\n","2698 tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9328180319696178 2.2\n","2699 tensor(-0.0147, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9328852139376481 2.3\n","2700 tensor(-0.0078, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9329523287237105 2.4\n","2701 tensor(-0.0111, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9330193763949868 2.0\n","2702 tensor(-0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9330863570185918 1.5\n","2703 tensor(-0.0110, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9331532706615732 1.5\n","2704 tensor(-0.0125, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9332201173909116 1.2\n","2705 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9332868972735207 1.2\n","2706 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9333536103762472 1.1\n","2707 tensor(-0.0170, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9334202567658709 1.0\n","2708 tensor(-0.0088, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.933486836509105 1.5\n","2709 tensor(-0.0114, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.933553349672596 1.4\n","2710 tensor(-0.0091, device='cuda:0', grad_fn=<MeanBackward0>) 20 0.9336197963229234 3.3\n","2711 tensor(-0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9336861765266005 3.4\n","2712 tensor(-0.0038, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9337524903500738 3.5\n","2713 tensor(-0.0122, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9338187378597238 3.5\n","2714 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.933884919121864 3.6\n","2715 tensor(-0.0133, device='cuda:0', grad_fn=<MeanBackward0>) 14 0.9339510342027422 5.0\n","2716 tensor(-0.0129, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9340170831685395 5.1\n","2717 tensor(-0.0062, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.934083066085371 5.1\n","2718 tensor(-0.0100, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9341489830192855 4.6\n","2719 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9342148340362663 4.8\n","2720 tensor(-0.0158, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9342806192022299 3.1\n","2721 tensor(-0.0092, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.9343463385830277 3.8\n","2722 tensor(-0.0106, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9344119922444447 3.8\n","2723 tensor(-0.0068, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9344775802522003 4.1\n","2724 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9345431026719481 4.4\n","2725 tensor(-0.0111, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9346085595692761 3.0\n","2726 tensor(-0.0069, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9346739510097068 2.6\n","2727 tensor(-0.0112, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9347392770586971 2.8\n","2728 tensor(-0.0125, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9348045377816384 2.6\n","2729 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9348697332438568 2.4\n","2730 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.934934863510613 2.6\n","2731 tensor(-0.0145, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9349999286471024 1.7\n","2732 tensor(-0.0067, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9350649287184553 1.6\n","2733 tensor(-0.0085, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9351298637897367 2.0\n","2734 tensor(-0.0012, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.935194733925947 1.9\n","2735 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9352595391920211 2.0\n","2736 tensor(-0.0042, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.935324279652829 3.2\n","2737 tensor(-0.0040, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9353889553731762 3.0\n","2738 tensor(-0.0067, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9354535664178031 3.2\n","2739 tensor(-0.0112, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9355181128513852 3.1\n","2740 tensor(-0.0071, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9355825947385339 2.7\n","2741 tensor(-0.0118, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9356470121437953 3.0\n","2742 tensor(-0.0125, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9357113651316515 3.1\n","2743 tensor(-0.0104, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9357756537665198 2.7\n","2744 tensor(-0.0084, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9358398781127534 2.7\n","2745 tensor(-0.0118, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9359040382346406 2.6\n","2746 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9359681341964059 1.4\n","2747 tensor(-0.0083, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9360321660622095 1.5\n","2748 tensor(-0.0098, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9360961338961473 1.3\n","2749 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9361600377622512 1.5\n","2750 tensor(-0.0153, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9362238777244889 1.5\n","2751 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9362876538467644 1.3\n","2752 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9363513661929177 1.6\n","2753 tensor(-0.0109, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9364150148267247 1.7\n","2754 tensor(-0.0145, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9364785998118981 1.7\n","2755 tensor(-0.0146, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.9365421212120861 2.7\n","2756 tensor(-0.0160, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.936605579090874 3.0\n","2757 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9366689735117831 2.9\n","2758 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9367323045382714 3.1\n","2759 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9367955722337331 2.9\n","2760 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9368587766614994 3.1\n","2761 tensor(-0.0091, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9369219178848379 3.2\n","2762 tensor(-0.0041, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9369849959669531 3.0\n","2763 tensor(-0.0136, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9370480109709861 3.4\n","2764 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9371109629600152 3.2\n","2765 tensor(-0.0112, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.937173851997055 2.3\n","2766 tensor(-0.0146, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9372366781450581 2.3\n","2767 tensor(-0.0162, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.937299441466913 2.4\n","2768 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.9373621420254461 3.3\n","2769 tensor(-0.0106, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.9374247798834207 4.6\n","2770 tensor(-0.0073, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9374873551035372 4.4\n","2771 tensor(-0.0104, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9375498677484336 4.8\n","2772 tensor(-0.0094, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9376123178806852 4.6\n","2773 tensor(-0.0068, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.9376747055628045 4.9\n","2774 tensor(-0.0115, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9377370308572417 5.1\n","2775 tensor(-0.0073, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9377992938263845 5.1\n","2776 tensor(-0.0086, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9378614945325581 4.9\n","2777 tensor(-0.0083, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9379236330380256 5.0\n","2778 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9379857094049875 4.1\n","2779 tensor(-0.0118, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9380477236955825 2.9\n","2780 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.938109675971887 2.9\n","2781 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9381715662959151 2.4\n","2782 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9382333947296192 2.8\n","2783 tensor(-0.0064, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.9382951613348895 2.6\n","2784 tensor(-0.0088, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9383568661735546 2.5\n","2785 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9384185093073811 2.4\n","2786 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9384800907980737 2.6\n","2787 tensor(-0.0100, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9385416107072757 2.5\n","2788 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9386030690965683 2.4\n","2789 tensor(-0.0155, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9386644660274718 3.0\n","2790 tensor(-0.0096, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9387258015614444 3.5\n","2791 tensor(-0.0175, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9387870757598828 3.5\n","2792 tensor(-0.0129, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.938848288684123 3.0\n","2793 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9389094403954389 2.5\n","2794 tensor(-0.0087, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9389705309550435 2.5\n","2795 tensor(-0.0073, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9390315604240884 2.6\n","2796 tensor(-0.0169, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9390925288636643 2.6\n","2797 tensor(-0.0102, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9391534363348006 2.9\n","2798 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.9392142828984659 4.0\n","2799 tensor(-0.0096, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9392750686155674 3.4\n","2800 tensor(-0.0100, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9393357935469518 2.9\n","2801 tensor(-0.0204, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9393964577534049 2.9\n","2802 tensor(-0.0174, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9394570612956514 3.0\n","2803 tensor(-0.0093, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9395176042343558 2.6\n","2804 tensor(-0.0147, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9395780866301214 2.6\n","2805 tensor(-0.0162, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9396385085434913 2.7\n","2806 tensor(-0.0190, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9396988700349479 2.9\n","2807 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9397591711649129 2.7\n","2808 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.939819411993748 1.8\n","2809 tensor(-0.0197, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9398795925817542 1.7\n","2810 tensor(-0.0106, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9399397129891724 1.6\n","2811 tensor(-0.0148, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9399997732761833 1.5\n","2812 tensor(-0.0185, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9400597735029071 1.4\n","2813 tensor(-0.0198, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9401197137294042 1.8\n","2814 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9401795940156749 2.1\n","2815 tensor(-0.0112, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9402394144216591 1.9\n","2816 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9402991750072375 1.4\n","2817 tensor(-0.0125, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9403588758322302 1.5\n","2818 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.940418516956398 1.3\n","2819 tensor(-0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9404780984394416 1.8\n","2820 tensor(-0.0195, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9405376203410022 1.9\n","2821 tensor(-0.0032, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9405970827206612 1.9\n","2822 tensor(-0.0137, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9406564856379405 2.4\n","2823 tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9407158291523026 2.5\n","2824 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9407751133231502 2.0\n","2825 tensor(-0.0156, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9408343382098271 2.3\n","2826 tensor(-0.0115, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9408935038716173 2.4\n","2827 tensor(-0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9409526103677457 2.6\n","2828 tensor(-0.0210, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9410116577573779 2.6\n","2829 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9410706460996205 2.2\n","2830 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9411295754535209 2.2\n","2831 tensor(-0.0162, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9411884458780674 2.5\n","2832 tensor(-0.0092, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9412472574321893 2.5\n","2833 tensor(-0.0183, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9413060101747571 2.3\n","2834 tensor(-0.0042, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9413647041645824 2.9\n","2835 tensor(-0.0115, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9414233394604178 3.0\n","2836 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9414819161209573 3.3\n","2837 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9415404342048365 3.0\n","2838 tensor(-0.0110, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9415988937706316 3.1\n","2839 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.941657294876861 3.2\n","2840 tensor(-0.0213, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9417156375819841 3.4\n","2841 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9417739219444021 3.9\n","2842 tensor(-0.0099, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9418321480224577 3.9\n","2843 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9418903158744353 4.0\n","2844 tensor(-0.0144, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9419484255585608 3.4\n","2845 tensor(-0.0094, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9420064771330022 3.0\n","2846 tensor(-0.0146, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9420644706558693 2.8\n","2847 tensor(-0.0118, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9421224061852134 2.7\n","2848 tensor(-0.0162, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9421802837790282 2.5\n","2849 tensor(-0.0182, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9422381034952492 2.7\n","2850 tensor(-0.0147, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9422958653917539 2.7\n","2851 tensor(-0.0166, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9423535695263622 2.2\n","2852 tensor(-0.0125, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.9424112159568357 2.6\n","2853 tensor(-0.0229, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9424688047408789 2.4\n","2854 tensor(-0.0115, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9425263359361381 2.5\n","2855 tensor(-0.0109, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9425838096002019 2.6\n","2856 tensor(-0.0022, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9426412257906017 2.5\n","2857 tensor(-0.0129, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9426985845648111 2.4\n","2858 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9427558859802463 2.5\n","2859 tensor(-0.0057, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.942813130094266 2.7\n","2860 tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9428703169641718 2.4\n","2861 tensor(-0.0094, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9429274466472076 2.4\n","2862 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9429845192005604 1.8\n","2863 tensor(-0.0179, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9430415346813599 1.6\n","2864 tensor(-0.0044, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9430984931466785 1.7\n","2865 tensor(-0.0077, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9431553946535318 1.8\n","2866 tensor(-0.0169, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9432122392588783 1.8\n","2867 tensor(-0.0110, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9432690270196195 1.8\n","2868 tensor(-0.0104, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9433257579925998 2.2\n","2869 tensor(-0.0132, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9433824322346072 1.7\n","2870 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9434390498023726 2.1\n","2871 tensor(-0.0138, device='cuda:0', grad_fn=<MeanBackward0>) 16 0.9434956107525702 3.4\n","2872 tensor(-0.0118, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9435521151418176 3.2\n","2873 tensor(-0.0163, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9436085630266758 3.4\n","2874 tensor(-0.0110, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9436649544636492 3.5\n","2875 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9437212895091855 3.3\n","2876 tensor(-0.0157, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9437775682196763 3.2\n","2877 tensor(-0.0112, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9438337906514567 3.2\n","2878 tensor(-0.0162, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9438899568608051 2.7\n","2879 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.9439460669039443 3.7\n","2880 tensor(-0.0157, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9440021208370404 3.8\n","2881 tensor(-0.0160, device='cuda:0', grad_fn=<MeanBackward0>) 15 0.9440581187162034 3.7\n","2882 tensor(-0.0164, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9441140605974871 3.8\n","2883 tensor(-0.0202, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9441699465368897 3.8\n","2884 tensor(-0.0187, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9442257765903528 3.6\n","2885 tensor(-0.0068, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9442815508137624 4.2\n","2886 tensor(-0.0123, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9443372692629487 4.3\n","2887 tensor(-0.0108, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9443929319936857 4.9\n","2888 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.944448539061692 5.0\n","2889 tensor(-0.0180, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9445040905226304 4.2\n","2890 tensor(-0.0165, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9445595864321077 4.1\n","2891 tensor(-0.0204, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9446150268456757 2.7\n","2892 tensor(-0.0037, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9446704118188299 2.9\n","2893 tensor(-0.0030, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.9447257414070112 3.8\n","2894 tensor(-0.0136, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9447810156656041 3.8\n","2895 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9448362346499385 3.8\n","2896 tensor(-0.0122, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9448913984152886 3.8\n","2897 tensor(-0.0092, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9449465070168733 3.6\n","2898 tensor(-0.0125, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9450015605098564 3.5\n","2899 tensor(-0.0153, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9450565589493466 3.2\n","2900 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9451115023903972 3.6\n","2901 tensor(-0.0193, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9451663908880068 3.6\n","2902 tensor(-0.0184, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9452212244971188 3.2\n","2903 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9452760032726217 2.2\n","2904 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9453307272693491 2.4\n","2905 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9453853965420798 2.3\n","2906 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 15 0.9454400111455377 3.7\n","2907 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9454945711343921 4.1\n","2908 tensor(-0.0168, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9455490765632577 4.5\n","2909 tensor(-0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9456035274866944 5.1\n","2910 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9456579239592078 4.7\n","2911 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9457122660352485 4.7\n","2912 tensor(-0.0134, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9457665537692133 4.7\n","2913 tensor(-0.0111, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.945820787215444 5.9\n","2914 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9458749664282287 5.6\n","2915 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9459290914618004 5.1\n","2916 tensor(-0.0171, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.9459831623703386 4.5\n","2917 tensor(-0.0083, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9460371792079683 4.2\n","2918 tensor(-0.0174, device='cuda:0', grad_fn=<MeanBackward0>) 21 0.9460911420287603 5.9\n","2919 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.9461450508867315 6.4\n","2920 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9461989058358448 6.2\n","2921 tensor(-0.0147, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.946252706930009 6.3\n","2922 tensor(-0.0074, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9463064542230789 6.9\n","2923 tensor(-0.0164, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9463601477688559 6.0\n","2924 tensor(-0.0099, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.946413787621087 6.6\n","2925 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9464673738334659 6.6\n","2926 tensor(-0.0123, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9465209064596325 6.3\n","2927 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9465743855531729 6.2\n","2928 tensor(-0.0136, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9466278111676196 4.3\n","2929 tensor(-0.0094, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.946681183356452 3.4\n","2930 tensor(-0.0111, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9467345021730956 3.2\n","2931 tensor(-0.0165, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9467877676709225 3.0\n","2932 tensor(-0.0209, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9468409799032516 2.8\n","2933 tensor(-0.0192, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9468941389233483 2.8\n","2934 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9469472447844249 2.2\n","2935 tensor(-0.0209, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9470002975396405 2.5\n","2936 tensor(-0.0210, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9470532972421009 1.9\n","2937 tensor(-0.0191, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9471062439448588 1.8\n","2938 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.947159137700914 1.7\n","2939 tensor(-0.0133, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.947211978563213 1.5\n","2940 tensor(-0.0038, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9472647665846499 1.9\n","2941 tensor(-0.0092, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9473175018180652 1.9\n","2942 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.9473701843162471 2.5\n","2943 tensor(-0.0086, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9474228141319309 2.4\n","2944 tensor(-0.0085, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9474753913177989 2.5\n","2945 tensor(-0.0089, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9475279159264811 2.3\n","2946 tensor(-0.0136, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9475803880105547 2.3\n","2947 tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.9476328076225441 3.3\n","2948 tensor(-0.0098, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9476851748149215 3.3\n","2949 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9477374896401066 3.6\n","2950 tensor(-0.0108, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9477897521504665 3.3\n","2951 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9478419623983161 4.1\n","2952 tensor(-0.0160, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9478941204359177 3.5\n","2953 tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9479462263154819 3.5\n","2954 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9479982800891663 3.4\n","2955 tensor(-0.0086, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9480502818090771 3.5\n","2956 tensor(-0.0181, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9481022315272681 4.2\n","2957 tensor(-0.0155, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9481541292957408 2.9\n","2958 tensor(-0.0122, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9482059751664451 2.9\n","2959 tensor(-0.0117, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9482577691912786 2.9\n","2960 tensor(-0.0117, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9483095114220873 3.2\n","2961 tensor(-0.0146, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9483612019106653 3.0\n","2962 tensor(-0.0111, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9484128407087546 2.7\n","2963 tensor(-0.0097, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9484644278680459 2.5\n","2964 tensor(-0.0047, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9485159634401779 2.7\n","2965 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9485674474767376 2.7\n","2966 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9486188800292609 2.1\n","2967 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9486702611492316 2.4\n","2968 tensor(-0.0191, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9487215908880824 2.4\n","2969 tensor(-0.0177, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9487728692971943 2.1\n","2970 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9488240964278971 1.7\n","2971 tensor(-0.0168, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9488752723314692 1.3\n","2972 tensor(-0.0106, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9489263970591377 1.4\n","2973 tensor(-0.0097, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.9489774706620786 2.5\n","2974 tensor(-0.0137, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9490284931914166 2.3\n","2975 tensor(-0.0116, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9490794646982251 2.3\n","2976 tensor(-0.0158, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9491303852335269 2.3\n","2977 tensor(-0.0166, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.9491812548482934 2.9\n","2978 tensor(-0.0084, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.9492320735934451 4.1\n","2979 tensor(-0.0111, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9492828415198517 4.5\n","2980 tensor(-0.0074, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9493335586783318 5.2\n","2981 tensor(-0.0109, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9493842251196535 5.3\n","2982 tensor(-0.0066, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9494348408945338 5.1\n","2983 tensor(-0.0109, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9494854060536393 3.9\n","2984 tensor(-0.0010, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9495359206475856 4.0\n","2985 tensor(-0.0110, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.949586384726938 3.9\n","2986 tensor(-0.0151, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.949636798342211 4.2\n","2987 tensor(-0.0134, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9496871615438689 3.6\n","2988 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.949737474382325 2.4\n","2989 tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9497877369079427 2.0\n","2990 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9498379491710347 1.4\n","2991 tensor(-0.0176, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9498881112218637 1.4\n","2992 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9499382231106418 1.7\n","2993 tensor(-0.0189, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9499882848875312 2.0\n","2994 tensor(-0.0070, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9500382966026437 2.0\n","2995 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.950088258306041 2.4\n","2996 tensor(-0.0146, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9501381700477349 2.7\n","2997 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9501880318776872 2.6\n","2998 tensor(-0.0156, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9502378438458096 2.6\n","2999 tensor(-0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9502876060019637 2.8\n","3000 tensor(-0.0172, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9503373183959618 3.0\n","3001 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9503869810775658 2.9\n","3002 tensor(-0.0123, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9504365940964883 2.8\n","3003 tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9504861575023917 2.7\n","3004 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9505356713448894 3.1\n","3005 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9505851356735445 3.1\n","3006 tensor(-0.0017, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9506345505378709 2.7\n","3007 tensor(-0.0122, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.950683915987333 2.5\n","3008 tensor(-0.0094, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9507332320713457 2.8\n","3009 tensor(-0.0088, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9507824988392743 2.9\n","3010 tensor(-0.0145, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9508317163404352 3.4\n","3011 tensor(-0.0182, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9508808846240947 3.4\n","3012 tensor(-0.0108, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9509300037394706 3.3\n","3013 tensor(-0.0132, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9509790737357311 3.1\n","3014 tensor(-0.0187, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9510280946619953 2.7\n","3015 tensor(-0.0093, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9510770665673334 2.7\n","3016 tensor(-0.0093, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9511259895007661 2.8\n","3017 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9511748635112653 2.8\n","3018 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9512236886477541 2.5\n","3019 tensor(-0.0173, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9512724649591062 2.2\n","3020 tensor(-0.0075, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9513211924941471 1.5\n","3021 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.951369871301653 2.0\n","3022 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9514185014303513 1.9\n","3023 tensor(-0.0171, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.951467082928921 2.1\n","3024 tensor(-0.0097, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9515156158459921 2.1\n","3025 tensor(-0.0074, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.951564100230146 2.8\n","3026 tensor(-0.0134, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9516125361299159 2.6\n","3027 tensor(-0.0188, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9516609235937861 2.9\n","3028 tensor(-0.0178, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.9517092626701923 3.7\n","3029 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9517575534075221 4.0\n","3030 tensor(-0.0111, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9518057958541145 4.0\n","3031 tensor(-0.0122, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9518539900582604 3.6\n","3032 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9519021360682022 4.4\n","3033 tensor(-0.0114, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.951950233932134 4.4\n","3034 tensor(-0.0033, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9519982836982018 5.0\n","3035 tensor(-0.0155, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9520462854145036 3.8\n","3036 tensor(-0.0088, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9520942391290891 4.1\n","3037 tensor(-0.0156, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9521421448899601 3.9\n","3038 tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.95219000274507 3.4\n","3039 tensor(-0.0106, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.952237812742325 3.1\n","3040 tensor(-0.0168, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.9522855749295827 4.1\n","3041 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9523332893546531 4.0\n","3042 tensor(-0.0102, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9523809560652985 3.3\n","3043 tensor(-0.0122, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9524285751092332 3.2\n","3044 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9524761465341239 2.8\n","3045 tensor(-0.0205, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9525236703875898 3.0\n","3046 tensor(-0.0109, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9525711467172022 3.0\n","3047 tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.952618575570485 3.1\n","3048 tensor(-0.0162, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9526659569949145 2.7\n","3049 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9527132910379196 2.7\n","3050 tensor(-0.0129, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9527605777468817 2.3\n","3051 tensor(-0.0078, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9528078171691348 2.5\n","3052 tensor(-0.0146, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9528550093519657 2.5\n","3053 tensor(-0.0163, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9529021543426137 2.7\n","3054 tensor(-0.0167, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9529492521882711 2.4\n","3055 tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9529963029360828 2.4\n","3056 tensor(-0.0003, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9530433066331467 1.9\n","3057 tensor(-0.0171, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9530902633265136 2.5\n","3058 tensor(-0.0179, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.953137173063187 2.9\n","3059 tensor(-0.0168, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9531840358901239 3.0\n","3060 tensor(-0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9532308518542337 2.4\n","3061 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9532776210023796 2.2\n","3062 tensor(-0.0137, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9533243433813772 2.3\n","3063 tensor(-0.0170, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9533710190379958 2.3\n","3064 tensor(-0.0160, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9534176480189578 2.4\n","3065 tensor(-0.0177, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9534642303709389 2.8\n","3066 tensor(-0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9535107661405678 3.0\n","3067 tensor(-0.0106, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.9535572553744273 3.2\n","3068 tensor(-0.0191, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9536036981190529 2.8\n","3069 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9536500944209338 3.0\n","3070 tensor(-0.0167, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9536964443265129 2.9\n","3071 tensor(-0.0116, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.9537427478821864 3.6\n","3072 tensor(-0.0048, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.9537890051343042 4.4\n","3073 tensor(-0.0216, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9538352161291699 4.2\n","3074 tensor(-0.0137, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9538813809130408 4.9\n","3075 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9539274995321276 4.8\n","3076 tensor(-0.0199, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9539735720325956 4.9\n","3077 tensor(-0.0134, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.954019598460563 3.9\n","3078 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9540655788621024 3.9\n","3079 tensor(-0.0071, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.9541115132832403 4.8\n","3080 tensor(-0.0053, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.954157401769957 5.4\n","3081 tensor(-0.0123, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.954203244368187 5.0\n","3082 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9542490411238189 4.3\n","3083 tensor(-0.0075, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9542947920826951 4.3\n","3084 tensor(-0.0123, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9543404972906124 3.9\n","3085 tensor(-0.0174, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9543861567933217 3.8\n","3086 tensor(-0.0176, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9544317706365284 3.7\n","3087 tensor(-0.0037, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9544773388658919 4.2\n","3088 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.954522861527026 4.4\n","3089 tensor(-0.0123, device='cuda:0', grad_fn=<MeanBackward0>) 20 0.954568338665499 5.2\n","3090 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9546137703268335 4.7\n","3091 tensor(-0.0005, device='cuda:0', grad_fn=<MeanBackward0>) 18 0.9546591565565067 6.0\n","3092 tensor(-0.0093, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9547044973999501 5.8\n","3093 tensor(-0.0174, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9547497929025502 5.9\n","3094 tensor(-0.0122, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9547950431096477 5.7\n","3095 tensor(-0.0146, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.954840248066538 5.4\n","3096 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9548854078184714 5.2\n","3097 tensor(-0.0179, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.954930522410653 4.8\n","3098 tensor(-0.0167, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9549755918882423 4.7\n","3099 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9550206162963542 3.2\n","3100 tensor(-0.0123, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9550655956800578 3.6\n","3101 tensor(-0.0179, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9551105300843777 2.2\n","3102 tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9551554195542933 2.4\n","3103 tensor(-0.0132, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.955200264134739 3.0\n","3104 tensor(-0.0096, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9552450638706043 3.4\n","3105 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9552898188067337 3.7\n","3106 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9553345289879269 4.0\n","3107 tensor(-0.0097, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.955379194458939 4.0\n","3108 tensor(-0.0141, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.9554238152644801 5.1\n","3109 tensor(-0.0102, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9554683914492156 5.3\n","3110 tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9555129230577664 5.3\n","3111 tensor(-0.0097, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.9555574101347086 5.8\n","3112 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9556018527245739 5.9\n","3113 tensor(-0.0086, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9556462508718493 5.6\n","3114 tensor(-0.0061, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9556906046209775 5.2\n","3115 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9557349140163565 5.2\n","3116 tensor(-0.0074, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9557791791023401 5.0\n","3117 tensor(-0.0075, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9558233999232378 5.1\n","3118 tensor(-0.0125, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9558675765233146 4.2\n","3119 tensor(-0.0136, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9559117089467912 3.6\n","3120 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9559557972378445 3.3\n","3121 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9559998414406067 2.5\n","3122 tensor(-0.0075, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.956043841599166 2.1\n","3123 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9560877977575668 2.4\n","3124 tensor(-0.0151, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9561317099598092 2.3\n","3125 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9561755782498494 2.5\n","3126 tensor(-0.0122, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9562194026715997 2.5\n","3127 tensor(-0.0011, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.956263183268928 2.7\n","3128 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9563069200856591 3.2\n","3129 tensor(-0.0178, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9563506131655735 3.5\n","3130 tensor(-0.0076, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9563942625524079 4.0\n","3131 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 20 0.9564378682898554 5.9\n","3132 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9564814304215656 6.2\n","3133 tensor(-0.0160, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.956524948991144 6.1\n","3134 tensor(-0.0134, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9565684240421529 6.3\n","3135 tensor(-0.0132, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9566118556181108 6.0\n","3136 tensor(-0.0111, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9566552437624927 6.4\n","3137 tensor(-0.0132, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9566985885187301 6.3\n","3138 tensor(-0.0136, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9567418899302114 5.5\n","3139 tensor(-0.0167, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9567851480402813 5.1\n","3140 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9568283628922409 4.4\n","3141 tensor(-0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9568715345293487 2.9\n","3142 tensor(-0.0133, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9569146629948193 3.0\n","3143 tensor(-0.0122, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9569577483318246 2.4\n","3144 tensor(-0.0181, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9570007905834926 2.3\n","3145 tensor(-0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9570437897929092 2.1\n","3146 tensor(-0.0153, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9570867460031163 1.9\n","3147 tensor(-0.0019, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9571296592571131 1.6\n","3148 tensor(-0.0178, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.957172529597856 2.0\n","3149 tensor(-0.0133, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9572153570682582 2.1\n","3150 tensor(-0.0162, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.95725814171119 2.2\n","3151 tensor(-0.0079, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9573008835694787 1.7\n","3152 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9573435826859092 1.3\n","3153 tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9573862391032233 1.3\n","3154 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9574288528641202 1.1\n","3155 tensor(-0.0145, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.957471424011256 1.1\n","3156 tensor(-0.0157, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9575139525872447 1.1\n","3157 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9575564386346576 1.4\n","3158 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9575988821960228 1.1\n","3159 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9576412833138268 1.6\n","3160 tensor(-0.0168, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.957683642030513 2.6\n","3161 tensor(-0.0074, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9577259583884825 2.6\n","3162 tensor(-0.0110, device='cuda:0', grad_fn=<MeanBackward0>) 15 0.957768232430094 4.1\n","3163 tensor(-0.0148, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9578104641976639 4.1\n","3164 tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9578526537334663 4.3\n","3165 tensor(-0.0090, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9578948010797328 4.5\n","3166 tensor(-0.0116, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.957936906278653 4.3\n","3167 tensor(-0.0026, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9579789693723744 4.3\n","3168 tensor(-0.0137, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.958020990403002 4.3\n","3169 tensor(-0.0123, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.958062969412599 3.7\n","3170 tensor(-0.0137, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9581049064431865 3.0\n","3171 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9581468015367433 3.2\n","3172 tensor(-0.0188, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9581886547352065 1.8\n","3173 tensor(-0.0138, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9582304660804712 2.4\n","3174 tensor(-0.0157, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.9582722356143908 3.2\n","3175 tensor(-0.0114, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9583139633787764 3.1\n","3176 tensor(-0.0093, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9583556494153976 3.4\n","3177 tensor(-0.0037, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9583972937659823 3.9\n","3178 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9584388964722163 3.8\n","3179 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9584804575757441 3.8\n","3180 tensor(-0.0146, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9585219771181683 3.5\n","3181 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9585634551410501 3.3\n","3182 tensor(-0.0100, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9586048916859091 3.3\n","3183 tensor(-0.0099, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9586462867942231 3.4\n","3184 tensor(-0.0147, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9586876405074289 3.1\n","3185 tensor(-0.0184, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9587289528669215 3.4\n","3186 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9587702239140546 3.3\n","3187 tensor(-0.0118, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9588114536901405 2.9\n","3188 tensor(-0.0168, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9588526422364504 2.9\n","3189 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.958893789594214 2.9\n","3190 tensor(-0.0180, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9589348958046198 3.3\n","3191 tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9589759609088151 3.3\n","3192 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9590169849479063 3.2\n","3193 tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9590579679629584 2.8\n","3194 tensor(-0.0123, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9590989099949955 2.1\n","3195 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9591398110850005 1.9\n","3196 tensor(-0.0122, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9591806712739155 2.0\n","3197 tensor(-0.0142, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9592214906026415 1.7\n","3198 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.9592622691120389 2.7\n","3199 tensor(-0.0091, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9593030068429269 3.2\n","3200 tensor(-0.0138, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9593437038360839 2.9\n","3201 tensor(-0.0110, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9593843601322478 3.0\n","3202 tensor(-0.0120, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9594249757721156 3.1\n","3203 tensor(-0.0102, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9594655507963434 2.8\n","3204 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9595060852455471 3.2\n","3205 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9595465791603016 2.9\n","3206 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9595870325811413 3.0\n","3207 tensor(-0.0144, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9596274455485602 3.4\n","3208 tensor(-0.0078, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9596678181030116 2.7\n","3209 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9597081502849085 2.2\n","3210 tensor(-0.0098, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9597484421346236 2.2\n","3211 tensor(-0.0078, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9597886936924891 2.4\n","3212 tensor(-0.0167, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9598289049987966 2.3\n","3213 tensor(-0.0116, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9598690760937978 2.9\n","3214 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.959909207017704 2.5\n","3215 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9599492978106863 3.2\n","3216 tensor(-0.0106, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9599893485128755 3.1\n","3217 tensor(-0.0146, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9600293591643627 2.6\n","3218 tensor(-0.0094, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9600693298051983 2.5\n","3219 tensor(-0.0118, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9601092604753931 2.8\n","3220 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9601491512149177 2.6\n","3221 tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9601890020637028 2.4\n","3222 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9602288130616391 2.5\n","3223 tensor(-0.0081, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9602685842485775 2.2\n","3224 tensor(-0.0138, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.960308315664329 2.4\n","3225 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9603480073486645 1.7\n","3226 tensor(-0.0192, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9603876593413159 1.3\n","3227 tensor(-0.0172, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9604272716819746 1.6\n","3228 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9604668444102926 1.5\n","3229 tensor(-0.0097, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9605063775658823 1.8\n","3230 tensor(-0.0155, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9605458711883165 2.1\n","3231 tensor(-0.0056, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9605853253171281 2.5\n","3232 tensor(-0.0122, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.960624739991811 2.7\n","3233 tensor(-0.0158, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9606641152518192 2.9\n","3234 tensor(-0.0142, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9607034511365674 2.9\n","3235 tensor(-0.0147, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9607427476854308 2.9\n","3236 tensor(-0.0020, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9607820049377453 3.1\n","3237 tensor(-0.0155, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9608212229328076 2.8\n","3238 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9608604017098749 2.7\n","3239 tensor(-0.0141, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9608995413081649 2.5\n","3240 tensor(-0.0097, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9609386417668568 2.7\n","3241 tensor(-0.0144, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9609777031250899 2.3\n","3242 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9610167254219648 2.0\n","3243 tensor(-0.0100, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9610557086965429 1.6\n","3244 tensor(-0.0043, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9610946529878464 1.6\n","3245 tensor(-0.0112, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9611335583348585 2.4\n","3246 tensor(-0.0186, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9611724247765236 2.4\n","3247 tensor(-0.0082, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9612112523517471 2.9\n","3248 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9612500410993954 3.7\n","3249 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.961288791058296 4.1\n","3250 tensor(-0.0084, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9613275022672376 3.6\n","3251 tensor(-0.0100, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9613661747649704 3.6\n","3252 tensor(-0.0164, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9614048085902055 3.9\n","3253 tensor(-0.0115, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9614434037816153 3.8\n","3254 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9614819603778336 3.9\n","3255 tensor(-0.0173, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9615204784174558 3.2\n","3256 tensor(-0.0169, device='cuda:0', grad_fn=<MeanBackward0>) 14 0.9615589579390383 4.4\n","3257 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9615973989810993 3.9\n","3258 tensor(-0.0057, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9616358015821183 3.3\n","3259 tensor(-0.0094, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9616741657805361 3.1\n","3260 tensor(-0.0062, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9617124916147556 3.4\n","3261 tensor(-0.0077, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9617507791231408 3.7\n","3262 tensor(-0.0016, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9617890283440177 3.7\n","3263 tensor(-0.0093, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9618272393156736 3.9\n","3264 tensor(-0.0125, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.9618654120763579 4.9\n","3265 tensor(-0.0084, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9619035466642816 4.8\n","3266 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9619416431176173 3.9\n","3267 tensor(-0.0073, device='cuda:0', grad_fn=<MeanBackward0>) 14 0.9619797014744997 5.3\n","3268 tensor(-0.0104, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9620177217730252 5.8\n","3269 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9620557040512522 5.3\n","3270 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9620936483472009 5.3\n","3271 tensor(-0.0094, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9621315546988537 4.9\n","3272 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9621694231441549 4.9\n","3273 tensor(-0.0133, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9622072537210107 4.6\n","3274 tensor(-0.0129, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9622450464672897 3.3\n","3275 tensor(-0.0090, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9622828014208225 3.3\n","3276 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9623205186194016 2.9\n","3277 tensor(-0.0114, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9623581981007822 1.9\n","3278 tensor(-0.0204, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9623958399026814 1.6\n","3279 tensor(-0.0160, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9624334440627788 1.5\n","3280 tensor(-0.0078, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.962471010618716 1.4\n","3281 tensor(-0.0090, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9625085396080972 1.9\n","3282 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9625460310684891 1.7\n","3283 tensor(-0.0155, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9625834850374206 2.1\n","3284 tensor(-0.0129, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9626209015523832 2.7\n","3285 tensor(-0.0080, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.9626582806508308 3.7\n","3286 tensor(-0.0106, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.96269562237018 3.7\n","3287 tensor(-0.0086, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9627329267478099 3.4\n","3288 tensor(-0.0099, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.962770193821062 3.5\n","3289 tensor(-0.0120, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9628074236272409 3.8\n","3290 tensor(-0.0081, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9628446162036137 4.1\n","3291 tensor(-0.0069, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9628817715874101 3.6\n","3292 tensor(-0.0099, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9629188898158227 3.9\n","3293 tensor(-0.0158, device='cuda:0', grad_fn=<MeanBackward0>) 23 0.9629559709260069 5.8\n","3294 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9629930149550808 5.2\n","3295 tensor(-0.0073, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9630300219401258 4.5\n","3296 tensor(-0.0125, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9630669919181857 4.4\n","3297 tensor(-0.0138, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.9631039249262675 5.3\n","3298 tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9631408210013412 4.8\n","3299 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9631776801803399 4.8\n","3300 tensor(-0.0104, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.9632145025001595 5.5\n","3301 tensor(-0.0146, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.9632512879976594 6.8\n","3302 tensor(-0.0155, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9632880367096617 6.4\n","3303 tensor(-0.0046, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.963324748672952 4.6\n","3304 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9633614239242791 5.1\n","3305 tensor(-0.0123, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9633980625003549 5.4\n","3306 tensor(-0.0015, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9634346644378544 6.0\n","3307 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9634712297734166 5.0\n","3308 tensor(-0.0072, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9635077585436432 5.6\n","3309 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9635442507850995 5.6\n","3310 tensor(-0.0071, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.9635807065343145 5.4\n","3311 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9636171258277801 4.6\n","3312 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 29 0.9636535087019523 7.5\n","3313 tensor(-0.0151, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9636898551932505 7.4\n","3314 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9637261653380571 7.3\n","3315 tensor(-0.0148, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9637624391727191 7.3\n","3316 tensor(-0.0134, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.9637986767335464 7.6\n","3317 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9638348780568129 8.2\n","3318 tensor(-0.0074, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.963871043178756 7.9\n","3319 tensor(-0.0173, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9639071721355773 8.0\n","3320 tensor(-0.0145, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9639432649634417 7.1\n","3321 tensor(-0.0132, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9639793216984782 6.8\n","3322 tensor(-0.0133, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9640153423767798 3.9\n","3323 tensor(-0.0064, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.964051327034403 4.1\n","3324 tensor(-0.0048, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9640872757073686 3.8\n","3325 tensor(-0.0138, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9641231884316612 3.6\n","3326 tensor(-0.0133, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9641590652432296 2.7\n","3327 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9641949061779863 2.8\n","3328 tensor(-0.0183, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.9642307112718084 3.6\n","3329 tensor(-0.0162, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9642664805605365 4.0\n","3330 tensor(-0.0029, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.964302214079976 4.2\n","3331 tensor(-0.0173, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.964337911865896 4.2\n","3332 tensor(-0.0137, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.9643735739540301 5.1\n","3333 tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9644092003800762 4.6\n","3334 tensor(-0.0141, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9644447911796961 4.5\n","3335 tensor(-0.0120, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9644803463885163 4.1\n","3336 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9645158660421278 4.5\n","3337 tensor(-0.0151, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9645513501760857 3.9\n","3338 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9645867988259096 3.0\n","3339 tensor(-0.0118, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9646222120270836 2.2\n","3340 tensor(-0.0049, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9646575898150566 2.5\n","3341 tensor(-0.0166, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9646929322252416 2.8\n","3342 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9647282392930163 2.1\n","3343 tensor(-0.0096, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9647635110537233 2.1\n","3344 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9647987475426696 2.4\n","3345 tensor(-0.0153, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9648339487951269 2.7\n","3346 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.9648691148463318 3.3\n","3347 tensor(-0.0100, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9649042457314855 3.2\n","3348 tensor(-0.0167, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.964939341485754 3.5\n","3349 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9649744021442682 3.7\n","3350 tensor(-0.0079, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.965009427742124 3.9\n","3351 tensor(-0.0091, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.9650444183143818 4.3\n","3352 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9650793738960675 4.2\n","3353 tensor(-0.0064, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9651142945221713 4.2\n","3354 tensor(-0.0005, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9651491802276492 4.1\n","3355 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9651840310474216 4.2\n","3356 tensor(-0.0054, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9652188470163741 3.6\n","3357 tensor(-0.0016, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9652536281693578 3.8\n","3358 tensor(-0.0145, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9652883745411884 4.0\n","3359 tensor(-0.0040, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.9653230861666472 4.9\n","3360 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.9653577630804806 5.2\n","3361 tensor(-0.0153, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9653924053174001 4.7\n","3362 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9654270129120827 4.8\n","3363 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9654615858991706 5.2\n","3364 tensor(-0.0172, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9654961243132714 5.1\n","3365 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9655306281889582 5.0\n","3366 tensor(-0.0031, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9655650975607691 4.8\n","3367 tensor(-0.0089, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9655995324632084 4.9\n","3368 tensor(-0.0116, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9656339329307452 4.8\n","3369 tensor(-0.0059, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9656682989978145 3.7\n","3370 tensor(-0.0075, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9657026306988167 2.7\n","3371 tensor(-0.0025, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9657369280681178 2.4\n","3372 tensor(-0.0106, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.9657711911400497 3.1\n","3373 tensor(-0.0178, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9658054199489097 2.8\n","3374 tensor(-0.0137, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9658396145289607 3.2\n","3375 tensor(-0.0138, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9658737749144318 3.4\n","3376 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9659079011395174 3.4\n","3377 tensor(-0.0075, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9659419932383778 3.5\n","3378 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9659760512451395 3.7\n","3379 tensor(-0.0060, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9660100751938944 4.4\n","3380 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.9660440651187004 5.4\n","3381 tensor(-0.0132, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9660780210535818 5.9\n","3382 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9661119430325281 5.0\n","3383 tensor(-0.0108, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9661458310894956 4.8\n","3384 tensor(-0.0063, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.9661796852584061 5.4\n","3385 tensor(-0.0129, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9662135055731478 4.9\n","3386 tensor(-0.0015, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9662472920675745 4.8\n","3387 tensor(-0.0137, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.966281044775507 4.6\n","3388 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.9663147637307314 4.8\n","3389 tensor(-0.0068, device='cuda:0', grad_fn=<MeanBackward0>) 16 0.9663484489670008 5.7\n","3390 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9663821005180337 5.3\n","3391 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9664157184175157 5.2\n","3392 tensor(-0.0065, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9664493026990982 5.2\n","3393 tensor(-0.0080, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9664828533963992 5.4\n","3394 tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9665163705430028 4.6\n","3395 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9665498541724598 4.6\n","3396 tensor(-0.0067, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9665833043182872 4.9\n","3397 tensor(-0.0065, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.966616721013969 4.9\n","3398 tensor(-0.0173, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.966650104292955 4.5\n","3399 tensor(-0.0134, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9666834541886621 3.6\n","3400 tensor(-0.0137, device='cuda:0', grad_fn=<MeanBackward0>) 14 0.9667167707344734 4.3\n","3401 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9667500539637389 4.4\n","3402 tensor(-0.0145, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9667833039097752 4.4\n","3403 tensor(-0.0129, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9668165206058654 4.9\n","3404 tensor(-0.0076, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9668497040852595 5.0\n","3405 tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9668828543811743 5.0\n","3406 tensor(-0.0148, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9669159715267931 4.8\n","3407 tensor(-0.0104, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9669490555552663 4.8\n","3408 tensor(-0.0156, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9669821064997111 4.2\n","3409 tensor(-0.0117, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9670151243932114 3.5\n","3410 tensor(-0.0069, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9670481092688181 2.6\n","3411 tensor(-0.0198, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9670810611595493 2.7\n","3412 tensor(-0.0142, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9671139800983898 3.5\n","3413 tensor(-0.0088, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9671468661182914 2.9\n","3414 tensor(-0.0168, device='cuda:0', grad_fn=<MeanBackward0>) 14 0.967179719252173 3.9\n","3415 tensor(-0.0178, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9672125395329209 4.5\n","3416 tensor(-0.0038, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9672453269933879 4.9\n","3417 tensor(-0.0147, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9672780816663946 5.1\n","3418 tensor(-0.0162, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9673108035847282 5.9\n","3419 tensor(-0.0089, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9673434927811435 6.0\n","3420 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9673761492883624 5.6\n","3421 tensor(-0.0108, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9674087731390739 5.4\n","3422 tensor(-0.0122, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9674413643659349 5.2\n","3423 tensor(-0.0141, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.967473923001569 5.2\n","3424 tensor(-0.0030, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9675064490785674 4.5\n","3425 tensor(-0.0136, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9675389426294888 4.6\n","3426 tensor(-0.0167, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9675714036868593 4.0\n","3427 tensor(-0.0083, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9676038322831725 4.3\n","3428 tensor(-0.0147, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9676362284508893 3.5\n","3429 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9676685922224384 3.8\n","3430 tensor(-0.0106, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.967700923630216 4.2\n","3431 tensor(-0.0166, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9677332227065858 4.2\n","3432 tensor(-0.0129, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9677654894838792 3.7\n","3433 tensor(-0.0068, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9677977239943952 4.3\n","3434 tensor(-0.0160, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9678299262704009 3.6\n","3435 tensor(-0.0056, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9678620963441305 3.6\n","3436 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9678942342477863 3.7\n","3437 tensor(-0.0075, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9679263400135385 3.0\n","3438 tensor(-0.0064, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.967958413673525 3.4\n","3439 tensor(-0.0178, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9679904552598515 3.8\n","3440 tensor(-0.0079, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9680224648045916 3.5\n","3441 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9680544423397871 3.6\n","3442 tensor(-0.0090, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9680863878974473 3.5\n","3443 tensor(-0.0084, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9681183015095498 3.0\n","3444 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9681501832080402 3.0\n","3445 tensor(-0.0108, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.9681820330248322 3.2\n","3446 tensor(-0.0086, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9682138509918075 3.6\n","3447 tensor(-0.0020, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9682456371408156 4.3\n","3448 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9682773915036748 4.4\n","3449 tensor(-0.0098, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9683091141121711 3.6\n","3450 tensor(-0.0110, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.968340804998059 3.6\n","3451 tensor(-0.0055, device='cuda:0', grad_fn=<MeanBackward0>) 22 0.9683724641930609 5.2\n","3452 tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9684040917288678 5.5\n","3453 tensor(-0.0157, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9684356876371389 5.4\n","3454 tensor(-0.0010, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9684672519495018 5.4\n","3455 tensor(-0.0016, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9684987846975524 4.7\n","3456 tensor(-0.0100, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9685302859128547 4.4\n","3457 tensor(-0.0097, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9685617556269419 4.2\n","3458 tensor(-0.0110, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9685931938713149 3.9\n","3459 tensor(-0.0093, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9686246006774436 4.0\n","3460 tensor(-0.0079, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9686559760767662 4.5\n","3461 tensor(-0.0017, device='cuda:0', grad_fn=<MeanBackward0>) 18 0.9686873201006895 4.1\n","3462 tensor(-0.0083, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9687186327805888 3.8\n","3463 tensor(-0.0112, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9687499141478082 4.0\n","3464 tensor(-0.0053, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9687811642336603 4.0\n","3465 tensor(-0.0166, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9688123830694266 4.5\n","3466 tensor(-0.0151, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9688435706863573 4.3\n","3467 tensor(-0.0089, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9688747271156709 4.3\n","3468 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9689058523885552 4.8\n","3469 tensor(-0.0185, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9689369465361667 4.8\n","3470 tensor(-0.0117, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9689680095896305 4.5\n","3471 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9689990415800409 2.8\n","3472 tensor(-0.0060, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9690300425384608 2.8\n","3473 tensor(-0.0132, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9690610124959224 3.0\n","3474 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9690919514834264 3.1\n","3475 tensor(-0.0145, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.969122859531943 2.5\n","3476 tensor(-0.0133, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9691537366724111 3.1\n","3477 tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9691845829357386 2.6\n","3478 tensor(-0.0091, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9692153983528029 1.9\n","3479 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.9692461829544501 2.7\n","3480 tensor(-0.0165, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9692769367714956 2.9\n","3481 tensor(-0.0089, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.9693076598347242 3.9\n","3482 tensor(-0.0125, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9693383521748895 4.0\n","3483 tensor(-0.0132, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9693690138227146 3.6\n","3484 tensor(-0.0055, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9693996448088918 4.3\n","3485 tensor(-0.0129, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9694302451640829 4.2\n","3486 tensor(-0.0111, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9694608149189189 4.3\n","3487 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.969491354104 5.6\n","3488 tensor(-0.0111, device='cuda:0', grad_fn=<MeanBackward0>) 16 0.9695218627498959 7.2\n","3489 tensor(-0.0064, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.969552340887146 6.5\n","3490 tensor(-0.0096, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9695827885462589 6.2\n","3491 tensor(-0.0106, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9696132057577127 5.1\n","3492 tensor(-0.0110, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.969643592551955 5.0\n","3493 tensor(-0.0162, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.969673948959403 5.3\n","3494 tensor(-0.0118, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9697042750104435 4.6\n","3495 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9697345707354331 4.6\n","3496 tensor(-0.0065, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9697648361646977 4.5\n","3497 tensor(-0.0093, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.969795071328533 3.3\n","3498 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9698252762572045 1.8\n","3499 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9698554509809473 2.2\n","3500 tensor(-0.0093, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9698855955299663 2.4\n","3501 tensor(-0.0084, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.9699157099344363 3.6\n","3502 tensor(-0.0114, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9699457942245019 3.8\n","3503 tensor(-3.2191e-05, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9699758484302774 3.4\n","3504 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9700058725818471 3.5\n","3505 tensor(-0.0062, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9700358667092653 3.5\n","3506 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.970065830842556 3.3\n","3507 tensor(-0.0080, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9700957650117135 3.7\n","3508 tensor(-0.0087, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9701256692467017 3.8\n","3509 tensor(-0.0112, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.970155543577455 3.2\n","3510 tensor(-0.0091, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9701853880338777 3.2\n","3511 tensor(-4.3908e-05, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.9702152026458437 3.0\n","3512 tensor(-0.0059, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9702449874431979 2.9\n","3513 tensor(-0.0057, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9702747424557547 3.2\n","3514 tensor(-0.0064, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9703044677132989 3.3\n","3515 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 23 0.9703341632455856 5.6\n","3516 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9703638290823401 5.4\n","3517 tensor(-0.0002, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9703934652532578 5.2\n","3518 tensor(-0.0151, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9704230717880045 5.7\n","3519 tensor(-0.0108, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9704526487162165 5.8\n","3520 tensor(-0.0064, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9704821960675002 5.3\n","3521 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9705117138714328 4.7\n","3522 tensor(-0.0106, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9705412021575613 5.1\n","3523 tensor(-0.0129, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9705706609554038 5.5\n","3524 tensor(-0.0032, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9706000902944484 5.4\n","3525 tensor(-0.0137, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9706294902041539 3.1\n","3526 tensor(-0.0099, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9706588607139497 3.5\n","3527 tensor(-0.0169, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9706882018532358 3.3\n","3528 tensor(-0.0155, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9707175136513826 3.0\n","3529 tensor(-0.0019, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.9707467961377312 3.9\n","3530 tensor(-0.0110, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9707760493415934 4.0\n","3531 tensor(-0.0141, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9708052732922519 4.0\n","3532 tensor(-0.0093, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9708344680189596 3.6\n","3533 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9708636335509406 2.9\n","3534 tensor(-0.0163, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9708927699173897 2.9\n","3535 tensor(-0.0053, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.9709218771474724 4.0\n","3536 tensor(-0.0117, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9709509552703248 3.6\n","3537 tensor(-0.0151, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9709800043150545 3.6\n","3538 tensor(-0.0164, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9710090243107394 3.4\n","3539 tensor(-0.0074, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9710380152864287 2.4\n","3540 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9710669772711423 2.9\n","3541 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9710959102938711 2.9\n","3542 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9711248143835772 3.0\n","3543 tensor(-0.0132, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9711536895691937 3.2\n","3544 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9711825358796244 3.5\n","3545 tensor(-0.0193, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9712113533437449 2.4\n","3546 tensor(-0.0108, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.9712401419904011 3.1\n","3547 tensor(-0.0068, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9712689018484107 3.5\n","3548 tensor(-0.0157, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9712976329465624 4.1\n","3549 tensor(-0.0168, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9713263353136158 4.2\n","3550 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9713550089783022 4.1\n","3551 tensor(-0.0068, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9713836539693238 3.8\n","3552 tensor(-0.0145, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9714122703153545 3.8\n","3553 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9714408580450391 3.7\n","3554 tensor(-0.0100, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9714694171869941 3.3\n","3555 tensor(-0.0144, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.9714979477698071 4.4\n","3556 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9715264498220373 3.9\n","3557 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9715549233722153 3.6\n","3558 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9715833684488431 3.4\n","3559 tensor(-0.0109, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9716117850803943 3.4\n","3560 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9716401732953138 3.7\n","3561 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9716685331220185 3.6\n","3562 tensor(-0.0133, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.9716968645888965 4.5\n","3563 tensor(-0.0083, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9717251677243076 4.5\n","3564 tensor(-0.0155, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9717534425565832 4.7\n","3565 tensor(-0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9717816891140267 3.6\n","3566 tensor(-0.0176, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.9718099074249127 4.5\n","3567 tensor(-0.0138, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9718380975174877 4.4\n","3568 tensor(-0.0092, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9718662594199703 3.9\n","3569 tensor(-0.0141, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9718943931605503 4.5\n","3570 tensor(-0.0096, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9719224987673898 4.1\n","3571 tensor(-0.0106, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9719505762686224 4.9\n","3572 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 18 0.9719786256923537 5.6\n","3573 tensor(-0.0165, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9720066470666614 5.5\n","3574 tensor(-0.0104, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9720346404195948 5.3\n","3575 tensor(-0.0178, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9720626057791751 5.8\n","3576 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9720905431733959 4.8\n","3577 tensor(-0.0025, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9721184526302226 4.8\n","3578 tensor(-0.0125, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9721463341775923 5.0\n","3579 tensor(-0.0066, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9721741878434148 4.8\n","3580 tensor(-0.0098, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9722020136555714 4.5\n","3581 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9722298116419158 3.7\n","3582 tensor(-0.0166, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9722575818302739 2.0\n","3583 tensor(-0.0156, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9722853242484436 2.2\n","3584 tensor(-0.0097, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9723130389241952 2.6\n","3585 tensor(-0.0141, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.972340725885271 2.6\n","3586 tensor(-0.0091, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9723683851593856 2.6\n","3587 tensor(-0.0057, device='cuda:0', grad_fn=<MeanBackward0>) 17 0.9723960167742263 4.2\n","3588 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.972423620757452 4.3\n","3589 tensor(-0.0096, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9724511971366946 3.8\n","3590 tensor(-0.0155, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.972478745939558 4.1\n","3591 tensor(-0.0085, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9725062671936183 4.3\n","3592 tensor(-0.0145, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9725337609264247 4.2\n","3593 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.9725612271654983 5.2\n","3594 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9725886659383328 5.1\n","3595 tensor(-0.0078, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9726160772723945 5.0\n","3596 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9726434611951221 4.8\n","3597 tensor(-0.0074, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9726708177339269 3.2\n","3598 tensor(-0.0066, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.972698146916193 3.3\n","3599 tensor(-0.0138, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9727254487692768 3.3\n","3600 tensor(-0.0164, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9727527233205076 3.2\n","3601 tensor(-0.0194, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.972779970597187 3.1\n","3602 tensor(-0.0146, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9728071906265898 3.9\n","3603 tensor(-0.0141, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9728343834359633 3.5\n","3604 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9728615490525273 3.2\n","3605 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9728886875034748 2.8\n","3606 tensor(-0.0137, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9729157988159713 2.9\n","3607 tensor(-0.0138, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9729428830171554 3.0\n","3608 tensor(-0.0163, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9729699401341382 2.5\n","3609 tensor(-0.0047, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.972996970194004 2.6\n","3610 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9730239732238101 2.3\n","3611 tensor(-0.0047, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9730509492505862 2.6\n","3612 tensor(-0.0185, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9730778983013356 2.6\n","3613 tensor(-0.0201, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9731048204030344 2.4\n","3614 tensor(-0.0017, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9731317155826312 3.1\n","3615 tensor(-0.0098, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9731585838670487 3.4\n","3616 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9731854252831816 3.3\n","3617 tensor(-0.0011, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9732122398578984 3.4\n","3618 tensor(-0.0136, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.9732390276180405 4.3\n","3619 tensor(-0.0166, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9732657885904225 4.8\n","3620 tensor(-0.0115, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9732925228018321 5.6\n","3621 tensor(-0.0037, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.9733192302790302 6.4\n","3622 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9733459110487512 6.0\n","3623 tensor(-0.0069, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9733725651377024 5.6\n","3624 tensor(-0.0068, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9733991925725647 5.2\n","3625 tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9734257933799921 5.2\n","3626 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9734523675866121 5.3\n","3627 tensor(-0.0118, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9734789152190255 5.4\n","3628 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9735054363038066 5.0\n","3629 tensor(-0.0136, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9735319308675028 4.5\n","3630 tensor(-0.0180, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9735583989366352 4.1\n","3631 tensor(-0.0109, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9735848405376986 3.5\n","3632 tensor(-0.0057, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9736112556971609 3.5\n","3633 tensor(-0.0147, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9736376444414637 3.5\n","3634 tensor(-0.0180, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9736640067970223 3.2\n","3635 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9736903427902253 3.6\n","3636 tensor(-0.0104, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.973716652447435 3.5\n","3637 tensor(-0.0069, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9737429357949876 3.2\n","3638 tensor(-0.0189, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9737691928591926 3.3\n","3639 tensor(-0.0102, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.9737954236663334 4.5\n","3640 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.973821628242667 4.1\n","3641 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.9738478066144244 4.4\n","3642 tensor(-0.0059, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.97387395880781 4.0\n","3643 tensor(-0.0097, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9739000848490021 3.8\n","3644 tensor(-0.0118, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9739261847641532 4.2\n","3645 tensor(-0.0108, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.973952258579389 3.8\n","3646 tensor(-0.0083, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9739783063208096 3.7\n","3647 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9740043280144888 3.8\n","3648 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9740303236864744 3.2\n","3649 tensor(-0.0058, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9740562933627879 2.2\n","3650 tensor(-0.0112, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9740822370694251 2.4\n","3651 tensor(-0.0086, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9741081548323557 1.5\n","3652 tensor(-0.0070, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9741340466775232 1.9\n","3653 tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9741599126308458 2.0\n","3654 tensor(-0.0165, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.974185752718215 2.1\n","3655 tensor(-0.0090, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9742115669654967 2.0\n","3656 tensor(-0.0146, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9742373553985312 2.2\n","3657 tensor(-0.0110, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9742631180431327 2.2\n","3658 tensor(-0.0117, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9742888549250895 2.4\n","3659 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9743145660701644 2.2\n","3660 tensor(-0.0187, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9743402515040943 2.2\n","3661 tensor(-0.0187, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9743659112525902 2.5\n","3662 tensor(-0.0141, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9743915453413377 2.1\n","3663 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9744171537959962 2.1\n","3664 tensor(-0.0088, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9744427366422003 1.8\n","3665 tensor(-0.0040, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9744682939055581 1.6\n","3666 tensor(-0.0147, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9744938256116525 1.5\n","3667 tensor(-0.0175, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.9745193317860409 2.2\n","3668 tensor(-0.0120, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9745448124542548 2.5\n","3669 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9745702676418005 2.8\n","3670 tensor(-0.0014, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9745956973741587 2.7\n","3671 tensor(-0.0096, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9746211016767846 2.9\n","3672 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9746464805751078 3.0\n","3673 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 15 0.9746718340945327 4.4\n","3674 tensor(-0.0169, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9746971622604381 4.4\n","3675 tensor(-0.0141, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9747224650981777 4.6\n","3676 tensor(-0.0209, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9747477426330795 5.1\n","3677 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9747729948904464 4.2\n","3678 tensor(-0.0110, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.974798221895556 3.7\n","3679 tensor(-0.0110, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9748234236736605 3.8\n","3680 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.9748486002499868 5.0\n","3681 tensor(-0.0153, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.9748737516497368 5.6\n","3682 tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.974898877898087 5.6\n","3683 tensor(-0.0055, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.974923979020189 4.5\n","3684 tensor(-0.0072, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9749490550411688 4.4\n","3685 tensor(-0.0180, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.9749741059861277 5.4\n","3686 tensor(-0.0046, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9749991318801415 5.1\n","3687 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9750241327482614 5.3\n","3688 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9750491086155131 5.8\n","3689 tensor(-0.0074, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9750740595068976 5.6\n","3690 tensor(-0.0097, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9750989854473907 4.8\n","3691 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9751238864619434 3.7\n","3692 tensor(-0.0190, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9751487625754813 3.7\n","3693 tensor(-0.0160, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9751736138129059 4.0\n","3694 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.975198440199093 3.9\n","3695 tensor(-0.0072, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9752232417588939 2.7\n","3696 tensor(-0.0070, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.975248018517135 3.2\n","3697 tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9752727704986178 3.6\n","3698 tensor(-0.0202, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9752974977281192 3.6\n","3699 tensor(-0.0200, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9753222002303912 4.0\n","3700 tensor(-0.0147, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9753468780301607 3.9\n","3701 tensor(-0.0093, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.9753715311521306 4.9\n","3702 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9753961596209785 4.8\n","3703 tensor(-0.0092, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9754207634613574 4.8\n","3704 tensor(-0.0111, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9754453426978961 4.9\n","3705 tensor(-0.0171, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9754698973551982 5.2\n","3706 tensor(-0.0145, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.975494427457843 4.4\n","3707 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9755189330303852 3.8\n","3708 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.9755434140973548 4.4\n","3709 tensor(-0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9755678706832575 4.1\n","3710 tensor(-0.0165, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9755923028125741 4.3\n","3711 tensor(-0.0111, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9756167105097616 3.9\n","3712 tensor(-0.0182, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9756410937992518 4.0\n","3713 tensor(-0.0115, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9756654527054526 4.0\n","3714 tensor(-0.0141, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9756897872527471 3.9\n","3715 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9757140974654944 3.6\n","3716 tensor(-0.0020, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9757383833680289 3.9\n","3717 tensor(-0.0055, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9757626449846608 4.1\n","3718 tensor(-0.0146, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9757868823396763 3.1\n","3719 tensor(-0.0153, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9758110954573366 2.7\n","3720 tensor(-0.0166, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9758352843618792 2.7\n","3721 tensor(-0.0088, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9758594490775173 2.5\n","3722 tensor(-0.0106, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9758835896284398 2.5\n","3723 tensor(-0.0108, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.9759077060388114 2.9\n","3724 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9759317983327725 3.0\n","3725 tensor(-0.0190, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9759558665344398 3.5\n","3726 tensor(-0.0197, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9759799106679053 3.4\n","3727 tensor(-0.0123, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9760039307572375 3.5\n","3728 tensor(-0.0193, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9760279268264802 3.6\n","3729 tensor(-0.0071, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9760518988996537 3.8\n","3730 tensor(-0.0145, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.976075847000754 3.4\n","3731 tensor(-0.0114, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9760997711537533 3.5\n","3732 tensor(-0.0170, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9761236713825996 3.6\n","3733 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9761475477112169 2.5\n","3734 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9761714001635058 2.8\n","3735 tensor(-0.0062, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9761952287633422 2.9\n","3736 tensor(-0.0136, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9762190335345788 2.8\n","3737 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9762428145010443 2.6\n","3738 tensor(-0.0067, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9762665716865433 2.5\n","3739 tensor(-0.0136, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9762903051148567 2.4\n","3740 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9763140148097419 2.8\n","3741 tensor(-0.0099, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9763377007949321 2.4\n","3742 tensor(-0.0130, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9763613630941372 2.3\n","3743 tensor(-0.0129, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.976385001731043 2.8\n","3744 tensor(-0.0100, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.976408616729312 2.3\n","3745 tensor(-0.0050, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9764322081125827 1.9\n","3746 tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9764557759044701 2.3\n","3747 tensor(-0.0173, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9764793201285656 2.7\n","3748 tensor(-0.0176, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9765028408084371 2.8\n","3749 tensor(-0.0186, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9765263379676287 3.1\n","3750 tensor(-0.0060, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.976549811629661 3.0\n","3751 tensor(-0.0129, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9765732618180314 2.9\n","3752 tensor(-0.0085, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9765966885562133 2.8\n","3753 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.9766200918676571 3.4\n","3754 tensor(-0.0156, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9766434717757895 3.6\n","3755 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9766668283040136 3.7\n","3756 tensor(-0.0100, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9766901614757096 3.3\n","3757 tensor(-0.0147, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9767134713142339 3.2\n","3758 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9767367578429197 3.4\n","3759 tensor(-0.0157, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9767600210850768 3.1\n","3760 tensor(-0.0151, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9767832610639917 2.8\n","3761 tensor(-0.0074, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9768064778029277 2.8\n","3762 tensor(-0.0134, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9768296713251248 2.9\n","3763 tensor(-0.0165, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9768528416537997 2.4\n","3764 tensor(-0.0123, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9768759888121459 2.2\n","3765 tensor(-0.0042, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9768991128233337 1.9\n","3766 tensor(-0.0171, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9769222137105104 2.3\n","3767 tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9769452914967999 2.0\n","3768 tensor(-0.0125, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.976968346205303 2.6\n","3769 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9769913778590977 2.6\n","3770 tensor(-0.0155, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9770143864812387 2.7\n","3771 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9770373720947574 3.0\n","3772 tensor(-0.0158, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9770603347226626 3.3\n","3773 tensor(-0.0102, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9770832743879401 2.8\n","3774 tensor(-0.0187, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9771061911135521 2.8\n","3775 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9771290849224386 3.0\n","3776 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9771519558375161 2.5\n","3777 tensor(-0.0156, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9771748038816785 2.4\n","3778 tensor(-0.0182, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9771976290777968 1.5\n","3779 tensor(-0.0106, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9772204314487191 1.4\n","3780 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9772432110172704 1.4\n","3781 tensor(-0.0181, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9772659678062531 1.2\n","3782 tensor(-0.0138, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9772887018384468 0.8\n","3783 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9773114131366084 1.3\n","3784 tensor(-0.0207, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9773341017234718 2.0\n","3785 tensor(-0.0133, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9773567676217483 1.8\n","3786 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 22 0.9773794108541266 4.0\n","3787 tensor(-0.0187, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9774020314432724 4.2\n","3788 tensor(-0.0198, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9774246294118292 4.6\n","3789 tensor(-0.0059, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9774472047824173 4.6\n","3790 tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9774697575776349 4.5\n","3791 tensor(-0.0142, device='cuda:0', grad_fn=<MeanBackward0>) 16 0.9774922878200573 6.0\n","3792 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9775147955322372 6.1\n","3793 tensor(-0.0185, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.977537280736705 5.7\n","3794 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9775597434559683 5.3\n","3795 tensor(-0.0141, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9775821837125123 5.4\n","3796 tensor(-0.0116, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9776046015287998 3.7\n","3797 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9776269969272711 3.6\n","3798 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9776493699303437 3.5\n","3799 tensor(-0.0102, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9776717205604134 3.8\n","3800 tensor(-0.0233, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.977694048839853 4.0\n","3801 tensor(-0.0198, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9777163547910132 2.4\n","3802 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9777386384362221 2.5\n","3803 tensor(-0.0193, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9777608997977859 2.4\n","3804 tensor(-0.0138, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9777831388979881 2.3\n","3805 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9778053557590901 3.0\n","3806 tensor(-0.0141, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.977827550403331 2.8\n","3807 tensor(-0.0116, device='cuda:0', grad_fn=<MeanBackward0>) 17 0.9778497228529277 4.4\n","3808 tensor(-0.0136, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9778718731300747 4.1\n","3809 tensor(-0.0083, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.9778940012569447 4.7\n","3810 tensor(-0.0113, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9779161072556878 4.6\n","3811 tensor(-0.0055, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9779381911484321 4.7\n","3812 tensor(-0.0138, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9779602529572836 4.7\n","3813 tensor(-0.0110, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9779822927043264 5.0\n","3814 tensor(-0.0136, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9780043104116221 5.0\n","3815 tensor(-0.0156, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9780263061012104 4.4\n","3816 tensor(-0.0194, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9780482797951092 4.3\n","3817 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.978070231515314 3.0\n","3818 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9780921612837987 2.9\n","3819 tensor(-0.0142, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.978114069122515 2.5\n","3820 tensor(-0.0200, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9781359550533925 2.2\n","3821 tensor(-0.0153, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9781578190983391 2.2\n","3822 tensor(-0.0203, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9781796612792407 2.7\n","3823 tensor(-0.0085, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.9782014816179615 3.4\n","3824 tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9782232801363435 3.3\n","3825 tensor(-0.0107, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9782450568562072 3.5\n","3826 tensor(-0.0115, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9782668117993509 3.4\n","3827 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9782885449875516 3.2\n","3828 tensor(-0.0156, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9783102564425641 3.4\n","3829 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9783319461861215 2.9\n","3830 tensor(-0.0059, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9783536142399354 3.1\n","3831 tensor(-0.0156, device='cuda:0', grad_fn=<MeanBackward0>) 19 0.9783752606256955 4.9\n","3832 tensor(-0.0163, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9783968853650697 4.6\n","3833 tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9784184884797047 3.6\n","3834 tensor(-0.0195, device='cuda:0', grad_fn=<MeanBackward0>) 15 0.978440069991225 5.0\n","3835 tensor(-0.0170, device='cuda:0', grad_fn=<MeanBackward0>) 19 0.9784616299212338 6.5\n","3836 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9784831682913125 6.4\n","3837 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9785046851230212 6.4\n","3838 tensor(-0.0129, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9785261804378982 6.7\n","3839 tensor(-0.0116, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9785476542574603 7.1\n","3840 tensor(-0.0153, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9785691066032028 6.9\n","3841 tensor(-0.0148, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9785905374965996 5.7\n","3842 tensor(-0.0118, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.978611946959103 5.9\n","3843 tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9786333350121439 6.3\n","3844 tensor(-0.0123, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9786547016771318 4.8\n","3845 tensor(-0.0145, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9786760469754546 3.3\n","3846 tensor(-0.0137, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9786973709284792 3.6\n","3847 tensor(-0.0224, device='cuda:0', grad_fn=<MeanBackward0>) 19 0.9787186735575507 5.3\n","3848 tensor(-0.0114, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9787399548839931 5.2\n","3849 tensor(-0.0132, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9787612149291092 4.8\n","3850 tensor(-0.0186, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.97878245371418 4.9\n","3851 tensor(-0.0148, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9788036712604659 4.3\n","3852 tensor(-0.0168, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9788248675892054 3.8\n","3853 tensor(-0.0220, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9788460427216162 3.5\n","3854 tensor(-0.0169, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9788671966788945 3.9\n","3855 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9788883294822157 3.6\n","3856 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9789094411527335 3.3\n","3857 tensor(-0.0157, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9789305317115807 1.7\n","3858 tensor(-0.0093, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9789516011798691 1.3\n","3859 tensor(-0.0058, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9789726495786893 1.5\n","3860 tensor(-0.0096, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9789936769291107 1.5\n","3861 tensor(-0.0212, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9790146832521816 1.6\n","3862 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9790356685689293 2.0\n","3863 tensor(-0.0156, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9790566329003604 2.2\n","3864 tensor(-0.0138, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9790775762674601 2.0\n","3865 tensor(-0.0170, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9790984986911926 2.0\n","3866 tensor(-0.0095, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9791194001925014 2.3\n","3867 tensor(-0.0155, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9791402807923089 2.0\n","3868 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9791611405115166 2.3\n","3869 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.979181979371005 2.8\n","3870 tensor(-0.0168, device='cuda:0', grad_fn=<MeanBackward0>) 11 0.9792027973916341 3.8\n","3871 tensor(-0.0175, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9792235945942425 3.8\n","3872 tensor(-0.0129, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9792443709996482 3.6\n","3873 tensor(-0.0175, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9792651266286485 3.2\n","3874 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9792858615020199 3.0\n","3875 tensor(-0.0157, device='cuda:0', grad_fn=<MeanBackward0>) 14 0.9793065756405178 4.3\n","3876 tensor(-0.0118, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9793272690648773 4.2\n","3877 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9793479417958124 4.5\n","3878 tensor(-0.0177, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9793685938540166 4.4\n","3879 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.9793892252601626 5.0\n","3880 tensor(-0.0153, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9794098360349025 3.9\n","3881 tensor(-0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9794304261988676 4.0\n","3882 tensor(-0.0191, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9794509957726687 3.9\n","3883 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.979471544776896 4.1\n","3884 tensor(-0.0117, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.9794920732321192 5.4\n","3885 tensor(-0.0117, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9795125811588871 4.0\n","3886 tensor(-0.0138, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9795330685777281 3.9\n","3887 tensor(-0.0202, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9795535355091504 4.0\n","3888 tensor(-0.0200, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9795739819736413 3.8\n","3889 tensor(-0.0151, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9795944079916676 2.7\n","3890 tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.979614813583676 3.1\n","3891 tensor(-0.0156, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9796351987700923 3.0\n","3892 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9796555635713222 2.9\n","3893 tensor(-0.0179, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9796759080077508 2.8\n","3894 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9796962320997431 1.8\n","3895 tensor(-0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9797165358676434 2.1\n","3896 tensor(-0.0117, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9797368193317757 2.3\n","3897 tensor(-0.0172, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.979757082512444 2.4\n","3898 tensor(-0.0142, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9797773254299315 2.4\n","3899 tensor(-0.0179, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9797975481045016 2.3\n","3900 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9798177505563971 2.1\n","3901 tensor(-0.0124, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9798379328058406 1.9\n","3902 tensor(-0.0089, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9798580948730349 1.8\n","3903 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9798782367781618 1.8\n","3904 tensor(-0.0164, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9798983585413836 1.6\n","3905 tensor(-0.0161, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9799184601828422 2.0\n","3906 tensor(-0.0214, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9799385417226594 1.7\n","3907 tensor(-0.0191, device='cuda:0', grad_fn=<MeanBackward0>) 14 0.9799586031809367 2.6\n","3908 tensor(-0.0165, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9799786445777559 3.3\n","3909 tensor(-0.0170, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9799986659331781 3.5\n","3910 tensor(-0.0116, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9800186672672448 3.5\n","3911 tensor(-0.0179, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9800386485999777 3.9\n","3912 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9800586099513776 4.0\n","3913 tensor(-0.0194, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9800785513414263 4.3\n","3914 tensor(-0.0141, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.9800984727900849 5.1\n","3915 tensor(-0.0131, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9801183743172948 4.7\n","3916 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9801382559429774 5.1\n","3917 tensor(-0.0106, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9801581176870345 4.3\n","3918 tensor(-0.0158, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9801779595693475 3.6\n","3919 tensor(-0.0141, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9801977816097781 4.1\n","3920 tensor(-0.0133, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9802175838281684 4.2\n","3921 tensor(-0.0199, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9802373662443402 4.4\n","3922 tensor(-0.0116, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9802571288780958 4.3\n","3923 tensor(-0.0148, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9802768717492177 4.1\n","3924 tensor(-0.0101, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9802965948774686 3.2\n","3925 tensor(-0.0142, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.980316298282591 3.2\n","3926 tensor(-0.0188, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9803359819843085 3.2\n","3927 tensor(-0.0096, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9803556460023242 2.7\n","3928 tensor(-0.0116, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9803752903563219 2.9\n","3929 tensor(-0.0099, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9803949150659655 2.5\n","3930 tensor(-0.0162, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9804145201508996 2.3\n","3931 tensor(-0.0097, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9804341056307486 1.7\n","3932 tensor(-0.0110, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9804536715251179 2.3\n","3933 tensor(-0.0104, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9804732178535928 2.1\n","3934 tensor(-0.0190, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9804927446357392 2.3\n","3935 tensor(-0.0135, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9805122518911035 2.1\n","3936 tensor(-0.0109, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9805317396392124 1.7\n","3937 tensor(-0.0167, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9805512078995731 1.9\n","3938 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9805706566916735 1.7\n","3939 tensor(-0.0158, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9805900860349819 2.1\n","3940 tensor(-0.0126, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9806094959489469 2.1\n","3941 tensor(-0.0055, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.980628886452998 2.2\n","3942 tensor(-0.0166, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.980648257566545 1.7\n","3943 tensor(-0.0173, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9806676093089783 1.7\n","3944 tensor(-0.0144, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9806869416996694 1.8\n","3945 tensor(-0.0149, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9807062547579698 2.0\n","3946 tensor(-0.0109, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9807255485032118 2.0\n","3947 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9807448229547086 1.8\n","3948 tensor(-0.0108, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9807640781317538 1.8\n","3949 tensor(-0.0167, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9807833140536221 1.0\n","3950 tensor(-0.0106, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.9808025307395685 1.9\n","3951 tensor(-0.0120, device='cuda:0', grad_fn=<MeanBackward0>) 35 0.980821728208829 5.3\n","3952 tensor(-0.0169, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9808409064806201 5.5\n","3953 tensor(-0.0065, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9808600655741395 6.0\n","3954 tensor(-0.0063, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9808792055085653 5.8\n","3955 tensor(-0.0139, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9808983263030567 5.8\n","3956 tensor(-0.0163, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9809174279767537 6.0\n","3957 tensor(-0.0184, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.980936510548777 6.3\n","3958 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9809555740382282 6.5\n","3959 tensor(-0.0159, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.98097461846419 6.8\n","3960 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9809936438457257 6.1\n","3961 tensor(-0.0116, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.98101265020188 2.7\n","3962 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 9 0.9810316375516781 3.3\n","3963 tensor(-0.0169, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9810506059141265 3.2\n","3964 tensor(-0.0125, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9810695553082124 3.8\n","3965 tensor(-0.0166, device='cuda:0', grad_fn=<MeanBackward0>) 12 0.9810884857529041 4.7\n","3966 tensor(-0.0079, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9811073972671512 4.6\n","3967 tensor(-0.0094, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.981126289869884 4.4\n","3968 tensor(-0.0110, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9811451635800141 4.2\n","3969 tensor(-0.0075, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9811640184164342 4.2\n","3970 tensor(-0.0140, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9811828543980178 3.9\n","3971 tensor(-0.0178, device='cuda:0', grad_fn=<MeanBackward0>) 14 0.9812016715436197 5.2\n","3972 tensor(-0.0080, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9812204698720761 4.5\n","3973 tensor(-0.0138, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9812392494022041 4.7\n","3974 tensor(-0.0143, device='cuda:0', grad_fn=<MeanBackward0>) 5 0.9812580101528018 4.5\n","3975 tensor(-0.0151, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.981276752142649 3.7\n","3976 tensor(-0.0173, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9812954753905063 3.6\n","3977 tensor(-0.0155, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9813141799151158 4.2\n","3978 tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9813328657352007 4.8\n","3979 tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9813515328694655 4.8\n","3980 tensor(-0.0111, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.981370181336596 4.8\n","3981 tensor(-0.0119, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9813888111552594 3.4\n","3982 tensor(-0.0154, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9814074223441043 3.3\n","3983 tensor(-0.0166, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9814260149217602 2.7\n","3984 tensor(-0.0182, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9814445889068384 2.8\n","3985 tensor(-0.0158, device='cuda:0', grad_fn=<MeanBackward0>) 10 0.9814631443179316 3.4\n","3986 tensor(-0.0060, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9814816811736136 3.8\n","3987 tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9815001994924399 3.8\n","3988 tensor(-0.0105, device='cuda:0', grad_fn=<MeanBackward0>) 3 0.9815186992929475 3.5\n","3989 tensor(-0.0153, device='cuda:0', grad_fn=<MeanBackward0>) 2 0.9815371805936546 3.4\n","3990 tensor(-0.0094, device='cuda:0', grad_fn=<MeanBackward0>) 6 0.9815556434130609 4.0\n","3991 tensor(-0.0203, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9815740877696479 4.7\n","3992 tensor(-0.0171, device='cuda:0', grad_fn=<MeanBackward0>) 8 0.9815925136818783 5.4\n","3993 tensor(-0.0174, device='cuda:0', grad_fn=<MeanBackward0>) 0 0.9816109211681964 5.4\n","3994 tensor(-0.0179, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9816293102470282 4.9\n","3995 tensor(-0.0183, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9816476809367811 4.0\n","3996 tensor(-0.0120, device='cuda:0', grad_fn=<MeanBackward0>) 4 0.9816660332558443 4.0\n","3997 tensor(-0.0138, device='cuda:0', grad_fn=<MeanBackward0>) 1 0.9816843672225886 3.3\n","3998 tensor(-0.0162, device='cuda:0', grad_fn=<MeanBackward0>) 7 0.9817026828553659 3.7\n","3999 tensor(-0.0128, device='cuda:0', grad_fn=<MeanBackward0>) 13 0.9817209801725105 4.8\n"]}],"source":["if torch.cuda.is_available():\n","    num_episodes = 600\n","else:\n","    num_episodes = 500\n","    \n","num_episodes = 1000000\n","\n","for i_episode in range(num_episodes):\n","    # if((i_episode + 1) % 25 == 0):\n","    #     with open(\"train_dqn_\" + str(i_episode + 1) + \".pkl\", 'wb') as file:\n","    # # Serialize and write the object to the file\n","    #         pickle.dump(policy_net, file)\n","\n","    # Initialize the environment and get its state\n","    env.reset()\n","    state = get_state(env.state())\n","#     state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n","    tot_rew = 0\n","\n","    for t in count():\n","        # print(t)\n","        action = select_action(state)\n","        # print(action)\n","        # Act according to the action and observe the transition and reward\n","        reward, done = env.act(action)\n","        observation = get_state(env.state())\n","        # if (np.mean(episode_durations[-10:]) >= 25) :\n","            # env.display_state(500)\n","            # env.close_display()\n","        \n","#         observation, reward, done, info, _= env.step(action.item())\n","        # print(rew)\n","\n","        #For mountain car HEREEEE\n","        # state_0 = state[0][0].item()\n","        # reward = 50 if observation[0]>=0.5 else abs(observation[0] - state_0)*100\n","        # print(reward)\n","        \n","        tot_rew += reward\n","        \n","        reward = torch.tensor([reward], device=device)\n","\n","        # try gamma later\n","        \n","        # print(tot_rew)\n","\n","        \n","\n","        if done:\n","            next_state = None\n","        else:\n","            next_state = (observation)\n","\n","#         done = done or info\n","        \n","        # Store the transition in memory\n","        memory.push(state, action, next_state, reward)\n","        # Move to the next state\n","#         print(policy_net.forward(state))\n","        state = next_state\n","\n","        # Perform one step of the optimization (on the policy network)\n","\n","        optimize_model()\n","\n","        # Soft update of the target network's weights\n","        # θ′ ← τ θ + (1 −τ )θ′\n","        target_net_state_dict = target_net.state_dict()\n","        policy_net_state_dict = policy_net.state_dict()\n","        for key in policy_net_state_dict:\n","            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n","        target_net.load_state_dict(target_net_state_dict)\n","\n","        if done:\n","            episode_durations.append(tot_rew)\n","            corr_mult *= 0.999\n","            if i_episode >= 1:# and np.remainder(i_episode,100) == 0:\n","                print(i_episode,call_correlation_coeff_kmeans(),tot_rew,1- corr_mult,np.mean(episode_durations[-10:]))\n","            # plot_durations()\n","#                 print(i_episode, tot_rew)\n","            break\n","    \n","    # if np.mean(episode_durations[-10:]) > 5:\n","    #     break\n","    if(len(episode_durations) >= 4000):\n","        break\n","    \n","env.close_display()\n","# print('Complete')\n","# plot_durations(show_result=True)\n","# plt.ioff()\n","# plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Noisy evaluation"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[],"source":["# num_episodes = 100\n","# episode_durations = []\n","# for i_episode in range(num_episodes):\n","#     # if((i_episode + 1) % 25 == 0):\n","#     #     with open(\"train_dqn_\" + str(i_episode + 1) + \".pkl\", 'wb') as file:\n","#     # # Serialize and write the object to the file\n","#     #         pickle.dump(policy_net, file)\n","\n","#     # Initialize the environment and get its state\n","#     state, info = env.reset()\n","#     state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n","#     tot_rew = 0\n","\n","#     for t in count():\n","#         # print(t)\n","#         state += torch.randn(state.size())*1\n","#         action = select_action(state)\n","#         # print(action)\n","#         observation, reward, done, info, _= env.step(action.item())\n","#         # print(rew)\n","\n","#         #For mountain car HEREEEE\n","#         # state_0 = state[0][0].item()\n","#         # reward = 50 if observation[0]>=0.5 else abs(observation[0] - state_0)*100\n","#         # print(reward)\n","\n","#         tot_rew += reward\n","        \n","#         reward = torch.tensor([reward], device=device)\n","\n","#         # try gamma later\n","        \n","#         # print(tot_rew)\n","\n","        \n","\n","#         if done:\n","#             next_state = None\n","#         else:\n","#             next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n","\n","#         done = done or info\n","        \n","#         # Store the transition in memory\n","# #         memory.push(state, action, next_state, reward)\n","\n","#         # Move to the next state\n","#         state = next_state\n","\n","#         # Perform one step of the optimization (on the policy network)\n","\n","# #         optimize_model()\n","\n","#         # Soft update of the target network's weights\n","#         # θ′ ← τ θ + (1 −τ )θ′\n","# #         target_net_state_dict = target_net.state_dict()\n","# #         policy_net_state_dict = policy_net.state_dict()\n","# #         for key in policy_net_state_dict:\n","# #             target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n","# #         target_net.load_state_dict(target_net_state_dict)\n","\n","#         if done:\n","#             episode_durations.append(tot_rew)\n","# #             if i_episode > 1:# and np.remainder(i_episode,100) == 0:\n","#             print(i_episode,call_correlation_coeff_kmeans(),tot_rew)\n","#             # plot_durations()\n","#             break\n","# print(np.mean(episode_durations))\n","\n","# # print('Complete')\n","# # plot_durations(show_result=True)\n","# # plt.ioff()\n","# # plt.show()"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[],"source":["# import pickle\n","# with open(\"dqn_lr_-4.pkl\", 'wb') as file:\n","#     # Serialize and write the object to the file\n","#     pickle.dump(policy_net, file)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-09-05T15:04:10.520665Z","iopub.status.busy":"2024-09-05T15:04:10.520185Z","iopub.status.idle":"2024-09-05T15:04:10.530274Z","shell.execute_reply":"2024-09-05T15:04:10.528996Z","shell.execute_reply.started":"2024-09-05T15:04:10.520628Z"},"trusted":true},"outputs":[],"source":["# import pickle\n","# with open(\"/kaggle/input/pickle-file/corr_dqn.pkl\", 'rb') as file:\n","#     # Serialize and write the object to the file\n","#     policy_net = pickle.load(file)"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[],"source":["# import pickle\n","# with open(\"dqn.pkl\", 'wb') as file:\n","#     # Serialize and write the object to the file\n","#     pickle.dump(policy_net, file)"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[],"source":["# import pickle\n","# with open(\"dqn_plain.pkl\", 'wb') as file:\n","#     # Serialize and write the object to the file\n","#     pickle.dump(policy_net, file)"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[],"source":["# import pickle\n","# with open(\"dqn_plain.pkl\", 'rb') as file:\n","#     # Serialize and write the object to the file\n","#     policy_net = pickle.load(file)"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[],"source":["# import pickle\n","# with open(\"dqn.pkl\", 'rb') as file:\n","#     # Serialize and write the object to the file\n","#     policy_net = pickle.load(file)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T10:24:42.299480Z","iopub.status.busy":"2024-09-06T10:24:42.298582Z","iopub.status.idle":"2024-09-06T10:24:42.307030Z","shell.execute_reply":"2024-09-06T10:24:42.305413Z","shell.execute_reply.started":"2024-09-06T10:24:42.299444Z"},"trusted":true},"outputs":[],"source":["def phi_wrapper(state, marker = 0):\n","    if(marker == 1): state = state[0]\n","    # print(\"hello\" + str(state.shape))\n","    state = get_state(state)\n","    x = policy_net.forward_correlation((state)).detach().cpu().numpy()\n","    return x #x/np.linalg.norm(x)"]},{"cell_type":"code","execution_count":21,"metadata":{"trusted":true},"outputs":[],"source":["# class phi(nn.Module):\n","\n","#     def __init__(self, dqn):\n","#         super(phi, self).__init__()\n","#         self.layer1 = dqn.layer1\n","#         self.layer2 = dqn.layer2\n","# #         self.layer3 = dqn.layer3\n","#         # self.layer4 = dqn.layer4\n","\n","#         # self.layer3 = nn.Linear(128, n_actions)\n","\n","#     # Called with either one element to determine next action, or a batch\n","#     # during optimization. Returns tensor([[left0exp,right0exp]...]).\n","#     def forward(self, x):         \n","#         x = torch.tensor(x)\n","#         x = F.relu(self.layer1(x))\n","# #         x = F.relu(self.layer2(x))\n","#         # x = F.relu(self.layer3(x))\n","#         # x = F.relu(self.layer4(x))\n","#         # x = F.relu(self.layer2(x))\n","#         return F.relu(self.layer2(x))\n","#     def forward_correlation(self, x):\n","#         x = F.relu(self.layer1(x))\n","# #         x = F.relu(self.layer2(x))\n","# #         x = F.relu(self.layer3(x))\n","#         # x = F.relu(self.layer4(x))\n","#         return F.relu(self.layer2(x))"]},{"cell_type":"code","execution_count":22,"metadata":{"trusted":true},"outputs":[],"source":["# trained_phi = phi(policy_net)\n"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-09-05T10:18:55.068343Z","iopub.status.busy":"2024-09-05T10:18:55.067888Z","iopub.status.idle":"2024-09-05T10:18:55.078214Z","shell.execute_reply":"2024-09-05T10:18:55.077037Z","shell.execute_reply.started":"2024-09-05T10:18:55.068309Z"},"trusted":true},"outputs":[],"source":["# import pickle\n","# with open(\"/kaggle/working/corr_dqn.pkl\", \"wb\") as file:\n","#     pickle.dump(policy_net, file)"]},{"cell_type":"code","execution_count":24,"metadata":{"trusted":true},"outputs":[],"source":["# import pickle\n","# with open(\"trained_phi.pkl\", 'wb') as file:\n","#     # Serialize and write the object to the file\n","#     pickle.dump(trained_phi, file)"]},{"cell_type":"code","execution_count":25,"metadata":{"trusted":true},"outputs":[],"source":["# import pickle\n","# with open(\"/kaggle/working/trained_phi.pkl\", 'rb') as file:\n","#     # Serialize and write the object to the file\n","#     policy_net = pickle.load(file)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T15:48:57.735821Z","iopub.status.busy":"2024-09-06T15:48:57.734997Z","iopub.status.idle":"2024-09-06T15:48:57.745344Z","shell.execute_reply":"2024-09-06T15:48:57.743807Z","shell.execute_reply.started":"2024-09-06T15:48:57.735765Z"},"trusted":true},"outputs":[],"source":["num_features = 128  # Number of features (state dimensions)\n","num_actions = env.num_actions()  # Number of actions\n","weights = np.zeros((num_features, num_actions))\n"]},{"cell_type":"markdown","metadata":{},"source":["# new corrected code for script"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T15:48:57.747780Z","iopub.status.busy":"2024-09-06T15:48:57.747297Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.0 0\n","0.2 0\n","0.7 0\n","0.3 1\n"]},{"name":"stdout","output_type":"stream","text":["0.7 0\n","0.3 0\n","0.2 0\n","0.8 1\n","0.0 0\n","0.3 0\n","0.4 2\n","0.4 1\n","0.3 1\n","0.2 1\n","0.2 1\n","0.7 0\n","1.1 0\n","0.2 0\n","1.1 0\n","0.9 1\n","0.4 0\n","0.5 1\n","0.6 2\n","0.4 0\n","1.2 0\n","0.8 1\n","0.5 1\n","0.7 0\n","0.4 0\n","0.5 0\n","0.7 0\n","1.4 5\n","0.3 1\n","1.2 2\n","1.3 4\n","1.1 0\n","0.8 0\n","0.5 0\n","1.1 0\n","0.9 1\n","1.4 1\n","0.7 2\n","0.8 0\n","0.6 0\n","0.6 1\n","1.1 1\n","1.2 2\n","0.6 0\n","0.5 0\n","0.9 0\n","0.3 0\n","0.6 0\n","0.6 0\n","0.6 1\n","1.2 1\n","1.0 4\n","0.8 0\n","0.7 1\n","1.1 0\n","0.4 0\n","0.8 1\n","1.4 1\n","0.7 0\n","1.1 0\n","0.6 0\n","1.3 1\n","0.8 1\n","1.7 2\n","1.6 0\n","0.4 1\n","1.0 0\n","0.4 1\n","0.7 0\n","1.6 1\n","1.0 1\n","1.7 2\n","1.0 0\n","0.7 0\n","0.5 2\n","0.5 0\n","1.0 1\n","1.1 0\n","0.5 0\n","1.5 2\n","1.2 0\n","0.8 0\n","0.8 1\n","0.5 0\n","1.2 2\n","1.6 4\n","1.0 1\n","0.5 3\n","1.0 1\n","0.6 0\n","1.2 5\n","2.4 0\n","1.9 0\n","1.2 1\n","1.1 0\n","0.9 0\n","1.2 4\n","1.0 1\n","0.8 0\n","1.7 4\n","1.4 0\n","0.3 0\n","1.4 2\n","0.9 0\n","1.0 1\n","0.7 0\n","1.7 2\n","1.4 0\n","0.9 4\n","0.7 0\n","1.5 0\n","0.6 2\n","0.7 1\n","1.0 0\n","0.9 0\n","0.3 1\n","1.2 2\n","1.0 0\n","1.3 6\n","0.7 0\n","1.0 0\n","1.5 2\n","0.7 0\n","0.8 0\n","1.7 2\n","1.2 2\n","1.1 2\n","1.3 4\n","1.3 3\n","0.9 0\n","1.1 0\n","0.8 1\n","1.0 1\n","1.2 0\n","1.4 1\n","1.0 2\n","0.6 1\n","1.6 0\n","0.8 0\n","0.7 2\n","1.5 11\n","0.5 0\n","1.3 2\n","1.1 0\n","1.4 0\n","1.1 0\n","1.7 2\n","0.9 1\n","1.5 1\n","1.5 1\n","0.6 2\n","0.9 2\n","0.8 0\n","0.5 0\n","0.4 1\n","1.8 3\n","1.4 2\n","1.4 5\n","0.9 0\n","1.8 3\n","1.6 1\n","1.2 2\n","1.7 1\n","1.1 0\n","1.2 3\n","1.7 0\n","1.5 3\n","1.3 2\n","1.7 0\n","0.8 0\n","1.2 2\n","1.7 1\n","0.9 0\n","1.2 1\n","1.5 0\n","1.4 0\n","1.6 0\n","0.4 1\n","1.7 3\n","1.2 4\n","0.9 0\n","0.6 1\n","1.7 6\n","1.6 0\n","1.3 0\n","1.0 3\n","1.3 0\n","2.1 0\n","2.5 0\n","2.4 2\n","1.8 6\n","1.6 2\n","1.9 2\n","1.4 0\n","2.4 1\n","2.1 0\n","1.2 2\n","1.0 0\n","1.4 1\n","1.8 1\n","1.7 2\n","1.3 0\n","2.7 5\n","1.1 0\n","2.9 1\n","1.2 0\n","1.1 3\n","0.5 0\n","2.4 5\n","1.6 0\n","1.9 4\n","2.1 5\n","2.3 4\n","1.9 6\n","0.8 0\n","1.1 0\n","2.0 4\n","1.6 4\n","2.0 0\n","1.1 1\n","1.7 0\n","1.7 5\n","1.2 2\n","2.0 3\n","2.2 0\n","0.5 0\n","1.6 0\n","1.5 0\n","0.9 0\n","2.2 3\n","1.9 0\n","1.8 2\n","1.4 0\n","2.1 0\n","1.4 0\n","1.4 0\n","1.1 3\n","2.0 2\n","1.3 3\n","1.5 0\n","2.5 5\n","2.6 4\n","2.1 0\n","1.5 1\n","1.4 2\n","1.9 1\n","1.2 0\n","1.1 0\n","0.9 2\n","2.7 4\n","0.9 0\n","2.7 1\n","0.5 2\n","1.8 4\n","1.5 4\n","0.8 0\n","1.8 1\n","1.3 3\n","1.7 0\n","1.5 1\n","1.5 2\n","2.1 0\n","1.9 0\n","1.2 0\n","1.9 1\n","2.2 0\n","4.7 3\n","2.1 4\n","1.3 0\n","2.7 7\n","1.5 0\n","0.9 0\n","1.2 1\n","1.3 0\n","1.8 1\n","1.4 0\n","1.3 0\n","3.2 0\n","2.2 5\n","1.2 2\n","1.2 6\n","2.4 3\n","2.0 3\n","2.0 4\n","2.2 2\n","2.8 1\n","1.2 3\n","2.4 0\n","2.6 2\n","1.6 0\n","2.5 0\n","2.0 0\n","1.8 2\n","1.5 1\n","1.4 3\n","1.4 2\n","1.8 0\n","1.9 1\n","2.8 7\n","3.2 9\n","3.3 1\n","1.2 0\n","1.1 0\n","2.0 4\n","3.2 4\n","2.5 6\n","3.1 0\n","1.7 6\n","1.6 0\n","0.9 1\n","3.0 3\n","0.9 0\n","2.5 3\n","1.7 4\n","2.6 1\n","2.0 3\n","4.1 1\n","1.7 2\n","1.6 3\n","3.1 9\n","1.4 0\n","2.1 4\n","1.6 0\n","2.0 1\n","3.1 0\n","1.7 2\n","2.6 2\n","2.0 0\n","2.5 9\n","3.2 11\n","2.1 0\n","3.2 4\n","1.8 4\n","2.1 0\n","3.5 2\n","1.1 1\n","2.6 7\n","3.8 5\n","3.0 8\n","2.1 1\n","1.2 0\n","2.1 0\n","1.4 0\n","3.5 1\n","2.2 3\n","3.2 1\n","1.4 2\n","1.4 3\n","1.4 2\n","1.3 1\n","3.8 1\n","3.4 2\n","exit at 0 3552\n","0.0 0\n","0.7 0\n","0.4 0\n","0.3 1\n","0.4 0\n","0.3 0\n","0.8 1\n","0.6 0\n","1.0 0\n","0.5 0\n","0.5 1\n","0.6 0\n","0.7 0\n","0.6 0\n","0.8 0\n","0.7 1\n","1.0 0\n","0.3 0\n","0.6 3\n","0.6 1\n","0.9 0\n","1.0 0\n","0.4 2\n","1.2 0\n","1.0 2\n","0.6 1\n","0.6 0\n","0.7 2\n","0.9 1\n","1.7 0\n","1.4 1\n","0.4 0\n","0.9 2\n","0.7 0\n","1.1 1\n","0.3 0\n","0.9 0\n","0.8 0\n","0.5 0\n","1.2 1\n","0.4 1\n","1.1 0\n","0.9 1\n","0.4 0\n","1.1 2\n","1.2 3\n","1.6 0\n","0.5 2\n","0.4 1\n","1.0 1\n","1.4 0\n","0.8 0\n","1.0 1\n","1.6 1\n","1.2 0\n","0.8 1\n","1.8 3\n","1.8 0\n","1.0 0\n","0.3 1\n","1.3 0\n","0.6 0\n","1.2 0\n","0.8 0\n","1.4 2\n","1.5 0\n","1.3 0\n","1.0 2\n","1.3 0\n","0.7 1\n","0.4 1\n","2.2 4\n","1.4 0\n","0.9 0\n","0.4 0\n","0.6 3\n","1.6 1\n","0.8 0\n","1.6 1\n","0.9 0\n","0.8 1\n","0.9 5\n","1.3 0\n","1.1 2\n","1.7 1\n","0.7 1\n","0.5 0\n","1.7 1\n","0.9 1\n","1.8 0\n","1.6 0\n","1.4 1\n","1.7 4\n","0.9 0\n","1.2 1\n","1.5 2\n","1.2 0\n","1.3 1\n","1.0 5\n","1.3 0\n","2.4 4\n","1.1 4\n","1.2 2\n","1.3 2\n","0.5 0\n","2.0 0\n","1.1 2\n","0.4 0\n","0.8 5\n","0.3 0\n","1.2 0\n","1.2 1\n","1.0 0\n","0.9 0\n","1.5 4\n","0.8 0\n","1.0 0\n","0.7 0\n","2.0 3\n","0.7 1\n","0.7 1\n","1.8 0\n","1.1 0\n","2.1 4\n","1.5 4\n","3.0 4\n","2.2 0\n","2.3 7\n","2.3 4\n","0.8 0\n","2.7 0\n","1.3 1\n","1.2 2\n","1.2 0\n","1.5 2\n","0.5 0\n","0.6 0\n","1.4 4\n","1.7 1\n","0.7 0\n","1.6 3\n","0.7 0\n","0.5 1\n","0.7 3\n","1.9 1\n","1.2 0\n","1.8 1\n","1.5 0\n","0.9 4\n","1.1 0\n","2.8 1\n","1.7 0\n","0.9 1\n","2.3 4\n","1.4 1\n","1.6 2\n","2.4 4\n","1.7 1\n","1.7 1\n","0.4 1\n","1.3 2\n","1.8 0\n","0.5 0\n","1.2 0\n","2.1 1\n","3.1 4\n","1.0 1\n","1.1 2\n","1.4 1\n","1.3 1\n","1.1 1\n","2.5 10\n","2.0 1\n","2.1 1\n","2.1 4\n","0.8 0\n","2.1 0\n","1.2 4\n","2.1 3\n","1.9 3\n","0.8 0\n","1.8 0\n","1.2 0\n","1.4 0\n","1.4 2\n","2.0 2\n","0.9 1\n","2.0 3\n","0.6 2\n","1.8 0\n","1.1 0\n","1.3 0\n","2.3 0\n","1.0 0\n","1.5 6\n","1.4 4\n","1.6 2\n","1.6 3\n","1.7 0\n","1.6 5\n","2.4 0\n","1.5 1\n","2.6 3\n","2.1 2\n","0.8 2\n","1.6 2\n","0.6 2\n","1.1 1\n","1.7 0\n","2.8 0\n","1.5 0\n","1.5 0\n","2.1 0\n","2.3 0\n","2.7 2\n","1.6 1\n","2.7 5\n","1.0 0\n","1.5 1\n","1.2 0\n","2.7 1\n","2.8 9\n","3.1 6\n","1.8 1\n","1.5 0\n","2.4 3\n","0.9 0\n","2.5 0\n","2.0 8\n","2.2 3\n","1.2 0\n","1.0 0\n","1.0 1\n","1.4 0\n","1.6 3\n","1.2 0\n","3.0 5\n","1.3 0\n","1.4 1\n","1.2 1\n","1.4 1\n","1.5 3\n","1.9 0\n","3.1 8\n","1.6 1\n","1.6 0\n","1.8 0\n","2.3 4\n","1.2 0\n","2.3 4\n","2.0 2\n","2.6 3\n","1.5 0\n","1.8 11\n","2.7 9\n","1.9 5\n","1.7 2\n","3.3 3\n","2.5 5\n","3.4 4\n","2.2 4\n","0.7 0\n","1.9 7\n","2.2 0\n","1.5 0\n","1.9 2\n","2.2 1\n","0.7 0\n","2.1 3\n","2.7 9\n","1.4 1\n","0.6 2\n","1.9 2\n","2.3 0\n","2.5 9\n","3.9 2\n","1.7 5\n","1.7 2\n","3.7 2\n","1.8 0\n","1.2 0\n","3.5 3\n","3.0 4\n","1.9 0\n","1.3 3\n","2.7 0\n","2.4 4\n","3.4 13\n","2.1 1\n","1.7 1\n","2.2 1\n","2.3 0\n","1.9 1\n","0.9 0\n","1.1 1\n","0.7 2\n","2.3 0\n","1.6 2\n","2.1 2\n","1.5 1\n","2.0 1\n","1.6 0\n","2.7 0\n","4.1 10\n","1.0 2\n","1.9 2\n","1.7 3\n","1.2 1\n","2.0 0\n","1.8 4\n","2.6 1\n","3.0 2\n","1.6 2\n","1.0 1\n","0.5 0\n","1.6 8\n","2.2 7\n","1.2 0\n","3.0 4\n","0.9 0\n","1.8 3\n","2.0 0\n","2.0 1\n","1.9 2\n","1.1 3\n","2.5 4\n","1.9 1\n","1.9 3\n","3.8 2\n","2.6 2\n","2.5 1\n","1.9 0\n","2.6 1\n","1.7 3\n","1.9 2\n","1.4 4\n","1.7 0\n","1.4 3\n","3.7 9\n","2.7 1\n","1.6 0\n","2.6 7\n","2.1 0\n","1.6 4\n","2.6 2\n","1.6 0\n","2.1 11\n","0.9 2\n","0.7 0\n","5.0 12\n","1.7 1\n","2.2 2\n","2.0 1\n","1.0 3\n","1.0 0\n","1.4 1\n","2.9 1\n","2.2 1\n","2.0 1\n","2.1 1\n","2.5 3\n","3.5 6\n","exit at 1 3611\n","0.0 0\n","0.7 0\n","0.3 0\n","0.8 0\n","0.2 0\n","0.3 0\n","0.1 1\n","0.4 1\n","0.8 3\n","0.8 3\n","0.6 0\n","0.6 0\n","0.7 1\n","1.0 1\n","0.4 0\n","0.8 1\n","0.7 0\n","0.4 1\n","0.2 0\n","0.9 1\n","0.4 0\n","0.4 0\n","0.6 3\n","0.6 1\n","0.4 2\n","1.0 0\n","0.6 0\n","0.4 2\n","0.8 1\n","0.7 1\n","0.8 1\n","0.4 1\n","0.4 1\n","0.9 1\n","0.6 0\n","0.6 1\n","0.8 0\n","1.0 1\n","1.0 2\n","0.7 3\n","1.0 2\n","0.4 0\n","0.7 0\n","0.7 0\n","1.1 0\n","0.7 0\n","0.9 1\n","0.6 0\n","0.3 0\n","1.2 2\n","0.6 0\n","0.5 1\n","0.8 0\n","0.5 1\n","1.2 0\n","1.2 2\n","0.7 0\n","1.2 0\n","0.8 0\n","1.0 0\n","0.9 2\n","0.2 0\n","0.8 0\n","0.3 1\n","1.0 0\n","1.0 5\n","0.7 0\n","1.5 2\n","1.1 3\n","1.2 3\n","0.5 0\n","0.7 3\n","1.3 0\n","1.4 1\n","0.8 3\n","0.7 1\n","0.7 1\n","0.7 1\n","1.5 2\n","1.0 1\n","0.7 1\n","1.7 1\n","0.8 1\n","1.0 0\n","1.4 0\n","1.5 1\n","0.6 0\n","0.6 3\n","1.1 0\n","0.9 2\n","0.5 0\n","0.6 0\n","1.1 1\n","1.3 2\n","1.2 1\n","1.1 1\n","0.6 0\n","0.7 2\n","1.8 5\n","1.6 5\n","0.9 1\n","0.8 0\n","1.3 3\n","2.2 2\n","1.1 0\n","1.1 0\n","1.7 1\n","1.0 0\n","1.2 1\n","2.0 0\n","1.3 3\n","1.3 2\n","1.5 0\n","0.7 1\n","0.7 0\n","1.3 0\n","1.0 2\n","1.6 1\n","2.1 5\n","1.7 1\n","1.3 0\n","1.9 0\n","2.4 0\n","2.1 0\n","2.3 8\n","1.1 1\n","0.8 0\n","1.9 3\n","0.7 0\n","1.1 1\n","2.2 1\n","1.1 3\n","1.0 0\n","0.5 0\n","1.7 0\n","2.1 4\n","1.1 1\n","0.9 0\n","1.6 2\n","0.8 1\n","1.7 5\n","1.4 2\n","0.8 0\n","0.5 0\n","1.5 0\n","1.7 1\n","1.2 1\n","1.0 2\n","1.5 4\n","0.8 0\n","1.5 1\n","1.6 0\n","1.7 6\n","3.9 1\n","1.2 2\n","0.7 1\n","1.2 1\n","1.0 1\n","2.1 0\n","2.3 1\n","0.8 1\n","1.2 3\n","1.5 0\n","1.6 2\n","1.1 4\n","1.9 0\n","2.5 1\n","0.9 3\n","2.4 0\n","0.8 0\n","1.4 2\n","2.3 4\n","0.8 3\n","2.1 11\n","1.8 3\n","0.9 0\n","1.3 2\n","1.1 1\n","1.9 3\n","1.3 0\n","1.8 5\n","2.0 2\n","3.8 0\n","1.1 1\n","1.6 2\n","1.8 1\n","1.3 1\n","1.7 0\n","2.3 5\n","2.6 3\n","1.6 5\n","1.2 1\n","2.0 1\n","1.0 0\n","1.5 0\n","0.8 0\n","1.1 3\n","2.2 2\n","3.5 3\n","2.5 3\n","1.6 0\n","2.2 1\n","1.3 2\n","1.6 2\n","1.5 1\n","1.8 1\n","1.6 5\n","3.0 10\n","1.7 5\n","1.8 1\n","1.3 0\n","1.4 1\n","1.2 0\n","0.6 0\n","1.7 0\n","1.8 0\n","2.5 4\n","2.0 6\n","1.4 2\n","1.9 1\n","1.5 0\n","2.2 4\n","2.1 5\n","1.4 1\n","1.3 8\n","2.4 2\n","2.5 1\n","1.7 3\n","1.8 1\n","1.1 1\n","2.7 1\n","2.2 0\n","1.4 3\n","2.6 2\n","2.4 2\n","2.6 0\n","2.3 4\n","3.0 1\n","1.9 0\n","1.2 0\n","1.0 0\n","1.2 4\n","2.8 8\n","3.4 3\n","2.4 9\n","3.6 1\n","1.6 2\n","1.9 0\n","4.0 4\n","exit at 2 2482\n","4.0 4\n","0.4 0\n","0.8 1\n","0.3 0\n","0.6 2\n","0.5 0\n","0.7 1\n","0.7 1\n","0.2 0\n","0.5 0\n","0.2 1\n","0.8 0\n","0.5 0\n","0.4 1\n","0.5 0\n","0.3 0\n","0.3 1\n","0.4 0\n","0.7 0\n","0.5 0\n","0.5 0\n","0.1 0\n","0.6 1\n","0.8 0\n","0.9 0\n","0.8 0\n","0.4 2\n","0.6 2\n","0.5 0\n","0.6 0\n","1.0 0\n","0.3 0\n","0.3 0\n","0.3 0\n","0.7 0\n","0.6 0\n","0.4 0\n","0.6 0\n","0.8 1\n","0.2 0\n","0.2 0\n","0.1 0\n","0.8 2\n","0.5 4\n","1.0 0\n","0.5 0\n","0.8 5\n","0.3 0\n","0.3 2\n","0.7 0\n","0.9 1\n","0.7 0\n","0.4 0\n","0.5 1\n","1.8 2\n","0.5 0\n","1.2 1\n","1.0 0\n","0.9 2\n","0.4 1\n","1.1 1\n","0.9 0\n","1.0 0\n","0.9 0\n","1.5 7\n","0.8 0\n","1.8 0\n","0.5 0\n","0.3 0\n","0.3 1\n","0.8 0\n","0.9 1\n","0.8 0\n","1.8 3\n","0.8 0\n","0.7 0\n","1.5 3\n","1.0 1\n","1.3 0\n","1.0 4\n","0.9 0\n","1.2 0\n","0.2 0\n","0.8 2\n","1.7 2\n","0.5 1\n","1.1 2\n","1.1 2\n","0.9 0\n","1.0 0\n","1.4 3\n","0.6 0\n","0.5 0\n","1.4 0\n","1.6 3\n","0.4 0\n","0.7 1\n","0.9 1\n","0.5 0\n","0.9 1\n","0.5 1\n","0.7 1\n","1.6 1\n","2.2 1\n","1.4 1\n","0.8 0\n","1.1 2\n","0.9 0\n","1.3 2\n","1.0 0\n","0.8 1\n","0.7 2\n","1.0 0\n","0.6 0\n","0.6 3\n","1.2 1\n","1.2 1\n","2.0 0\n","1.3 1\n","1.1 2\n","0.2 0\n","1.9 4\n","1.1 0\n","1.4 6\n","0.2 0\n","1.6 1\n","1.1 2\n","0.9 2\n","1.6 2\n","0.8 2\n","1.4 0\n","1.2 2\n","1.6 2\n","0.7 0\n","1.4 0\n","1.6 6\n","1.1 4\n","1.2 1\n","1.1 2\n","0.7 3\n","2.5 0\n","1.4 2\n","2.5 3\n","1.0 1\n","1.3 1\n","1.1 1\n","0.8 0\n","1.5 0\n","1.9 2\n","1.6 0\n","1.7 1\n","1.7 0\n","2.1 1\n","1.4 5\n","1.4 2\n","1.1 0\n","0.9 1\n","1.9 0\n","0.7 1\n","1.3 6\n","1.6 2\n","1.2 0\n","2.8 2\n","1.5 1\n","2.7 1\n","1.3 2\n","1.3 0\n","1.2 0\n","1.4 0\n","1.6 3\n","2.3 7\n","2.3 2\n","2.1 1\n","2.0 2\n","1.8 5\n","1.2 3\n","1.5 1\n","2.7 3\n","1.4 2\n","2.0 1\n","0.9 3\n","2.0 0\n","1.5 0\n","1.6 0\n","1.3 2\n","3.4 0\n","2.1 9\n","1.1 0\n","2.1 3\n","2.9 3\n","2.0 0\n","0.8 0\n","2.1 5\n","1.4 5\n","1.1 4\n","1.2 0\n","1.5 0\n","1.6 0\n","2.0 0\n","1.8 6\n","0.5 0\n","2.1 9\n","1.6 0\n","3.1 1\n","1.9 2\n","2.2 1\n","1.2 3\n","2.9 1\n","3.0 1\n","2.3 1\n","2.1 1\n","1.4 1\n","1.0 0\n","2.6 4\n","1.4 2\n","1.2 4\n","1.9 0\n","2.7 2\n","3.2 2\n","1.3 0\n","2.8 2\n","1.6 2\n","0.6 0\n","2.6 0\n","2.1 4\n","1.2 0\n","4.0 4\n","3.3 2\n","1.1 2\n","2.2 2\n","1.5 1\n","2.6 3\n","1.4 0\n","3.2 1\n","2.2 2\n","2.5 8\n","2.7 1\n","1.6 6\n","1.0 2\n","2.2 0\n","2.1 8\n","2.5 0\n","2.4 1\n","2.6 0\n","3.3 0\n","1.0 1\n","2.9 1\n","1.7 5\n","2.7 2\n","2.3 1\n","0.8 0\n","1.3 1\n","2.8 6\n","1.6 3\n","2.0 8\n","2.2 1\n","1.8 1\n","1.6 7\n","1.2 3\n","2.0 7\n","1.4 1\n","1.4 3\n","2.3 1\n","1.5 10\n","1.7 1\n","1.0 4\n","2.6 0\n","1.6 1\n","2.8 0\n","2.9 4\n","1.5 0\n","1.7 0\n","2.4 2\n","1.6 1\n","1.9 3\n","2.1 1\n","1.8 6\n","0.9 1\n","0.5 0\n","1.5 0\n","2.9 0\n","1.9 1\n","2.2 3\n","0.8 0\n","4.4 3\n","1.6 2\n","1.3 0\n","3.0 3\n","1.8 2\n","1.7 7\n","2.7 5\n","1.9 2\n","3.3 0\n","1.8 4\n","2.9 0\n","2.2 6\n","1.2 1\n","1.3 0\n","2.4 0\n","2.0 3\n","2.6 0\n","0.4 0\n","1.5 1\n","1.8 0\n","2.0 1\n","2.9 4\n","2.2 2\n","3.2 10\n","3.1 1\n","2.9 1\n","1.9 0\n","1.0 0\n","2.2 2\n","1.4 1\n","2.0 1\n","1.6 6\n","2.3 0\n","1.9 0\n","1.6 1\n","1.7 1\n","1.2 4\n","2.4 2\n","3.3 2\n","2.7 3\n","1.5 1\n","1.5 1\n","1.6 0\n","2.6 3\n","1.6 0\n","2.7 1\n","1.8 3\n","1.5 1\n","2.7 0\n","2.9 2\n","1.5 1\n","2.5 5\n","2.2 0\n","2.1 2\n","2.1 0\n","2.6 4\n","3.2 3\n","2.8 7\n","2.9 4\n","1.4 0\n","0.7 0\n","2.3 5\n","2.7 1\n","1.4 0\n","1.4 2\n","3.5 3\n","3.5 2\n","3.6 0\n","1.9 3\n","1.4 3\n","0.9 1\n","1.8 2\n","3.0 2\n","3.4 5\n","1.8 0\n","1.7 1\n","2.4 1\n","1.0 0\n","3.3 11\n","1.4 1\n","2.1 1\n","1.7 1\n","1.8 2\n","1.8 0\n","1.9 0\n","2.9 4\n","3.5 2\n","1.9 3\n","2.8 6\n","1.1 0\n","1.4 1\n","1.5 2\n","2.5 0\n","1.3 2\n","2.5 3\n","1.7 4\n","3.0 0\n","3.1 13\n","1.8 1\n","1.6 1\n","2.3 6\n","3.6 11\n","2.3 1\n","1.9 0\n","1.4 0\n","2.2 0\n","2.2 5\n","2.7 1\n","1.7 1\n","1.7 3\n","2.5 6\n","0.6 0\n","1.6 1\n","1.0 1\n","1.6 0\n","2.5 2\n","2.7 0\n","1.6 1\n","3.3 6\n","2.5 5\n","3.0 2\n","3.7 1\n","2.6 2\n","1.1 0\n","1.6 0\n","1.9 3\n","2.4 2\n","3.4 3\n","3.4 0\n","3.3 2\n","2.9 5\n","2.0 0\n","1.6 0\n","1.7 0\n","1.1 1\n","3.0 4\n","exit at 3 4194\n","0.0 0\n","0.8 1\n","0.5 1\n","0.4 0\n","0.6 0\n","0.3 0\n","0.7 0\n","0.9 0\n","0.6 0\n","0.7 0\n","0.7 2\n","0.6 1\n","0.4 0\n","0.3 0\n","0.8 2\n","0.5 0\n","0.4 2\n","0.1 0\n","0.3 0\n","0.8 1\n","0.8 0\n","0.3 0\n","0.3 0\n","0.8 2\n","0.4 0\n","0.8 0\n","0.4 1\n","0.5 0\n","0.9 0\n","0.8 2\n","0.8 0\n","0.7 0\n","0.9 1\n","1.0 1\n","0.4 1\n","0.9 2\n","0.9 1\n","0.9 1\n","1.0 3\n","1.1 0\n","0.5 0\n","0.2 0\n","0.9 3\n","0.5 0\n","0.9 1\n","0.7 1\n","0.3 2\n","0.9 3\n","0.8 0\n","0.5 0\n","0.1 0\n","0.5 1\n","0.7 1\n","0.3 1\n","1.1 2\n","0.1 0\n","1.1 1\n","0.8 1\n","0.4 0\n","1.1 2\n","0.8 1\n","0.3 1\n","1.5 5\n","1.2 5\n","0.6 0\n","1.0 0\n","1.9 0\n","1.1 0\n","0.8 1\n","0.8 0\n","0.5 0\n","0.7 1\n","0.5 0\n","0.4 1\n","0.6 0\n","1.2 1\n","1.2 0\n","0.6 0\n","0.9 0\n","0.8 1\n","0.8 1\n","0.4 0\n","0.9 0\n","1.4 3\n","0.9 1\n","0.5 1\n","1.5 0\n","0.7 0\n","1.1 1\n","1.8 0\n","0.9 1\n","0.9 0\n","0.5 0\n","0.5 0\n","1.0 1\n","1.3 3\n","1.2 0\n","1.6 2\n","1.0 2\n","0.7 0\n","0.7 1\n","0.4 0\n","0.5 0\n","1.9 0\n","0.8 1\n","0.7 1\n","1.2 2\n","0.8 1\n","0.8 3\n","0.6 0\n","1.1 0\n","0.7 0\n","1.0 1\n","0.7 0\n","1.6 6\n","0.7 2\n","0.7 3\n","1.2 2\n","0.7 0\n","1.3 1\n","0.9 1\n","0.9 0\n","1.0 0\n","0.3 0\n","0.6 0\n","1.2 0\n","0.8 1\n","1.3 0\n","1.1 2\n","0.6 0\n","1.4 0\n","0.3 0\n","0.6 0\n","1.1 3\n","1.6 1\n","0.7 0\n","1.2 1\n","1.0 0\n","0.8 1\n","0.7 0\n","1.1 0\n","1.5 0\n","0.7 4\n","1.3 1\n","0.7 0\n","1.5 1\n","1.0 4\n","0.4 1\n","1.7 1\n","1.1 0\n","1.3 0\n","0.6 0\n","0.6 0\n","1.3 0\n","0.4 0\n","1.2 1\n","1.3 2\n","0.9 0\n","0.5 1\n","2.2 9\n","1.3 1\n","1.4 3\n","1.8 0\n","1.5 3\n","1.4 0\n","1.7 1\n","1.9 0\n","0.7 1\n","2.0 3\n","1.3 1\n","2.4 4\n","2.0 0\n","0.9 0\n","1.5 2\n","1.5 0\n","1.2 0\n","1.4 2\n","1.1 3\n","0.8 0\n","2.0 0\n","1.6 4\n","1.8 0\n","1.5 1\n","1.9 0\n","1.1 0\n","1.8 6\n","1.4 1\n","1.6 1\n","0.5 1\n","0.5 0\n","1.8 1\n","2.0 0\n","1.2 2\n","2.0 3\n","0.7 0\n","0.7 0\n","2.3 4\n","2.3 1\n","1.1 0\n","0.2 0\n","2.0 3\n","1.3 4\n","0.9 0\n","2.1 3\n","0.9 2\n","1.3 0\n","2.2 0\n","1.5 1\n","1.4 0\n","1.3 2\n","1.8 4\n","2.5 2\n","0.6 2\n","1.8 0\n","0.6 0\n","1.4 4\n","1.9 1\n","1.2 0\n","1.0 0\n","1.2 0\n","2.2 0\n","1.1 0\n","0.9 1\n","0.9 0\n","2.1 4\n","2.2 6\n","1.5 0\n","1.8 4\n","1.2 0\n","2.0 3\n","2.1 6\n","2.0 0\n","3.0 4\n","0.7 1\n","1.2 0\n","1.9 0\n","2.4 1\n","2.3 5\n","1.1 3\n","0.9 0\n","3.6 5\n","1.4 1\n","1.8 0\n","1.7 4\n","2.8 1\n","1.6 0\n","1.9 0\n","1.6 5\n","3.1 3\n","2.4 1\n","1.1 4\n","1.8 0\n","1.4 2\n","1.3 1\n","0.7 1\n","0.9 2\n","3.0 18\n","1.5 4\n","0.8 0\n","1.6 0\n","0.3 1\n","2.4 2\n","1.5 1\n","3.0 1\n","1.8 3\n","2.0 2\n","2.4 3\n","2.2 2\n","3.0 1\n","1.0 1\n","2.8 0\n","1.8 0\n","0.9 1\n","2.7 0\n","1.0 0\n","2.3 2\n","1.0 3\n","2.1 1\n","2.4 1\n","2.7 5\n","1.5 4\n","0.8 1\n","1.7 2\n","2.3 11\n","1.5 9\n","1.2 0\n","2.6 3\n","1.2 0\n","1.9 0\n","2.8 7\n","1.0 0\n","0.7 0\n","1.9 1\n","2.0 3\n","1.9 2\n","1.8 0\n","1.4 2\n","2.0 6\n","1.1 1\n","2.8 2\n","2.2 1\n","2.0 9\n","2.9 4\n","1.8 0\n","1.3 2\n","2.0 1\n","2.8 2\n","1.7 0\n","2.7 4\n","2.5 2\n","2.0 3\n","3.3 4\n","1.6 1\n","3.0 0\n","1.7 2\n","3.0 1\n","1.8 0\n","2.9 0\n","1.3 3\n","1.9 3\n","2.8 0\n","1.6 0\n","1.9 5\n","2.3 3\n","2.8 0\n","2.1 8\n","exit at 4 3254\n","1.0 1\n","0.4 1\n","0.4 0\n","0.6 0\n","0.2 1\n","0.2 0\n","0.2 0\n","0.9 0\n","0.3 0\n","0.4 0\n","0.7 4\n","0.1 0\n","0.3 0\n","0.6 3\n","1.2 0\n","0.2 0\n","0.6 0\n","0.2 0\n","0.8 0\n","0.6 0\n","0.5 0\n","0.8 2\n","0.5 0\n","0.7 1\n","0.8 4\n","0.2 0\n","0.6 1\n","0.8 0\n","0.8 1\n","0.9 0\n","0.5 0\n","0.7 1\n","0.6 1\n","0.7 0\n","0.4 0\n","0.3 1\n","1.0 3\n","0.4 0\n","0.9 0\n","0.1 0\n","0.3 0\n","0.4 1\n","0.5 1\n","0.8 1\n","0.9 0\n","1.2 2\n","0.7 0\n","1.0 3\n","0.6 0\n","1.6 0\n","0.2 0\n","0.6 0\n","0.4 0\n","0.7 0\n","0.5 0\n","0.1 1\n","0.7 1\n","0.1 0\n","0.2 1\n","0.9 0\n","0.2 0\n","0.6 1\n","0.4 0\n","0.2 1\n","0.8 0\n","0.2 0\n","1.0 1\n","0.6 0\n","1.2 4\n","1.1 0\n","1.4 2\n","1.1 0\n","1.0 0\n","1.0 1\n","1.7 2\n","1.9 1\n","1.1 3\n","0.7 2\n","1.8 0\n","1.3 2\n","1.0 0\n","0.6 0\n","0.3 0\n","0.9 3\n","0.6 1\n","0.9 2\n","0.7 0\n","1.2 1\n","0.9 0\n","0.9 0\n","1.1 0\n","0.8 0\n","1.0 2\n","1.2 3\n","0.8 0\n","1.7 0\n","0.8 0\n","0.8 0\n","1.6 2\n","1.1 2\n","1.0 0\n","0.6 0\n","1.0 1\n","1.5 0\n","0.7 2\n","0.9 0\n","1.5 0\n","1.6 1\n","1.4 2\n","0.6 1\n","1.1 0\n","1.3 6\n","0.7 1\n","0.8 1\n","1.0 0\n","1.1 0\n","0.8 0\n","1.3 1\n","1.0 2\n","1.2 0\n","0.7 0\n","1.2 1\n","0.9 0\n","1.3 0\n","1.4 4\n","0.7 0\n","0.9 1\n","1.0 1\n","0.5 1\n","0.8 0\n","2.0 1\n","1.4 2\n","0.8 0\n","1.0 1\n","0.4 0\n","0.8 0\n","1.8 4\n","1.0 2\n","2.1 3\n","2.0 0\n","2.4 0\n","1.6 2\n","1.5 0\n","1.7 1\n","2.5 9\n","1.8 0\n","1.0 1\n","2.2 0\n","0.8 0\n","1.1 0\n","1.4 6\n","1.5 1\n","0.8 0\n","1.9 6\n","1.9 0\n","1.0 0\n","1.5 4\n","1.4 0\n","1.3 2\n","1.2 2\n","1.6 1\n","1.0 1\n","1.0 0\n","0.6 0\n","1.7 5\n","0.9 0\n","1.8 0\n","1.2 1\n","1.5 4\n","1.5 0\n","1.2 0\n","1.5 1\n","2.4 3\n","1.2 1\n","2.2 1\n","1.7 0\n","1.5 1\n","1.5 2\n","2.4 0\n","1.9 5\n","1.1 1\n","1.3 1\n","0.8 4\n","0.6 0\n","1.8 2\n","1.2 0\n","0.7 0\n","1.1 0\n","1.3 2\n","2.6 11\n","1.7 1\n","1.2 0\n","0.7 0\n","1.6 1\n","1.0 0\n","1.0 1\n","1.6 3\n","1.9 0\n","2.0 0\n","0.9 1\n","1.7 4\n","1.3 1\n","1.5 2\n","1.2 0\n","2.5 4\n","2.2 5\n","1.4 0\n","2.5 1\n","1.6 8\n","1.2 0\n","2.5 0\n","1.0 0\n","1.1 0\n","1.3 1\n","1.1 3\n","1.4 2\n","1.2 1\n","1.1 1\n","1.7 4\n","1.1 0\n","2.7 10\n","2.3 3\n","1.7 1\n","2.7 0\n","1.4 1\n","1.0 3\n","3.0 2\n","1.2 2\n","1.0 2\n","1.3 0\n","1.7 4\n","0.7 2\n","3.1 4\n","2.0 3\n","2.1 0\n","1.9 0\n","2.1 0\n","3.0 3\n","1.3 0\n","1.3 0\n","0.9 3\n","1.9 1\n","0.9 0\n","1.8 3\n","1.4 1\n","1.5 0\n","1.6 0\n","2.2 2\n","1.6 4\n","1.4 4\n","1.5 0\n","2.5 0\n","1.4 1\n","1.4 0\n","0.8 0\n","2.8 0\n","2.8 0\n","2.3 4\n","2.4 4\n","1.6 1\n","1.6 1\n","1.7 2\n","1.3 0\n","1.3 1\n","1.3 5\n","1.7 1\n","2.4 0\n","2.3 2\n","1.5 1\n","0.7 0\n","1.9 0\n","1.3 0\n","1.2 1\n","1.9 0\n","2.3 0\n","1.8 0\n","2.3 2\n","2.0 1\n","2.1 1\n","2.2 5\n","1.4 4\n","2.0 4\n","0.9 2\n","1.8 0\n","1.2 0\n","1.9 2\n","2.4 0\n","2.4 0\n","2.4 5\n","2.0 1\n","1.5 0\n","1.4 0\n","1.7 4\n","1.4 3\n","1.7 0\n","2.1 1\n","0.3 0\n","2.7 0\n","1.0 1\n","2.4 12\n","1.6 2\n","1.0 0\n","1.4 3\n","1.4 4\n","1.3 0\n","1.1 1\n","1.6 0\n","1.8 8\n","0.8 1\n","1.5 0\n","1.6 3\n","2.5 0\n","1.6 0\n","1.0 3\n","1.2 3\n","1.9 3\n","1.1 0\n","2.5 2\n","1.4 0\n","2.0 2\n","1.9 4\n","1.7 0\n","2.4 2\n","2.5 1\n","2.0 2\n","1.6 5\n","2.9 2\n","2.8 5\n","2.1 0\n","1.3 4\n","2.4 4\n","1.5 0\n","2.7 2\n","3.7 1\n","2.6 3\n","1.3 0\n","3.0 7\n","1.7 1\n","1.5 1\n","2.2 0\n","1.9 0\n","1.7 7\n","0.4 0\n","2.3 4\n","4.1 5\n","2.8 5\n","1.7 1\n","1.7 2\n","2.7 6\n","2.3 2\n","2.3 0\n","2.3 0\n","2.0 1\n","1.8 0\n","2.1 3\n","1.7 0\n","3.2 8\n","2.2 1\n","1.8 1\n","1.9 6\n","1.5 1\n","1.4 1\n","1.6 6\n","2.9 0\n","2.0 2\n","1.3 0\n","3.4 1\n","1.2 8\n","1.9 5\n","1.6 0\n","2.7 4\n","3.1 3\n","2.3 3\n","1.1 2\n","2.6 0\n","2.3 4\n","1.8 0\n","2.7 4\n","2.3 2\n","4.5 3\n","1.4 1\n","2.5 4\n","2.4 13\n","2.0 1\n","2.3 1\n","3.7 11\n","1.7 4\n","2.1 0\n","1.7 1\n","exit at 5 3888\n","0.0 0\n","0.3 0\n","0.3 0\n","0.8 5\n","0.4 1\n","0.3 0\n","0.4 0\n","0.4 1\n","0.5 0\n","0.3 1\n","0.6 0\n","0.3 0\n","1.2 2\n","0.8 0\n","0.6 0\n","0.9 0\n","0.8 0\n","0.7 0\n","1.1 0\n","0.9 2\n","1.1 1\n","0.7 0\n","1.0 1\n","0.7 0\n","1.0 1\n","0.4 0\n","1.3 0\n","1.1 1\n","0.8 3\n","0.5 1\n","1.3 2\n","0.8 0\n","0.9 1\n","0.4 2\n","0.9 0\n","0.3 0\n","0.9 0\n","0.9 0\n","0.5 1\n","0.3 0\n","0.6 0\n","0.7 0\n","0.5 2\n","0.7 2\n","0.6 0\n","1.3 0\n","1.9 1\n","1.1 1\n","2.4 6\n","1.3 3\n","1.7 1\n","0.6 0\n","1.1 0\n","1.2 0\n","1.2 2\n","1.1 0\n","0.5 0\n","0.8 0\n","0.6 0\n","0.6 0\n","1.8 1\n","1.9 1\n","1.1 2\n","0.9 0\n","1.4 0\n","1.1 3\n","0.9 1\n","0.8 3\n","1.1 1\n","2.4 3\n","1.5 2\n","0.7 0\n","0.9 0\n","0.7 0\n","1.3 3\n","0.5 0\n","0.4 0\n","0.8 0\n","1.5 0\n","0.9 2\n","1.3 0\n","1.0 1\n","0.6 0\n","1.0 0\n","1.2 0\n","1.2 0\n","0.6 0\n","2.6 0\n","2.7 1\n","1.9 4\n","1.2 1\n","0.7 0\n","1.2 2\n","0.7 0\n","1.2 1\n","1.6 0\n","1.6 0\n","0.5 0\n","0.7 0\n","1.0 1\n","1.0 0\n","0.6 1\n","1.6 0\n","1.3 1\n","1.6 0\n","1.3 1\n","0.9 0\n","1.0 0\n","0.7 0\n","0.6 5\n","0.7 0\n","1.3 4\n","0.8 0\n","0.3 0\n","1.2 3\n","1.5 1\n","3.5 1\n","3.1 6\n","1.7 1\n","1.6 2\n","1.2 1\n","1.4 1\n","1.7 0\n","0.7 1\n","0.6 0\n","2.0 1\n","0.9 0\n","0.8 1\n","0.7 0\n","0.4 0\n","1.0 1\n","0.9 3\n","1.2 0\n","1.8 1\n","1.3 3\n","1.8 1\n","1.1 2\n","1.2 2\n","1.1 1\n","1.2 1\n","2.0 1\n","1.4 0\n","2.5 0\n","1.2 0\n","1.2 1\n","1.4 1\n","1.0 1\n","1.0 0\n","2.1 2\n","1.6 1\n","1.8 5\n","3.5 11\n","1.0 0\n","1.3 0\n","1.6 1\n","1.9 0\n","2.0 3\n","1.9 4\n","1.7 0\n","2.1 3\n","1.5 1\n","0.5 1\n","0.9 1\n","0.5 1\n","1.4 0\n","1.4 0\n","0.5 1\n","2.2 2\n","0.7 0\n","1.2 1\n","3.3 1\n","1.5 2\n","1.7 10\n","1.2 0\n","1.3 0\n","3.1 1\n","2.2 1\n","0.6 0\n","1.6 0\n","2.3 7\n","1.4 1\n","1.2 1\n","2.9 5\n","1.1 2\n","1.1 1\n","1.8 2\n","1.2 3\n","1.1 1\n","2.4 7\n","1.7 0\n","2.1 1\n","0.8 1\n","2.0 0\n","2.0 1\n","1.7 4\n","3.0 0\n","2.1 0\n","2.2 1\n","1.7 0\n","1.4 0\n","2.1 4\n","1.8 2\n","2.5 1\n","1.5 0\n","2.7 0\n","2.4 6\n","2.4 8\n","2.4 4\n","2.0 0\n","0.9 0\n","2.2 5\n","2.8 0\n","1.3 1\n","2.0 2\n","3.9 5\n","1.2 2\n","2.2 0\n","3.9 12\n","2.1 5\n","0.8 0\n","2.2 4\n","1.7 6\n","2.1 1\n","1.9 2\n","2.0 1\n","2.5 2\n","2.6 0\n","1.6 1\n","3.2 2\n","1.6 3\n","1.3 0\n","1.3 0\n","1.2 0\n","1.9 0\n","1.9 2\n","1.8 1\n","1.7 1\n","1.5 0\n","2.4 2\n","2.4 4\n","3.0 3\n","1.7 6\n","0.1 0\n","0.7 1\n","2.0 0\n","2.6 1\n","2.2 1\n","2.7 0\n","1.2 0\n","2.8 4\n","1.4 0\n","1.5 1\n","2.9 6\n","1.8 6\n","2.7 0\n","1.0 3\n","2.1 1\n","2.6 6\n","2.3 3\n","1.4 1\n","0.5 1\n","1.1 2\n","2.7 7\n","3.5 7\n","1.4 1\n","1.4 4\n","2.8 6\n","3.3 2\n","2.1 2\n","1.2 0\n","3.1 8\n","1.0 0\n","1.1 0\n","2.0 1\n","1.6 0\n","3.5 0\n","1.5 1\n","0.9 1\n","0.9 0\n","3.6 1\n","2.6 9\n","1.0 3\n","2.7 5\n","1.4 0\n","0.9 1\n","2.2 1\n","2.6 6\n","2.6 8\n","1.7 4\n","1.7 0\n","1.0 0\n","1.6 3\n","1.6 0\n","1.9 9\n","1.6 2\n","1.2 0\n","2.4 0\n","1.6 1\n","2.0 6\n","3.0 0\n","2.2 2\n","1.9 6\n","1.7 3\n","2.5 1\n","2.9 0\n","1.1 0\n","2.2 4\n","1.8 0\n","2.1 3\n","2.2 5\n","2.2 0\n","1.8 1\n","0.5 0\n","1.3 2\n","1.5 2\n","2.1 1\n","0.9 0\n","2.4 3\n","1.3 2\n","2.2 2\n","3.7 7\n","1.4 4\n","2.6 0\n","3.1 0\n","3.6 3\n","1.2 1\n","0.9 2\n","2.0 1\n","1.7 0\n","2.2 4\n","1.0 0\n","2.5 5\n","1.6 3\n","1.2 1\n","2.5 1\n","2.4 1\n","1.6 3\n","1.7 1\n","1.4 0\n","1.9 2\n","1.9 1\n","0.5 0\n","3.1 5\n","2.1 4\n","2.7 2\n","1.8 4\n","3.2 2\n","2.0 0\n","1.2 1\n","2.8 2\n","exit at 6 3495\n","2.0 2\n","0.6 0\n","0.7 1\n","0.7 0\n","0.5 2\n","1.2 1\n","0.7 2\n","0.3 0\n","1.3 2\n","0.4 0\n","0.5 0\n","0.4 0\n","0.5 1\n","0.2 0\n","0.5 1\n","0.1 0\n","0.5 0\n","0.6 0\n","0.6 1\n","0.5 1\n","0.5 0\n","0.3 0\n","0.6 0\n","0.6 0\n","0.2 0\n","1.0 0\n","0.5 1\n","0.3 1\n","0.4 0\n","0.3 0\n","0.3 0\n","1.2 0\n","0.4 0\n","0.6 0\n","0.4 0\n","0.1 1\n","0.5 1\n","1.0 1\n","0.7 0\n","0.6 1\n","0.6 0\n","0.5 1\n","0.6 1\n","0.6 0\n","0.4 0\n","0.8 0\n","0.1 0\n","0.3 0\n","0.8 0\n","0.9 0\n","0.2 0\n","0.4 0\n","0.6 0\n","0.7 1\n","0.6 1\n","0.7 0\n","1.1 0\n","0.5 0\n","1.1 3\n","0.7 3\n","0.7 0\n","0.3 0\n","0.7 0\n","0.4 0\n","0.4 0\n","0.6 1\n","0.5 1\n","1.0 0\n","0.4 1\n","0.4 1\n","0.4 1\n","0.3 0\n","0.9 1\n","0.6 0\n","0.9 0\n","0.9 0\n","0.2 0\n","0.5 0\n","0.7 0\n","0.2 0\n","0.4 0\n","0.4 2\n","0.0 0\n","0.1 0\n","1.2 0\n","0.3 0\n","0.4 0\n","1.3 1\n","0.2 0\n","0.3 0\n","0.6 0\n","0.3 0\n","0.9 1\n","0.5 1\n","0.9 0\n","0.9 1\n","0.6 2\n","0.7 3\n","0.4 2\n","0.6 0\n","0.4 0\n","1.0 0\n","0.8 0\n","1.1 1\n","0.4 0\n","0.7 1\n","1.5 1\n","1.0 1\n","0.9 3\n","0.8 1\n","0.8 0\n","0.8 3\n","1.6 2\n","1.8 1\n","0.5 2\n","0.8 0\n","0.5 2\n","1.5 0\n","0.6 1\n","1.0 0\n","1.2 0\n","0.5 2\n","1.2 1\n","1.1 1\n","0.6 1\n","1.5 0\n","1.4 1\n","1.2 3\n","0.4 0\n","0.9 0\n","1.4 0\n","1.5 3\n","0.8 0\n","0.2 1\n","1.0 2\n","1.2 1\n","1.6 2\n","1.7 0\n","0.7 0\n","1.0 3\n","1.2 1\n","1.3 0\n","0.7 1\n","0.7 2\n","1.9 0\n","1.0 0\n","0.7 0\n","1.5 0\n","0.7 1\n","0.2 0\n","0.8 1\n","0.6 0\n","0.9 1\n","0.7 0\n","1.6 0\n","0.8 1\n","0.5 1\n","0.4 1\n","1.3 2\n","1.0 0\n","0.4 0\n","1.1 1\n","2.1 1\n","0.7 0\n","1.0 0\n","0.8 0\n","1.9 0\n","1.7 0\n","1.6 1\n","0.4 1\n","1.2 1\n","1.4 6\n","0.7 0\n","1.4 3\n","1.6 5\n","1.5 2\n","2.1 6\n","1.4 2\n","1.4 2\n","1.0 3\n","0.9 0\n","0.7 0\n","1.2 2\n","1.1 2\n","2.0 7\n","1.0 1\n","1.0 2\n","2.1 5\n","1.0 0\n","0.5 0\n","2.6 2\n","1.3 3\n","0.9 0\n","0.9 0\n","1.1 3\n","1.4 2\n","0.9 1\n","1.6 0\n","1.8 1\n","1.1 1\n","1.2 1\n","1.7 0\n","1.5 1\n","1.7 2\n","1.1 0\n","2.7 3\n","1.3 3\n","1.6 2\n","1.1 0\n","2.0 8\n","2.5 0\n","1.2 1\n","2.1 0\n","1.7 5\n","1.1 0\n","1.9 2\n","1.0 0\n","1.6 1\n","1.4 1\n","1.1 0\n","1.0 1\n","1.9 0\n","1.8 2\n","1.6 0\n","2.3 6\n","2.0 0\n","0.6 0\n","2.4 1\n","1.5 3\n","2.0 4\n","1.1 1\n","1.7 6\n","1.3 0\n","1.3 1\n","1.2 0\n","1.7 3\n","2.6 4\n","1.5 2\n","1.3 2\n","2.5 1\n","0.8 2\n","1.3 2\n","1.5 0\n","1.4 1\n","1.3 2\n","1.1 1\n","2.0 1\n","2.4 4\n","2.5 0\n","1.7 1\n","1.4 1\n","1.6 1\n","0.7 0\n","1.7 0\n","1.4 1\n","1.3 1\n","2.2 1\n","2.4 0\n","1.9 1\n","1.4 1\n","1.9 0\n","0.7 1\n","2.9 12\n","0.9 0\n","2.0 1\n","2.8 2\n","0.9 0\n","2.2 0\n","1.1 1\n","2.3 2\n","1.6 1\n","1.7 0\n","1.9 0\n","2.5 0\n","1.8 4\n","1.6 2\n","2.4 3\n","2.9 1\n","2.2 0\n","1.1 0\n","2.8 6\n","1.9 0\n","2.2 4\n","1.3 2\n","1.1 3\n","3.3 7\n","exit at 7 2855\n","4.0 4\n","0.4 0\n","0.4 2\n","0.7 2\n","0.8 0\n","0.5 0\n","0.7 1\n","0.4 0\n","0.7 0\n","0.6 0\n","0.8 0\n","0.3 0\n","1.0 2\n","1.0 0\n","0.8 1\n","0.6 1\n","0.7 1\n","0.4 1\n","0.3 0\n","0.2 0\n","0.2 0\n","0.8 0\n","0.7 4\n","0.4 1\n","0.7 6\n","0.2 0\n","0.5 0\n","0.3 0\n","1.4 0\n","1.0 1\n","1.4 1\n","0.7 1\n","0.3 0\n","0.5 0\n","0.8 0\n","0.9 0\n","0.5 1\n","0.7 0\n","1.1 5\n","1.7 1\n","1.0 1\n","1.3 0\n","0.7 0\n","0.8 1\n","1.1 0\n","1.1 3\n","1.0 1\n","0.3 0\n","1.1 0\n","0.6 0\n","2.0 1\n","1.0 0\n","0.9 0\n","0.6 0\n","0.5 1\n","0.8 4\n","1.0 0\n","0.9 0\n","1.2 2\n","1.0 2\n","0.6 1\n","1.8 0\n","0.7 1\n","0.7 4\n","0.3 0\n","1.4 0\n","0.4 0\n","0.8 0\n","0.4 2\n","1.6 0\n","0.7 1\n","0.6 0\n","0.6 1\n","0.9 0\n","0.8 0\n","0.6 0\n","0.6 0\n","0.9 0\n","1.9 2\n","0.6 0\n","0.7 0\n","0.5 1\n","0.9 0\n","0.9 0\n","0.6 0\n","1.3 1\n","2.0 0\n","1.0 1\n","1.4 0\n","1.7 1\n","1.5 6\n","0.4 0\n","0.7 1\n","1.5 1\n","1.5 1\n","1.1 0\n","0.5 0\n","1.2 1\n","1.5 0\n","0.6 0\n","0.6 0\n","0.6 0\n","0.8 0\n","0.8 2\n","1.2 0\n","0.7 3\n","1.4 2\n","1.9 6\n","2.9 0\n","1.4 3\n","0.8 0\n","0.9 2\n","1.6 3\n","0.7 1\n","1.3 2\n","1.4 0\n","1.1 1\n","1.2 0\n","1.2 1\n","2.6 0\n","1.1 1\n","1.2 0\n","1.3 0\n","1.2 2\n","1.2 0\n","1.0 2\n","1.4 2\n","1.3 1\n","1.1 1\n","1.0 0\n","1.6 1\n","1.1 3\n","1.4 1\n","1.6 1\n","1.5 3\n","0.7 1\n","1.3 3\n","1.5 1\n","0.9 0\n","0.6 0\n","0.8 0\n","1.5 0\n","2.4 4\n","1.9 4\n","1.7 1\n","3.4 7\n","1.6 1\n","1.4 0\n","1.6 1\n","1.2 2\n","0.8 0\n","1.3 0\n","1.9 2\n","1.9 3\n","2.2 1\n","0.9 0\n","1.1 1\n","1.5 0\n","2.5 0\n","1.3 0\n","2.0 3\n","1.6 1\n","1.2 1\n","2.6 2\n","2.6 2\n","1.7 1\n","2.3 4\n","0.6 0\n","1.3 5\n","1.7 10\n","1.1 0\n","1.2 1\n","1.5 2\n","1.3 3\n","1.0 3\n","1.8 7\n","1.9 2\n","2.9 4\n","1.5 1\n","1.3 2\n","1.4 0\n","2.2 0\n","1.7 1\n","2.0 0\n","2.5 0\n","2.4 8\n","0.8 4\n","2.5 2\n","2.0 2\n","2.4 0\n","2.6 3\n","1.6 3\n","2.1 0\n","2.7 4\n","2.4 0\n","2.0 0\n","2.3 4\n","1.6 3\n","2.8 3\n","2.0 2\n","2.7 1\n","2.7 1\n","2.8 5\n","1.7 6\n","1.0 2\n","0.8 4\n","1.8 1\n","1.3 0\n","2.5 1\n","1.3 0\n","2.0 4\n","0.4 0\n","1.2 1\n","1.8 0\n","1.7 4\n","2.4 1\n","3.5 3\n","3.3 3\n","2.6 1\n","1.8 1\n","2.5 4\n","1.1 1\n","4.0 1\n","1.2 1\n","1.8 3\n","1.6 2\n","1.9 0\n","2.4 0\n","1.9 0\n","1.5 1\n","2.0 0\n","2.4 6\n","3.1 4\n","1.5 0\n","2.1 3\n","1.5 1\n","3.1 1\n","1.3 2\n","1.5 0\n","1.8 0\n","3.4 5\n","1.6 0\n","2.1 1\n","1.0 1\n","3.7 0\n","2.3 5\n","1.3 0\n","1.7 1\n","2.2 0\n","3.2 1\n","1.2 0\n","1.6 4\n","1.0 2\n","2.1 1\n","1.9 2\n","2.3 3\n","2.2 0\n","2.5 4\n","2.3 9\n","3.3 3\n","1.7 3\n","2.6 0\n","3.9 2\n","1.5 0\n","2.2 0\n","4.0 0\n","3.0 5\n","3.4 3\n","2.9 6\n","2.6 4\n","1.7 0\n","2.6 1\n","2.7 1\n","2.1 0\n","1.9 9\n","1.4 2\n","1.6 3\n","1.8 0\n","2.4 1\n","1.2 3\n","2.0 0\n","1.5 3\n","1.5 5\n","1.5 2\n","2.0 5\n","2.5 1\n","1.4 0\n","2.3 0\n","1.4 2\n","2.5 0\n","3.4 15\n","3.5 0\n","1.8 0\n","2.9 1\n","2.7 4\n","2.5 0\n","2.4 0\n","1.7 0\n","2.8 1\n","2.1 8\n","1.2 0\n","1.8 3\n","2.5 11\n","2.3 7\n","1.3 1\n","2.3 1\n","5.2 13\n","exit at 8 3060\n","3.0 3\n","0.6 0\n","0.1 0\n","0.3 2\n","0.2 0\n","0.3 1\n","0.4 0\n","0.5 0\n","1.3 0\n","0.8 3\n","0.7 0\n","0.3 0\n","0.9 1\n","1.1 4\n","1.3 0\n","0.1 0\n","0.9 0\n","0.2 0\n","0.6 1\n","0.2 0\n","0.6 1\n","0.8 0\n","0.5 1\n","0.3 0\n","0.3 0\n","0.8 0\n","0.1 0\n","0.7 0\n","0.6 3\n","0.7 0\n","0.2 0\n","0.7 1\n","0.6 2\n","0.8 2\n","0.8 0\n","0.9 1\n","0.9 1\n","1.0 0\n","0.5 0\n","0.3 1\n","0.4 0\n","1.0 0\n","0.5 0\n","0.3 0\n","0.7 3\n","0.9 2\n","0.5 2\n","0.7 0\n","1.0 1\n","2.4 4\n","0.4 3\n","0.4 0\n","0.8 0\n","0.5 2\n","0.4 0\n","0.7 1\n","0.2 0\n","0.8 2\n","0.5 0\n","0.2 0\n","1.4 8\n","1.1 0\n","0.6 0\n","1.1 1\n","1.2 1\n","1.1 2\n","1.7 2\n","0.8 0\n","1.2 0\n","1.2 1\n","0.4 0\n","0.8 6\n","1.0 3\n","0.9 0\n","0.4 0\n","0.9 2\n","0.4 0\n","0.6 2\n","1.5 1\n","1.2 2\n","1.5 0\n","0.7 1\n","1.3 5\n","0.8 0\n","0.9 0\n","1.0 0\n","0.9 3\n","0.6 1\n","0.7 0\n","1.9 2\n","1.2 0\n","0.3 0\n","0.8 1\n","1.0 0\n","1.4 0\n","1.0 1\n","0.8 0\n","1.0 2\n","0.7 0\n","1.0 0\n","0.6 1\n","0.8 2\n","2.2 0\n","1.0 3\n","1.2 0\n","0.9 2\n","0.4 0\n","0.8 0\n","1.8 0\n","1.4 2\n","1.1 0\n","2.1 0\n","2.1 0\n","1.2 3\n","1.1 0\n","2.1 13\n","1.3 1\n","0.4 0\n","1.8 3\n","1.7 2\n","1.1 0\n","0.4 0\n","0.9 0\n","1.0 0\n","1.0 2\n","1.5 0\n","0.8 0\n","1.8 2\n","1.0 1\n","1.8 4\n","1.8 0\n","2.1 1\n","2.5 1\n","1.2 4\n","0.9 3\n","1.9 1\n","0.7 0\n","0.8 3\n","1.4 0\n","1.1 1\n","0.5 1\n","1.0 2\n","1.5 4\n","0.8 0\n","1.6 1\n","0.4 2\n","1.4 6\n","1.2 0\n","1.9 2\n","1.4 0\n","1.1 0\n","0.7 0\n","0.8 1\n","1.4 0\n","1.2 6\n","0.5 0\n","1.3 4\n","1.2 5\n","0.6 0\n","0.1 0\n","2.4 0\n","2.2 1\n","1.3 1\n","2.4 8\n","1.6 4\n","1.2 2\n","1.2 0\n","1.2 0\n","1.4 4\n","2.1 1\n","2.1 4\n","2.1 0\n","2.4 2\n","1.1 0\n","1.2 0\n","1.8 3\n","0.7 1\n","2.8 6\n","1.1 1\n","0.5 0\n","0.2 0\n","1.1 5\n","1.4 4\n","1.1 1\n","1.7 0\n","1.2 2\n","1.7 2\n","0.6 0\n","1.5 1\n","0.9 0\n","0.8 0\n","1.0 0\n","1.5 0\n","2.4 8\n","2.4 1\n","0.8 0\n","1.1 2\n","2.6 0\n","1.8 2\n","1.5 0\n","1.8 1\n","2.5 5\n","0.6 3\n","1.5 1\n","0.9 2\n","1.4 2\n","1.9 1\n","2.5 0\n","0.9 0\n","2.0 0\n","1.3 1\n","1.3 2\n","0.9 1\n","1.2 5\n","2.2 1\n","1.9 2\n","2.2 13\n","2.0 5\n","2.0 3\n","1.5 0\n","1.1 0\n","2.1 2\n","3.7 3\n","1.4 0\n","2.3 4\n","1.4 1\n","1.2 0\n","1.3 3\n","1.2 0\n","1.1 3\n","2.4 2\n","1.6 0\n","0.7 1\n","0.8 0\n","2.2 0\n","2.1 6\n","2.1 1\n","3.8 5\n","1.1 0\n","2.4 1\n","0.4 2\n","2.5 0\n","0.7 0\n","1.5 8\n","1.6 1\n","0.5 0\n","2.1 0\n","2.1 1\n","2.1 4\n","1.2 2\n","1.1 2\n","1.6 0\n","0.7 0\n","1.7 2\n","0.1 0\n","1.3 0\n","1.5 1\n","2.2 6\n","1.7 0\n","1.3 1\n","1.7 1\n","2.0 4\n","3.1 1\n","1.3 1\n","1.1 3\n","0.7 0\n","1.3 0\n","1.7 6\n","1.5 3\n","0.7 0\n","1.4 1\n","1.6 4\n","0.7 0\n","2.3 4\n","0.8 0\n","2.9 1\n","1.4 0\n","2.1 1\n","2.5 2\n","1.4 0\n","3.0 3\n","2.0 0\n","1.9 0\n","3.2 7\n","2.6 0\n","1.6 7\n","1.3 0\n","2.3 1\n","1.6 1\n","3.0 0\n","2.5 2\n","1.1 1\n","2.3 7\n","3.0 2\n","2.4 1\n","2.6 0\n","1.7 3\n","2.1 1\n","0.8 0\n","2.4 0\n","1.2 0\n","2.1 2\n","4.0 6\n","2.5 0\n","1.5 0\n","1.8 8\n","2.5 2\n","2.1 8\n","3.2 1\n","1.2 0\n","2.5 1\n","1.8 0\n","1.7 1\n","3.4 0\n","1.6 3\n","2.7 3\n","2.4 0\n","2.3 3\n","1.8 0\n","1.2 2\n","4.1 2\n","2.0 0\n","3.0 3\n","2.1 5\n","1.6 0\n","1.8 4\n","3.0 12\n","1.8 8\n","4.0 4\n","1.7 0\n","1.3 4\n","2.5 2\n","2.1 2\n","2.5 0\n","2.9 5\n","2.6 2\n","2.5 1\n","0.8 0\n","1.6 3\n","2.6 2\n","0.9 0\n","1.6 3\n","1.8 4\n","3.0 5\n","2.1 0\n","3.2 4\n","1.4 1\n","1.4 0\n","2.5 1\n","1.8 1\n","1.8 2\n","1.7 1\n","3.6 6\n","1.9 4\n","2.6 1\n","2.8 12\n","2.4 1\n","2.5 0\n","2.5 4\n","3.6 0\n","1.3 0\n","3.3 0\n","1.2 1\n","1.3 0\n","1.5 2\n","4.3 0\n","3.0 15\n","1.6 0\n","1.8 4\n","2.6 6\n","3.1 0\n","3.7 5\n","2.6 1\n","1.8 2\n","3.8 1\n","2.1 0\n","1.4 1\n","2.8 7\n","2.6 1\n","1.7 4\n","2.0 2\n","3.0 6\n","3.1 6\n","2.9 2\n","3.1 4\n","2.0 2\n","1.9 2\n","1.5 1\n","2.8 5\n","1.2 0\n","1.3 2\n","1.5 1\n","2.3 0\n","1.2 0\n","2.7 5\n","3.5 5\n","1.1 0\n","1.1 4\n","2.9 4\n","2.9 0\n","2.3 0\n","4.0 1\n","1.4 0\n","2.5 2\n","2.6 1\n","3.8 10\n","2.2 0\n","0.8 0\n","1.4 3\n","1.6 0\n","2.4 2\n","3.4 0\n","3.4 6\n","1.2 0\n","0.9 1\n","1.1 0\n","1.4 0\n","2.0 0\n","3.0 2\n","0.5 0\n","2.1 3\n","2.2 0\n","2.7 2\n","3.7 9\n","2.1 7\n","1.6 1\n","3.6 3\n","1.2 0\n","2.1 1\n","2.8 6\n","2.7 0\n","1.8 2\n","0.9 1\n","1.0 1\n","1.4 0\n","2.5 4\n","2.4 2\n","3.5 2\n","0.8 3\n","2.6 2\n","1.5 1\n","3.0 0\n","1.5 1\n","1.3 1\n","2.7 7\n","3.3 1\n","1.6 6\n","2.7 1\n","2.6 0\n","2.1 6\n","2.2 3\n","1.9 1\n","3.3 0\n","1.8 1\n","2.4 0\n","4.2 10\n","0.9 2\n","1.9 0\n","2.0 0\n","2.2 1\n","3.6 0\n","1.8 0\n","3.0 4\n","3.3 0\n","2.0 1\n","1.9 0\n","1.3 1\n","2.1 1\n","2.6 8\n","1.5 1\n","1.2 1\n","2.0 8\n","2.0 0\n","1.8 0\n","3.6 4\n","3.0 3\n","2.7 7\n","1.4 3\n","3.3 1\n","1.3 0\n","1.3 0\n","1.3 0\n","2.1 1\n","2.8 0\n","3.4 5\n","3.3 9\n","2.5 2\n","1.8 1\n","2.4 1\n","3.9 3\n","1.5 1\n","2.1 3\n","1.4 3\n","1.9 4\n","2.4 2\n","1.2 2\n","2.2 2\n","1.4 1\n","2.6 0\n","2.1 0\n","4.4 9\n","1.2 0\n","3.0 2\n","2.5 7\n","3.1 13\n","2.0 2\n","3.2 4\n","2.1 1\n","1.3 4\n","2.1 3\n","2.9 0\n","2.5 4\n","2.4 1\n","2.7 0\n","1.6 3\n","2.1 2\n","4.6 0\n","1.9 0\n","4.5 13\n","exit at 9 5182\n","[3552, 3611, 2482, 4194, 3254, 3888, 3495, 2855, 3060, 5182]\n","3557.3\n"]}],"source":["# import gym\n","import numpy as np\n","# import copy\n","\n","# Hyperparameters\n","alpha = 0.001  # Learning rate, 0.001 for mountaincar\n","gamma = 0.99 # Discount factor\n","  # Epsilon-greedy exploration parameter\n","num_episodes = 30000# Number of episodes\n","# steps_compl = 0\n","# Create the CartPole environment\n","# env = gym.make('CartPole-v1', render_mode = 'none')\n","# env = gym.make('LunarLander-v2', render_mode = 'none')\n","# Initialize the weights for the linear function approximation\n","\n","# weights = np.random.rand(num_features, num_actions)\n","# weights = copy.deepcopy(curr_nn_weights)\n","\n","# print(\"hskgd\")\n","\n","\n","# Linear function approximation\n","def approximate_q(state, weights):\n","    return np.dot(phi_wrapper(state), weights).reshape(-1,1)\n","\n","# curr_test_state = env.observation_space.sample()\n","# print(\"hello\", (approximate_q(curr_test_state), curr_policy_net(torch.tensor(curr_test_state)).detach().numpy()))\n","\n","# Epsilon-greedy policy\n","def epsilon_greedy_policy(state,tot_steps,weights):\n","    epsilon = 0.1 + math.exp(-1. * tot_steps / 5000)\n","    if np.random.rand() < epsilon:\n","        return random.randrange(env.num_actions())  # Random action\n","    else:\n","        q_values = approximate_q(state,weights)\n","        return np.argmax(q_values)  # Greedy action\n","\n","# Q-learning algorithm with linear function approximation\n","# env = gym.make(\n","#     \"LunarLander-v2\",\n","#     continuous = False,\n","#     gravity = -10.0,\n","#     enable_wind = False,\n","#     wind_power = 15.0,\n","#     turbulence_power = 1.5,\n","#     render_mode = 'human'\n","# )\n","res = []\n","for i in range(10):\n","    weights = np.zeros((num_features, num_actions))\n","    duration_list = []\n","    tot_steps = 0 \n","    for episode in range(num_episodes):\n","\n","        env.reset()\n","        \n","        state = env.state()\n","#         state = state[0]\n","#         state_length = state.size\n","        # print(len(state))\n","        done = False\n","        steps = 0\n","        # episode_duration  = 0\n","        tot_rew = 0\n","        while not done:\n","    #         env.render()\n","            steps +=1\n","            tot_steps +=1\n","            # episode_duration += 1\n","    #         state += np.random.normal(0,0.1,state_length)\n","            action = epsilon_greedy_policy(state,tot_steps,weights)\n","            # print(action)\n","            # print(action)\n","            # print((env.step(action)))\n","            # env.close_display()\n","            reward, done = env.act(action)\n","            next_state = (env.state())\n","            # env.display_state(500)\n","            # env.close_display()  \n","#             next_state, reward, done, _, _ = env.step(action)\n","    #         if done == False:\n","    #             reward += 1 \n","            tot_rew += reward\n","\n","            # print(state)\n","            # Update Q-value using the Q-learning update rule\n","            # print((next_state).shape)\n","            # print(np.max(approximate_q((next_state))).shape)\n","            # print(next_state)\n","            if done:\n","                td_target = reward\n","            else:\n","                td_target = reward + gamma * np.max(approximate_q(next_state,weights))\n","            td_error = td_target - approximate_q(state,weights)[action]\n","#             print(td_error)\n","    #         print(td_target, td_error)\n","            weights[:, action] += alpha * td_error * phi_wrapper(state).reshape(num_features,)\n","            # print(nn_weights)\n","            # print(alpha * td_error * phi_wrapper(state))\n","\n","            state = next_state\n","\n","            # if steps >= 1000:\n","            #     break\n","        duration_list.append(tot_rew)\n","    #     plt.plot(duration_list)\n","    #     plt.pause(0.001)  # pause a bit so that plots are updated\n","    #     display.display(plt.gcf())\n","    #     display.clear_output(wait=True)\n","#         print(tot_rew)\n","        if(episode % 10 == 0):\n","            print(np.mean(duration_list[-10:]), tot_rew)\n","        if np.mean(duration_list[-10:]) > 5:\n","            print(\"exit at\", i, episode)\n","            res.append(episode)\n","            break\n","    \n","    else:\n","        res.append(num_episodes)\n","  \n","        \n","        \n","print(res)\n","print(sum(res)/len(res))\n","    # if (episode + 1) % 100 == 0:\n","#     print(f\"Episode {episode + 1}/{num_episodes}\")\n","\n","# plt.pause(0.001)  # pause a bit so that plots are updated\n","# display.display(plt.gcf())\n","\n","# plt.show()\n","\n","# Close the environment\n","# env.close()"]},{"cell_type":"code","execution_count":28,"metadata":{"trusted":true},"outputs":[],"source":["# # import gym\n","# import numpy as np\n","# import copy\n","\n","# # Hyperparameters\n","# alpha = 0.00001  # Learning rate, 0.001 for mountaincar\n","# gamma = 0.99  # Discount factor\n","#   # Epsilon-greedy exploration parameter\n","# num_episodes = 10000# Number of episodes\n","# steps_compl = 0\n","# # Create the CartPole environment\n","# # env = gym.make('CartPole-v1', render_mode = 'none')\n","# # env = gym.make('LunarLander-v2', render_mode = 'none')\n","# # Initialize the weights for the linear function approximation\n","\n","# # weights = np.random.rand(num_features, num_actions)\n","# # weights = copy.deepcopy(curr_nn_weights)\n","\n","# # print(\"hskgd\")\n","\n","\n","# # Linear function approximation\n","# def approximate_q(state, weights = weights):\n","#     # state = state[0]\n","#     # print(np.array(state).shape)\n","#     # print(phi_wrapper(state).shape)\n","#     # print(phi_wrapper(state).shape)\n","#     # print(weights.shape)\n","#     return np.dot(phi_wrapper(state), weights)\n","\n","# curr_test_state = env.observation_space.sample()\n","# # print(\"hello\", (approximate_q(curr_test_state), curr_policy_net(torch.tensor(curr_test_state)).detach().numpy()))\n","\n","# # Epsilon-greedy policy\n","# def epsilon_greedy_policy(state):\n","#     global steps_compl\n","#     epsilon = 0.1 + math.exp(-1. * steps_compl / 5000)\n","#     # print(epsilon)\n","# #     epsilon = 0.3\n","# #     epsilon = 0.3\n","#     steps_compl += 1\n","#     if np.random.rand() < epsilon:\n","#         return env.action_space.sample()  # Random action\n","#     else:\n","#         q_values = approximate_q(state)\n","#         # print(q_values.shape)\n","#         return np.argmax(q_values)  # Greedy action\n","\n","# # Q-learning algorithm with linear function approximation\n","# # env = gym.make(\n","# #     \"LunarLander-v2\",\n","# #     continuous = False,\n","# #     gravity = -10.0,\n","# #     enable_wind = False,\n","# #     wind_power = 15.0,\n","# #     turbulence_power = 1.5,\n","# #     render_mode = 'human'\n","# # )\n","# # for i in range(2):\n","# duration_list = []\n","# #     weights = np.zeros((num_features, num_actions))\n","# #     steps_compl = 0\n","# for episode in range(num_episodes):\n","\n","#     state = env.reset()\n","#     state = state[0]\n","#     state_length = state.size\n","#     # print(len(state))\n","#     done = False\n","#     steps = 0\n","#     # episode_duration  = 0\n","#     tot_rew = 0\n","#     while not done:\n","# #         env.render()\n","#         steps +=1\n","#         # episode_duration += 1\n","# #         state += np.random.normal(0,0.1,state_length)\n","#         action = epsilon_greedy_policy(state)\n","#         # print(action)\n","#         # print(action)\n","#         # print((env.step(action)))\n","#         next_state, reward, done, _, _ = env.step(action)\n","# #         if done == False:\n","# #             reward = 0\n","#         tot_rew += reward\n","\n","#     # print(state)\n","#     # Update Q-value using the Q-learning update rule\n","#     # print((next_state).shape)\n","#     # print(np.max(approximate_q((next_state))).shape)\n","#     # print(next_state)\n","#         if done:\n","#             td_target = reward\n","#         else:\n","#             td_target = reward + gamma * np.max(approximate_q((next_state)))\n","#         td_error = td_target - approximate_q((state))[action]\n","# #         print(td_target, td_error)\n","#         weights[:, action] += alpha * td_error * phi_wrapper(state)\n","#         # print(nn_weights)\n","#         # print(alpha * td_error * phi_wrapper(state))\n","\n","#         state = next_state\n","#         if steps >= 1000:\n","#             break\n","#     duration_list.append(tot_rew)\n","# #     plt.plot(duration_list)\n","# #     plt.pause(0.001)  # pause a bit so that plots are updated\n","# #     display.display(plt.gcf())\n","# #     display.clear_output(wait=True)\n","#     if episode%100==0: print(tot_rew)\n","#     if np.mean(duration_list[-10:]) > 200:\n","#         print(\"exit at\", episode)\n","#         break\n","#     # if (episode + 1) % 100 == 0:\n","# #     print(f\"Episode {episode + 1}/{num_episodes}\")\n","\n","# # plt.pause(0.001)  # pause a bit so that plots are updated\n","# # display.display(plt.gcf())\n","\n","# # plt.show()\n","\n","# # Close the environment\n","# # env.close()"]},{"cell_type":"code","execution_count":29,"metadata":{"trusted":true},"outputs":[],"source":["# # import gym\n","# import numpy as np\n","# import copy\n","\n","# # Hyperparameters\n","# alpha = 0.00001  # Learning rate, 0.001 for mountaincar\n","# gamma = 0.99  # Discount factor\n","#   # Epsilon-greedy exploration parameter\n","# num_episodes = 10000# Number of episodes\n","# steps_compl = 0\n","# # Create the CartPole environment\n","# # env = gym.make('CartPole-v1', render_mode = 'none')\n","\n","# # Initialize the weights for the linear function approximation\n","# num_features = 32  # Number of features (state dimensions)\n","# num_actions = env.action_space.n  # Number of actions\n","# # weights = np.random.rand(num_features, num_actions)\n","# # weights = copy.deepcopy(curr_nn_weights)\n","# # weights = np.zeros((num_features, num_actions))\n","\n","# # print(\"hskgd\")\n","\n","\n","# # Linear function approximation\n","# def approximate_q(state, weights = weights):\n","#     # state = state[0]\n","#     # print(np.array(state).shape)\n","#     # print(phi_wrapper(state).shape)\n","#     # print(phi_wrapper(state).shape)\n","#     # print(weights.shape)\n","#     return np.dot(phi_wrapper(state), weights)\n","\n","# curr_test_state = env.observation_space.sample()\n","# # print(\"hello\", (approximate_q(curr_test_state), curr_policy_net(torch.tensor(curr_test_state)).detach().numpy()))\n","\n","# # Epsilon-greedy policy\n","# def epsilon_greedy_policy(state):\n","#     global steps_compl\n","#     epsilon = 0.1 + math.exp(-1. * steps_compl / 5000)\n","# #     print(epsilon)\n","# #     epsilon = 0.3\n","#     epsilon = 0\n","#     steps_compl += 1\n","#     if np.random.rand() < epsilon:\n","#         return env.action_space.sample()  # Random action\n","#     else:\n","#         q_values = approximate_q(state)\n","#         # print(q_values.shape)\n","#         return np.argmax(q_values)  # Greedy action\n","\n","# # Q-learning algorithm with linear function approximation\n","# # env = gym.make(\n","# #     \"LunarLander-v2\",\n","# #     continuous = False,\n","# #     gravity = -10.0,\n","# #     enable_wind = False,\n","# #     wind_power = 15.0,\n","# #     turbulence_power = 1.5,\n","# #     render_mode = 'human'\n","# # )\n","# duration_list = []\n","# for episode in range(num_episodes):\n","    \n","#     state = env.reset()\n","#     state = state[0]\n","#     state_length = state.size\n","#     # print(len(state))\n","#     done = False\n","#     steps = 0\n","#     # episode_duration  = 0\n","#     tot_rew = 0\n","#     while not done:\n","# #         env.render()\n","#         steps +=1\n","#         # episode_duration += 1\n","# #         state += np.random.normal(0,0.1,state_length)\n","#         action = epsilon_greedy_policy(state)\n","#         # print(action)\n","#         # print(action)\n","#         # print((env.step(action)))\n","#         next_state, reward, done, _, _ = env.step(action)\n","#         tot_rew += reward\n","\n","#         # print(state)\n","#         # Update Q-value using the Q-learning update rule\n","#         # print((next_state).shape)\n","#         # print(np.max(approximate_q((next_state))).shape)\n","#         # print(next_state)\n","#         if done:\n","#             td_target = reward\n","#         else:\n","#             td_target = reward + gamma * np.max(approximate_q((next_state)))\n","#         td_error = td_target - approximate_q((state))[action]\n","# #         print(td_target, td_error)\n","#         weights[:, action] += alpha * td_error * phi_wrapper(state)\n","#         # print(nn_weights)\n","#         # print(alpha * td_error * phi_wrapper(state))\n","        \n","#         state = next_state\n","#         if steps >= 1000:\n","#             break\n","#     duration_list.append(tot_rew)\n","# #     plt.plot(duration_list)\n","# #     plt.pause(0.001)  # pause a bit so that plots are updated\n","# #     display.display(plt.gcf())\n","# #     display.clear_output(wait=True)\n","#     print(tot_rew)\n","#     # if (episode + 1) % 100 == 0:\n","# #     print(f\"Episode {episode + 1}/{num_episodes}\")\n","\n","# # plt.pause(0.001)  # pause a bit so that plots are updated\n","# # display.display(plt.gcf())\n","\n","# # plt.show()\n","# print(\"The mean is\", np.mean(duration_list),np.std(duration_list))\n","# # Close the environment\n","# # env.close()"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["def extract_last_floating_numbers(file_path):\n","    ordered_list = []\n","    \n","    with open(file_path, 'r') as file:\n","        for line in file:\n","            # Strip leading/trailing whitespace and split by whitespace\n","            parts = line.strip().split()\n","            if parts:  # Ensure there's something in the line\n","                try:\n","                    # Attempt to convert the last part to a float\n","                    last_number = float(parts[-1])\n","                    ordered_list.append(last_number)\n","                except ValueError:\n","                    # Handle the case where the last part is not a valid float\n","                    print(f\"Warning: Last part '{parts[-1]}' is not a valid float.\")\n","    \n","    return ordered_list\n","\n","# Usage\n","file_path = 'copy_4_dqn_out.txt'  # Replace with your file path\n","rew_for_plot = extract_last_floating_numbers(file_path)\n","file_path = 'copy_3_plain_out.txt'\n","rew_plot_van = extract_last_floating_numbers(file_path)"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"data":{"text/plain":["<function matplotlib.pyplot.show(close=None, block=None)>"]},"execution_count":45,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 1000x600 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["%matplotlib inline\n","plt.figure(figsize=(10,6))\n","plt.plot(rew_for_plot, label = \"DS-DQN\", color = 'blue')\n","plt.plot(rew_plot_van, label = \"Vanilla DQN\", color = 'red')\n","plt.xlabel('Episodes')\n","plt.ylabel('Average Return')\n","plt.legend()\n","plt.grid(True)\n","plt.show"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5650541,"sourceId":9326810,"sourceType":"datasetVersion"}],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":4}
